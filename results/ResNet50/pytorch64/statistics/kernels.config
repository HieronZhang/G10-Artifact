Kernel ID: 0, Name: torch.ops.aten.convolution.default(primals_321, primals_1, None, [2, 2], [3, 3], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor320, Name: primals_321, Is global?: 1: Size in byte: 38535168, Dimensions: f32[64, 3, 224, 224]
tensor0, Name: primals_1, Is global?: 1: Size in byte: 37632, Dimensions: f32[64, 3, 7, 7]
Output Tensors:
tensor321, Name: convolution, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 1, Name: torch.ops.aten.add.Tensor(primals_164, 1)
Input Tensors:
tensor163, Name: primals_164, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor322, Name: add, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 2, Name: torch.ops.aten.var_mean.correction(convolution, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor321, Name: convolution, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
Output Tensors:
tensor323, Name: getitem, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
tensor324, Name: getitem_1, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 3, Name: torch.ops.aten.add.Tensor(getitem, 1e-05)
Input Tensors:
tensor323, Name: getitem, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor325, Name: add_1, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 4, Name: torch.ops.aten.rsqrt.default(add_1)
Input Tensors:
tensor325, Name: add_1, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor326, Name: rsqrt, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 5, Name: torch.ops.aten.sub.Tensor(convolution, getitem_1)
Input Tensors:
tensor321, Name: convolution, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor324, Name: getitem_1, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor327, Name: sub, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 6, Name: torch.ops.aten.mul.Tensor(sub, rsqrt)
Input Tensors:
tensor327, Name: sub, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor326, Name: rsqrt, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor328, Name: mul, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 7, Name: torch.ops.aten.squeeze.dims(getitem_1, [0, 2, 3])
Input Tensors:
tensor324, Name: getitem_1, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor329, Name: squeeze, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 8, Name: torch.ops.aten.mul.Tensor(squeeze, 0.1)
Input Tensors:
tensor329, Name: squeeze, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor330, Name: mul_1, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 9, Name: torch.ops.aten.mul.Tensor(primals_162, 0.9)
Input Tensors:
tensor161, Name: primals_162, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor331, Name: mul_2, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 10, Name: torch.ops.aten.add.Tensor(mul_1, mul_2)
Input Tensors:
tensor330, Name: mul_1, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor331, Name: mul_2, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor332, Name: add_2, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 11, Name: torch.ops.aten.mul.Tensor(squeeze_2, 1.0000012456169853)
Input Tensors:
tensor323, Name: squeeze_2, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor333, Name: mul_3, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 12, Name: torch.ops.aten.mul.Tensor(mul_3, 0.1)
Input Tensors:
tensor333, Name: mul_3, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor334, Name: mul_4, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 13, Name: torch.ops.aten.mul.Tensor(primals_163, 0.9)
Input Tensors:
tensor162, Name: primals_163, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor335, Name: mul_5, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 14, Name: torch.ops.aten.add.Tensor(mul_4, mul_5)
Input Tensors:
tensor334, Name: mul_4, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor335, Name: mul_5, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor336, Name: add_3, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 15, Name: torch.ops.aten.unsqueeze.default(primals_2, -1)
Input Tensors:
tensor1, Name: primals_2, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor337, Name: unsqueeze, Is global?: 0: Size in byte: 256, Dimensions: f32[64, 1]
____________________________________________________________________
Kernel ID: 16, Name: torch.ops.aten.mul.Tensor(mul, unsqueeze_1)
Input Tensors:
tensor328, Name: mul, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor337, Name: unsqueeze_1, Is global?: 0: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor338, Name: mul_6, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 17, Name: torch.ops.aten.add.Tensor(mul_6, unsqueeze_3)
Input Tensors:
tensor338, Name: mul_6, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor2, Name: unsqueeze_3, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor339, Name: add_4, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 18, Name: torch.ops.aten.relu.default(add_4)
Input Tensors:
tensor339, Name: add_4, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
Output Tensors:
tensor340, Name: relu, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 19, Name: torch.ops.aten.max_pool2d_with_indices.default(relu, [3, 3], [2, 2], [1, 1])
Input Tensors:
tensor340, Name: relu, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
Output Tensors:
tensor341, Name: getitem_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor342, Name: getitem_3, Is global?: 0: Size in byte: 102760448, Dimensions: i64[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 20, Name: torch.ops.aten.convolution.default(getitem_2, primals_4, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor341, Name: getitem_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor3, Name: primals_4, Is global?: 1: Size in byte: 16384, Dimensions: f32[64, 64, 1, 1]
Output Tensors:
tensor343, Name: convolution_1, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 21, Name: torch.ops.aten.add.Tensor(primals_167, 1)
Input Tensors:
tensor166, Name: primals_167, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor344, Name: add_5, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 22, Name: torch.ops.aten.var_mean.correction(convolution_1, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor343, Name: convolution_1, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor345, Name: getitem_4, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
tensor346, Name: getitem_5, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 23, Name: torch.ops.aten.add.Tensor(getitem_4, 1e-05)
Input Tensors:
tensor345, Name: getitem_4, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor347, Name: add_6, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 24, Name: torch.ops.aten.rsqrt.default(add_6)
Input Tensors:
tensor347, Name: add_6, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor348, Name: rsqrt_1, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 25, Name: torch.ops.aten.sub.Tensor(convolution_1, getitem_5)
Input Tensors:
tensor343, Name: convolution_1, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor346, Name: getitem_5, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor349, Name: sub_1, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 26, Name: torch.ops.aten.mul.Tensor(sub_1, rsqrt_1)
Input Tensors:
tensor349, Name: sub_1, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor348, Name: rsqrt_1, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor350, Name: mul_7, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 27, Name: torch.ops.aten.mul.Tensor(squeeze_3, 0.1)
Input Tensors:
tensor346, Name: squeeze_3, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor351, Name: mul_8, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 28, Name: torch.ops.aten.mul.Tensor(primals_165, 0.9)
Input Tensors:
tensor164, Name: primals_165, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor352, Name: mul_9, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 29, Name: torch.ops.aten.add.Tensor(mul_8, mul_9)
Input Tensors:
tensor351, Name: mul_8, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor352, Name: mul_9, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor353, Name: add_7, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 30, Name: torch.ops.aten.mul.Tensor(squeeze_5, 1.0000049824865598)
Input Tensors:
tensor345, Name: squeeze_5, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor354, Name: mul_10, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 31, Name: torch.ops.aten.mul.Tensor(mul_10, 0.1)
Input Tensors:
tensor354, Name: mul_10, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor355, Name: mul_11, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 32, Name: torch.ops.aten.mul.Tensor(primals_166, 0.9)
Input Tensors:
tensor165, Name: primals_166, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor356, Name: mul_12, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 33, Name: torch.ops.aten.add.Tensor(mul_11, mul_12)
Input Tensors:
tensor355, Name: mul_11, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor356, Name: mul_12, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor357, Name: add_8, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 34, Name: torch.ops.aten.mul.Tensor(mul_7, unsqueeze_5)
Input Tensors:
tensor350, Name: mul_7, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor4, Name: unsqueeze_5, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor358, Name: mul_13, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 35, Name: torch.ops.aten.add.Tensor(mul_13, unsqueeze_7)
Input Tensors:
tensor358, Name: mul_13, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor5, Name: unsqueeze_7, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor359, Name: add_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 36, Name: torch.ops.aten.relu.default(add_9)
Input Tensors:
tensor359, Name: add_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor360, Name: relu_1, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 37, Name: torch.ops.aten.convolution.default(relu_1, primals_7, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor360, Name: relu_1, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor6, Name: primals_7, Is global?: 1: Size in byte: 147456, Dimensions: f32[64, 64, 3, 3]
Output Tensors:
tensor361, Name: convolution_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 38, Name: torch.ops.aten.add.Tensor(primals_170, 1)
Input Tensors:
tensor169, Name: primals_170, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor362, Name: add_10, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 39, Name: torch.ops.aten.var_mean.correction(convolution_2, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor361, Name: convolution_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor363, Name: getitem_6, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
tensor364, Name: getitem_7, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 40, Name: torch.ops.aten.add.Tensor(getitem_6, 1e-05)
Input Tensors:
tensor363, Name: getitem_6, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor365, Name: add_11, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 41, Name: torch.ops.aten.rsqrt.default(add_11)
Input Tensors:
tensor365, Name: add_11, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor366, Name: rsqrt_2, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 42, Name: torch.ops.aten.sub.Tensor(convolution_2, getitem_7)
Input Tensors:
tensor361, Name: convolution_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor364, Name: getitem_7, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor367, Name: sub_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 43, Name: torch.ops.aten.mul.Tensor(sub_2, rsqrt_2)
Input Tensors:
tensor367, Name: sub_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor366, Name: rsqrt_2, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor368, Name: mul_14, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 44, Name: torch.ops.aten.mul.Tensor(squeeze_6, 0.1)
Input Tensors:
tensor364, Name: squeeze_6, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor369, Name: mul_15, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 45, Name: torch.ops.aten.mul.Tensor(primals_168, 0.9)
Input Tensors:
tensor167, Name: primals_168, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor370, Name: mul_16, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 46, Name: torch.ops.aten.add.Tensor(mul_15, mul_16)
Input Tensors:
tensor369, Name: mul_15, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor370, Name: mul_16, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor371, Name: add_12, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 47, Name: torch.ops.aten.mul.Tensor(squeeze_8, 1.0000049824865598)
Input Tensors:
tensor363, Name: squeeze_8, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor372, Name: mul_17, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 48, Name: torch.ops.aten.mul.Tensor(mul_17, 0.1)
Input Tensors:
tensor372, Name: mul_17, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor373, Name: mul_18, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 49, Name: torch.ops.aten.mul.Tensor(primals_169, 0.9)
Input Tensors:
tensor168, Name: primals_169, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor374, Name: mul_19, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 50, Name: torch.ops.aten.add.Tensor(mul_18, mul_19)
Input Tensors:
tensor373, Name: mul_18, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor374, Name: mul_19, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor375, Name: add_13, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 51, Name: torch.ops.aten.mul.Tensor(mul_14, unsqueeze_9)
Input Tensors:
tensor368, Name: mul_14, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor7, Name: unsqueeze_9, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor376, Name: mul_20, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 52, Name: torch.ops.aten.add.Tensor(mul_20, unsqueeze_11)
Input Tensors:
tensor376, Name: mul_20, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor8, Name: unsqueeze_11, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor377, Name: add_14, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 53, Name: torch.ops.aten.relu.default(add_14)
Input Tensors:
tensor377, Name: add_14, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor378, Name: relu_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 54, Name: torch.ops.aten.convolution.default(relu_2, primals_10, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor378, Name: relu_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor9, Name: primals_10, Is global?: 1: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
Output Tensors:
tensor379, Name: convolution_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 55, Name: torch.ops.aten.add.Tensor(primals_173, 1)
Input Tensors:
tensor172, Name: primals_173, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor380, Name: add_15, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 56, Name: torch.ops.aten.var_mean.correction(convolution_3, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor379, Name: convolution_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor381, Name: getitem_8, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor382, Name: getitem_9, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 57, Name: torch.ops.aten.add.Tensor(getitem_8, 1e-05)
Input Tensors:
tensor381, Name: getitem_8, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor383, Name: add_16, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 58, Name: torch.ops.aten.rsqrt.default(add_16)
Input Tensors:
tensor383, Name: add_16, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor384, Name: rsqrt_3, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 59, Name: torch.ops.aten.sub.Tensor(convolution_3, getitem_9)
Input Tensors:
tensor379, Name: convolution_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor382, Name: getitem_9, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor385, Name: sub_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 60, Name: torch.ops.aten.mul.Tensor(sub_3, rsqrt_3)
Input Tensors:
tensor385, Name: sub_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor384, Name: rsqrt_3, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor386, Name: mul_21, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 61, Name: torch.ops.aten.mul.Tensor(squeeze_9, 0.1)
Input Tensors:
tensor382, Name: squeeze_9, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor387, Name: mul_22, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 62, Name: torch.ops.aten.mul.Tensor(primals_171, 0.9)
Input Tensors:
tensor170, Name: primals_171, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor388, Name: mul_23, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 63, Name: torch.ops.aten.add.Tensor(mul_22, mul_23)
Input Tensors:
tensor387, Name: mul_22, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor388, Name: mul_23, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor389, Name: add_17, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 64, Name: torch.ops.aten.mul.Tensor(squeeze_11, 1.0000049824865598)
Input Tensors:
tensor381, Name: squeeze_11, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor390, Name: mul_24, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 65, Name: torch.ops.aten.mul.Tensor(mul_24, 0.1)
Input Tensors:
tensor390, Name: mul_24, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor391, Name: mul_25, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 66, Name: torch.ops.aten.mul.Tensor(primals_172, 0.9)
Input Tensors:
tensor171, Name: primals_172, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor392, Name: mul_26, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 67, Name: torch.ops.aten.add.Tensor(mul_25, mul_26)
Input Tensors:
tensor391, Name: mul_25, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor392, Name: mul_26, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor393, Name: add_18, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 68, Name: torch.ops.aten.mul.Tensor(mul_21, unsqueeze_13)
Input Tensors:
tensor386, Name: mul_21, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor10, Name: unsqueeze_13, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor394, Name: mul_27, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 69, Name: torch.ops.aten.add.Tensor(mul_27, unsqueeze_15)
Input Tensors:
tensor394, Name: mul_27, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor11, Name: unsqueeze_15, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor395, Name: add_19, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 70, Name: torch.ops.aten.convolution.default(getitem_2, primals_13, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor341, Name: getitem_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor12, Name: primals_13, Is global?: 1: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
Output Tensors:
tensor396, Name: convolution_4, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 71, Name: torch.ops.aten.add.Tensor(primals_176, 1)
Input Tensors:
tensor175, Name: primals_176, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor397, Name: add_20, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 72, Name: torch.ops.aten.var_mean.correction(convolution_4, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor396, Name: convolution_4, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor398, Name: getitem_10, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor399, Name: getitem_11, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 73, Name: torch.ops.aten.add.Tensor(getitem_10, 1e-05)
Input Tensors:
tensor398, Name: getitem_10, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor400, Name: add_21, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 74, Name: torch.ops.aten.rsqrt.default(add_21)
Input Tensors:
tensor400, Name: add_21, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor401, Name: rsqrt_4, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 75, Name: torch.ops.aten.sub.Tensor(convolution_4, getitem_11)
Input Tensors:
tensor396, Name: convolution_4, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor399, Name: getitem_11, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor402, Name: sub_4, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 76, Name: torch.ops.aten.mul.Tensor(sub_4, rsqrt_4)
Input Tensors:
tensor402, Name: sub_4, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor401, Name: rsqrt_4, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor403, Name: mul_28, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 77, Name: torch.ops.aten.mul.Tensor(squeeze_12, 0.1)
Input Tensors:
tensor399, Name: squeeze_12, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor404, Name: mul_29, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 78, Name: torch.ops.aten.mul.Tensor(primals_174, 0.9)
Input Tensors:
tensor173, Name: primals_174, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor405, Name: mul_30, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 79, Name: torch.ops.aten.add.Tensor(mul_29, mul_30)
Input Tensors:
tensor404, Name: mul_29, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor405, Name: mul_30, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor406, Name: add_22, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 80, Name: torch.ops.aten.mul.Tensor(squeeze_14, 1.0000049824865598)
Input Tensors:
tensor398, Name: squeeze_14, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor407, Name: mul_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 81, Name: torch.ops.aten.mul.Tensor(mul_31, 0.1)
Input Tensors:
tensor407, Name: mul_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor408, Name: mul_32, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 82, Name: torch.ops.aten.mul.Tensor(primals_175, 0.9)
Input Tensors:
tensor174, Name: primals_175, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor409, Name: mul_33, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 83, Name: torch.ops.aten.add.Tensor(mul_32, mul_33)
Input Tensors:
tensor408, Name: mul_32, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor409, Name: mul_33, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor410, Name: add_23, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 84, Name: torch.ops.aten.mul.Tensor(mul_28, unsqueeze_17)
Input Tensors:
tensor403, Name: mul_28, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor13, Name: unsqueeze_17, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor411, Name: mul_34, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 85, Name: torch.ops.aten.add.Tensor(mul_34, unsqueeze_19)
Input Tensors:
tensor411, Name: mul_34, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor14, Name: unsqueeze_19, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor412, Name: add_24, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 86, Name: torch.ops.aten.add.Tensor(add_19, add_24)
Input Tensors:
tensor395, Name: add_19, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor412, Name: add_24, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor413, Name: add_25, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 87, Name: torch.ops.aten.relu.default(add_25)
Input Tensors:
tensor413, Name: add_25, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor414, Name: relu_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 88, Name: torch.ops.aten.convolution.default(relu_3, primals_16, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor414, Name: relu_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor15, Name: primals_16, Is global?: 1: Size in byte: 65536, Dimensions: f32[64, 256, 1, 1]
Output Tensors:
tensor415, Name: convolution_5, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 89, Name: torch.ops.aten.add.Tensor(primals_179, 1)
Input Tensors:
tensor178, Name: primals_179, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor416, Name: add_26, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 90, Name: torch.ops.aten.var_mean.correction(convolution_5, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor415, Name: convolution_5, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor417, Name: getitem_12, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
tensor418, Name: getitem_13, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 91, Name: torch.ops.aten.add.Tensor(getitem_12, 1e-05)
Input Tensors:
tensor417, Name: getitem_12, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor419, Name: add_27, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 92, Name: torch.ops.aten.rsqrt.default(add_27)
Input Tensors:
tensor419, Name: add_27, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor420, Name: rsqrt_5, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 93, Name: torch.ops.aten.sub.Tensor(convolution_5, getitem_13)
Input Tensors:
tensor415, Name: convolution_5, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor418, Name: getitem_13, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor421, Name: sub_5, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 94, Name: torch.ops.aten.mul.Tensor(sub_5, rsqrt_5)
Input Tensors:
tensor421, Name: sub_5, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor420, Name: rsqrt_5, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor422, Name: mul_35, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 95, Name: torch.ops.aten.mul.Tensor(squeeze_15, 0.1)
Input Tensors:
tensor418, Name: squeeze_15, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor423, Name: mul_36, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 96, Name: torch.ops.aten.mul.Tensor(primals_177, 0.9)
Input Tensors:
tensor176, Name: primals_177, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor424, Name: mul_37, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 97, Name: torch.ops.aten.add.Tensor(mul_36, mul_37)
Input Tensors:
tensor423, Name: mul_36, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor424, Name: mul_37, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor425, Name: add_28, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 98, Name: torch.ops.aten.mul.Tensor(squeeze_17, 1.0000049824865598)
Input Tensors:
tensor417, Name: squeeze_17, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor426, Name: mul_38, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 99, Name: torch.ops.aten.mul.Tensor(mul_38, 0.1)
Input Tensors:
tensor426, Name: mul_38, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor427, Name: mul_39, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 100, Name: torch.ops.aten.mul.Tensor(primals_178, 0.9)
Input Tensors:
tensor177, Name: primals_178, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor428, Name: mul_40, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 101, Name: torch.ops.aten.add.Tensor(mul_39, mul_40)
Input Tensors:
tensor427, Name: mul_39, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor428, Name: mul_40, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor429, Name: add_29, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 102, Name: torch.ops.aten.mul.Tensor(mul_35, unsqueeze_21)
Input Tensors:
tensor422, Name: mul_35, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor16, Name: unsqueeze_21, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor430, Name: mul_41, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 103, Name: torch.ops.aten.add.Tensor(mul_41, unsqueeze_23)
Input Tensors:
tensor430, Name: mul_41, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor17, Name: unsqueeze_23, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor431, Name: add_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 104, Name: torch.ops.aten.relu.default(add_30)
Input Tensors:
tensor431, Name: add_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor432, Name: relu_4, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 105, Name: torch.ops.aten.convolution.default(relu_4, primals_19, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor432, Name: relu_4, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor18, Name: primals_19, Is global?: 1: Size in byte: 147456, Dimensions: f32[64, 64, 3, 3]
Output Tensors:
tensor433, Name: convolution_6, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 106, Name: torch.ops.aten.add.Tensor(primals_182, 1)
Input Tensors:
tensor181, Name: primals_182, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor434, Name: add_31, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 107, Name: torch.ops.aten.var_mean.correction(convolution_6, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor433, Name: convolution_6, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor435, Name: getitem_14, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
tensor436, Name: getitem_15, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 108, Name: torch.ops.aten.add.Tensor(getitem_14, 1e-05)
Input Tensors:
tensor435, Name: getitem_14, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor437, Name: add_32, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 109, Name: torch.ops.aten.rsqrt.default(add_32)
Input Tensors:
tensor437, Name: add_32, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor438, Name: rsqrt_6, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 110, Name: torch.ops.aten.sub.Tensor(convolution_6, getitem_15)
Input Tensors:
tensor433, Name: convolution_6, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor436, Name: getitem_15, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor439, Name: sub_6, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 111, Name: torch.ops.aten.mul.Tensor(sub_6, rsqrt_6)
Input Tensors:
tensor439, Name: sub_6, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor438, Name: rsqrt_6, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor440, Name: mul_42, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 112, Name: torch.ops.aten.mul.Tensor(squeeze_18, 0.1)
Input Tensors:
tensor436, Name: squeeze_18, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor441, Name: mul_43, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 113, Name: torch.ops.aten.mul.Tensor(primals_180, 0.9)
Input Tensors:
tensor179, Name: primals_180, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor442, Name: mul_44, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 114, Name: torch.ops.aten.add.Tensor(mul_43, mul_44)
Input Tensors:
tensor441, Name: mul_43, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor442, Name: mul_44, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor443, Name: add_33, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 115, Name: torch.ops.aten.mul.Tensor(squeeze_20, 1.0000049824865598)
Input Tensors:
tensor435, Name: squeeze_20, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor444, Name: mul_45, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 116, Name: torch.ops.aten.mul.Tensor(mul_45, 0.1)
Input Tensors:
tensor444, Name: mul_45, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor445, Name: mul_46, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 117, Name: torch.ops.aten.mul.Tensor(primals_181, 0.9)
Input Tensors:
tensor180, Name: primals_181, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor446, Name: mul_47, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 118, Name: torch.ops.aten.add.Tensor(mul_46, mul_47)
Input Tensors:
tensor445, Name: mul_46, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor446, Name: mul_47, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor447, Name: add_34, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 119, Name: torch.ops.aten.mul.Tensor(mul_42, unsqueeze_25)
Input Tensors:
tensor440, Name: mul_42, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor19, Name: unsqueeze_25, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor448, Name: mul_48, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 120, Name: torch.ops.aten.add.Tensor(mul_48, unsqueeze_27)
Input Tensors:
tensor448, Name: mul_48, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor20, Name: unsqueeze_27, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor449, Name: add_35, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 121, Name: torch.ops.aten.relu.default(add_35)
Input Tensors:
tensor449, Name: add_35, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor450, Name: relu_5, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 122, Name: torch.ops.aten.convolution.default(relu_5, primals_22, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor450, Name: relu_5, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor21, Name: primals_22, Is global?: 1: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
Output Tensors:
tensor451, Name: convolution_7, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 123, Name: torch.ops.aten.add.Tensor(primals_185, 1)
Input Tensors:
tensor184, Name: primals_185, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor452, Name: add_36, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 124, Name: torch.ops.aten.var_mean.correction(convolution_7, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor451, Name: convolution_7, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor453, Name: getitem_16, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor454, Name: getitem_17, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 125, Name: torch.ops.aten.add.Tensor(getitem_16, 1e-05)
Input Tensors:
tensor453, Name: getitem_16, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor455, Name: add_37, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 126, Name: torch.ops.aten.rsqrt.default(add_37)
Input Tensors:
tensor455, Name: add_37, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor456, Name: rsqrt_7, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 127, Name: torch.ops.aten.sub.Tensor(convolution_7, getitem_17)
Input Tensors:
tensor451, Name: convolution_7, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor454, Name: getitem_17, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor457, Name: sub_7, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 128, Name: torch.ops.aten.mul.Tensor(sub_7, rsqrt_7)
Input Tensors:
tensor457, Name: sub_7, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor456, Name: rsqrt_7, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor458, Name: mul_49, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 129, Name: torch.ops.aten.mul.Tensor(squeeze_21, 0.1)
Input Tensors:
tensor454, Name: squeeze_21, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor459, Name: mul_50, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 130, Name: torch.ops.aten.mul.Tensor(primals_183, 0.9)
Input Tensors:
tensor182, Name: primals_183, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor460, Name: mul_51, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 131, Name: torch.ops.aten.add.Tensor(mul_50, mul_51)
Input Tensors:
tensor459, Name: mul_50, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor460, Name: mul_51, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor461, Name: add_38, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 132, Name: torch.ops.aten.mul.Tensor(squeeze_23, 1.0000049824865598)
Input Tensors:
tensor453, Name: squeeze_23, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor462, Name: mul_52, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 133, Name: torch.ops.aten.mul.Tensor(mul_52, 0.1)
Input Tensors:
tensor462, Name: mul_52, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor463, Name: mul_53, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 134, Name: torch.ops.aten.mul.Tensor(primals_184, 0.9)
Input Tensors:
tensor183, Name: primals_184, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor464, Name: mul_54, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 135, Name: torch.ops.aten.add.Tensor(mul_53, mul_54)
Input Tensors:
tensor463, Name: mul_53, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor464, Name: mul_54, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor465, Name: add_39, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 136, Name: torch.ops.aten.mul.Tensor(mul_49, unsqueeze_29)
Input Tensors:
tensor458, Name: mul_49, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor22, Name: unsqueeze_29, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor466, Name: mul_55, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 137, Name: torch.ops.aten.add.Tensor(mul_55, unsqueeze_31)
Input Tensors:
tensor466, Name: mul_55, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor23, Name: unsqueeze_31, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor467, Name: add_40, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 138, Name: torch.ops.aten.add.Tensor(add_40, relu_3)
Input Tensors:
tensor467, Name: add_40, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor414, Name: relu_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor468, Name: add_41, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 139, Name: torch.ops.aten.relu.default(add_41)
Input Tensors:
tensor468, Name: add_41, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor469, Name: relu_6, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 140, Name: torch.ops.aten.convolution.default(relu_6, primals_25, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor469, Name: relu_6, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor24, Name: primals_25, Is global?: 1: Size in byte: 65536, Dimensions: f32[64, 256, 1, 1]
Output Tensors:
tensor470, Name: convolution_8, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 141, Name: torch.ops.aten.add.Tensor(primals_188, 1)
Input Tensors:
tensor187, Name: primals_188, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor471, Name: add_42, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 142, Name: torch.ops.aten.var_mean.correction(convolution_8, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor470, Name: convolution_8, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor472, Name: getitem_18, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
tensor473, Name: getitem_19, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 143, Name: torch.ops.aten.add.Tensor(getitem_18, 1e-05)
Input Tensors:
tensor472, Name: getitem_18, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor474, Name: add_43, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 144, Name: torch.ops.aten.rsqrt.default(add_43)
Input Tensors:
tensor474, Name: add_43, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor475, Name: rsqrt_8, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 145, Name: torch.ops.aten.sub.Tensor(convolution_8, getitem_19)
Input Tensors:
tensor470, Name: convolution_8, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor473, Name: getitem_19, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor476, Name: sub_8, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 146, Name: torch.ops.aten.mul.Tensor(sub_8, rsqrt_8)
Input Tensors:
tensor476, Name: sub_8, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor475, Name: rsqrt_8, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor477, Name: mul_56, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 147, Name: torch.ops.aten.mul.Tensor(squeeze_24, 0.1)
Input Tensors:
tensor473, Name: squeeze_24, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor478, Name: mul_57, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 148, Name: torch.ops.aten.mul.Tensor(primals_186, 0.9)
Input Tensors:
tensor185, Name: primals_186, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor479, Name: mul_58, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 149, Name: torch.ops.aten.add.Tensor(mul_57, mul_58)
Input Tensors:
tensor478, Name: mul_57, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor479, Name: mul_58, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor480, Name: add_44, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 150, Name: torch.ops.aten.mul.Tensor(squeeze_26, 1.0000049824865598)
Input Tensors:
tensor472, Name: squeeze_26, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor481, Name: mul_59, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 151, Name: torch.ops.aten.mul.Tensor(mul_59, 0.1)
Input Tensors:
tensor481, Name: mul_59, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor482, Name: mul_60, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 152, Name: torch.ops.aten.mul.Tensor(primals_187, 0.9)
Input Tensors:
tensor186, Name: primals_187, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor483, Name: mul_61, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 153, Name: torch.ops.aten.add.Tensor(mul_60, mul_61)
Input Tensors:
tensor482, Name: mul_60, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor483, Name: mul_61, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor484, Name: add_45, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 154, Name: torch.ops.aten.mul.Tensor(mul_56, unsqueeze_33)
Input Tensors:
tensor477, Name: mul_56, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor25, Name: unsqueeze_33, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor485, Name: mul_62, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 155, Name: torch.ops.aten.add.Tensor(mul_62, unsqueeze_35)
Input Tensors:
tensor485, Name: mul_62, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor26, Name: unsqueeze_35, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor486, Name: add_46, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 156, Name: torch.ops.aten.relu.default(add_46)
Input Tensors:
tensor486, Name: add_46, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor487, Name: relu_7, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 157, Name: torch.ops.aten.convolution.default(relu_7, primals_28, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor487, Name: relu_7, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor27, Name: primals_28, Is global?: 1: Size in byte: 147456, Dimensions: f32[64, 64, 3, 3]
Output Tensors:
tensor488, Name: convolution_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 158, Name: torch.ops.aten.add.Tensor(primals_191, 1)
Input Tensors:
tensor190, Name: primals_191, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor489, Name: add_47, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 159, Name: torch.ops.aten.var_mean.correction(convolution_9, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor488, Name: convolution_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor490, Name: getitem_20, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
tensor491, Name: getitem_21, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 160, Name: torch.ops.aten.add.Tensor(getitem_20, 1e-05)
Input Tensors:
tensor490, Name: getitem_20, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor492, Name: add_48, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 161, Name: torch.ops.aten.rsqrt.default(add_48)
Input Tensors:
tensor492, Name: add_48, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor493, Name: rsqrt_9, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
____________________________________________________________________
Kernel ID: 162, Name: torch.ops.aten.sub.Tensor(convolution_9, getitem_21)
Input Tensors:
tensor488, Name: convolution_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor491, Name: getitem_21, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor494, Name: sub_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 163, Name: torch.ops.aten.mul.Tensor(sub_9, rsqrt_9)
Input Tensors:
tensor494, Name: sub_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor493, Name: rsqrt_9, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor495, Name: mul_63, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 164, Name: torch.ops.aten.mul.Tensor(squeeze_27, 0.1)
Input Tensors:
tensor491, Name: squeeze_27, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor496, Name: mul_64, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 165, Name: torch.ops.aten.mul.Tensor(primals_189, 0.9)
Input Tensors:
tensor188, Name: primals_189, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor497, Name: mul_65, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 166, Name: torch.ops.aten.add.Tensor(mul_64, mul_65)
Input Tensors:
tensor496, Name: mul_64, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor497, Name: mul_65, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor498, Name: add_49, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 167, Name: torch.ops.aten.mul.Tensor(squeeze_29, 1.0000049824865598)
Input Tensors:
tensor490, Name: squeeze_29, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor499, Name: mul_66, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 168, Name: torch.ops.aten.mul.Tensor(mul_66, 0.1)
Input Tensors:
tensor499, Name: mul_66, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor500, Name: mul_67, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 169, Name: torch.ops.aten.mul.Tensor(primals_190, 0.9)
Input Tensors:
tensor189, Name: primals_190, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor501, Name: mul_68, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 170, Name: torch.ops.aten.add.Tensor(mul_67, mul_68)
Input Tensors:
tensor500, Name: mul_67, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor501, Name: mul_68, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor502, Name: add_50, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 171, Name: torch.ops.aten.mul.Tensor(mul_63, unsqueeze_37)
Input Tensors:
tensor495, Name: mul_63, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor28, Name: unsqueeze_37, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor503, Name: mul_69, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 172, Name: torch.ops.aten.add.Tensor(mul_69, unsqueeze_39)
Input Tensors:
tensor503, Name: mul_69, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor29, Name: unsqueeze_39, Is global?: 1: Size in byte: 256, Dimensions: f32[64, 1, 1]
Output Tensors:
tensor504, Name: add_51, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 173, Name: torch.ops.aten.relu.default(add_51)
Input Tensors:
tensor504, Name: add_51, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor505, Name: relu_8, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 174, Name: torch.ops.aten.convolution.default(relu_8, primals_31, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor505, Name: relu_8, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor30, Name: primals_31, Is global?: 1: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
Output Tensors:
tensor506, Name: convolution_10, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 175, Name: torch.ops.aten.add.Tensor(primals_194, 1)
Input Tensors:
tensor193, Name: primals_194, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor507, Name: add_52, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 176, Name: torch.ops.aten.var_mean.correction(convolution_10, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor506, Name: convolution_10, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor508, Name: getitem_22, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor509, Name: getitem_23, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 177, Name: torch.ops.aten.add.Tensor(getitem_22, 1e-05)
Input Tensors:
tensor508, Name: getitem_22, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor510, Name: add_53, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 178, Name: torch.ops.aten.rsqrt.default(add_53)
Input Tensors:
tensor510, Name: add_53, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor511, Name: rsqrt_10, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 179, Name: torch.ops.aten.sub.Tensor(convolution_10, getitem_23)
Input Tensors:
tensor506, Name: convolution_10, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor509, Name: getitem_23, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor512, Name: sub_10, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 180, Name: torch.ops.aten.mul.Tensor(sub_10, rsqrt_10)
Input Tensors:
tensor512, Name: sub_10, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor511, Name: rsqrt_10, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor513, Name: mul_70, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 181, Name: torch.ops.aten.mul.Tensor(squeeze_30, 0.1)
Input Tensors:
tensor509, Name: squeeze_30, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor514, Name: mul_71, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 182, Name: torch.ops.aten.mul.Tensor(primals_192, 0.9)
Input Tensors:
tensor191, Name: primals_192, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor515, Name: mul_72, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 183, Name: torch.ops.aten.add.Tensor(mul_71, mul_72)
Input Tensors:
tensor514, Name: mul_71, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor515, Name: mul_72, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor516, Name: add_54, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 184, Name: torch.ops.aten.mul.Tensor(squeeze_32, 1.0000049824865598)
Input Tensors:
tensor508, Name: squeeze_32, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor517, Name: mul_73, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 185, Name: torch.ops.aten.mul.Tensor(mul_73, 0.1)
Input Tensors:
tensor517, Name: mul_73, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor518, Name: mul_74, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 186, Name: torch.ops.aten.mul.Tensor(primals_193, 0.9)
Input Tensors:
tensor192, Name: primals_193, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor519, Name: mul_75, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 187, Name: torch.ops.aten.add.Tensor(mul_74, mul_75)
Input Tensors:
tensor518, Name: mul_74, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor519, Name: mul_75, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor520, Name: add_55, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 188, Name: torch.ops.aten.mul.Tensor(mul_70, unsqueeze_41)
Input Tensors:
tensor513, Name: mul_70, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor31, Name: unsqueeze_41, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor521, Name: mul_76, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 189, Name: torch.ops.aten.add.Tensor(mul_76, unsqueeze_43)
Input Tensors:
tensor521, Name: mul_76, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor32, Name: unsqueeze_43, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor522, Name: add_56, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 190, Name: torch.ops.aten.add.Tensor(add_56, relu_6)
Input Tensors:
tensor522, Name: add_56, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor469, Name: relu_6, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor523, Name: add_57, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 191, Name: torch.ops.aten.relu.default(add_57)
Input Tensors:
tensor523, Name: add_57, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor524, Name: relu_9, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 192, Name: torch.ops.aten.convolution.default(relu_9, primals_34, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor524, Name: relu_9, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor33, Name: primals_34, Is global?: 1: Size in byte: 131072, Dimensions: f32[128, 256, 1, 1]
Output Tensors:
tensor525, Name: convolution_11, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 193, Name: torch.ops.aten.add.Tensor(primals_197, 1)
Input Tensors:
tensor196, Name: primals_197, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor526, Name: add_58, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 194, Name: torch.ops.aten.var_mean.correction(convolution_11, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor525, Name: convolution_11, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
Output Tensors:
tensor527, Name: getitem_24, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
tensor528, Name: getitem_25, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 195, Name: torch.ops.aten.add.Tensor(getitem_24, 1e-05)
Input Tensors:
tensor527, Name: getitem_24, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor529, Name: add_59, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 196, Name: torch.ops.aten.rsqrt.default(add_59)
Input Tensors:
tensor529, Name: add_59, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor530, Name: rsqrt_11, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 197, Name: torch.ops.aten.sub.Tensor(convolution_11, getitem_25)
Input Tensors:
tensor525, Name: convolution_11, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor528, Name: getitem_25, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor531, Name: sub_11, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 198, Name: torch.ops.aten.mul.Tensor(sub_11, rsqrt_11)
Input Tensors:
tensor531, Name: sub_11, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor530, Name: rsqrt_11, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor532, Name: mul_77, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 199, Name: torch.ops.aten.mul.Tensor(squeeze_33, 0.1)
Input Tensors:
tensor528, Name: squeeze_33, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor533, Name: mul_78, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 200, Name: torch.ops.aten.mul.Tensor(primals_195, 0.9)
Input Tensors:
tensor194, Name: primals_195, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor534, Name: mul_79, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 201, Name: torch.ops.aten.add.Tensor(mul_78, mul_79)
Input Tensors:
tensor533, Name: mul_78, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor534, Name: mul_79, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor535, Name: add_60, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 202, Name: torch.ops.aten.mul.Tensor(squeeze_35, 1.0000049824865598)
Input Tensors:
tensor527, Name: squeeze_35, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor536, Name: mul_80, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 203, Name: torch.ops.aten.mul.Tensor(mul_80, 0.1)
Input Tensors:
tensor536, Name: mul_80, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor537, Name: mul_81, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 204, Name: torch.ops.aten.mul.Tensor(primals_196, 0.9)
Input Tensors:
tensor195, Name: primals_196, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor538, Name: mul_82, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 205, Name: torch.ops.aten.add.Tensor(mul_81, mul_82)
Input Tensors:
tensor537, Name: mul_81, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor538, Name: mul_82, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor539, Name: add_61, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 206, Name: torch.ops.aten.mul.Tensor(mul_77, unsqueeze_45)
Input Tensors:
tensor532, Name: mul_77, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor34, Name: unsqueeze_45, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor540, Name: mul_83, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 207, Name: torch.ops.aten.add.Tensor(mul_83, unsqueeze_47)
Input Tensors:
tensor540, Name: mul_83, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor35, Name: unsqueeze_47, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor541, Name: add_62, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 208, Name: torch.ops.aten.relu.default(add_62)
Input Tensors:
tensor541, Name: add_62, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
Output Tensors:
tensor542, Name: relu_10, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 209, Name: torch.ops.aten.convolution.default(relu_10, primals_37, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor542, Name: relu_10, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor36, Name: primals_37, Is global?: 1: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
Output Tensors:
tensor543, Name: convolution_12, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 210, Name: torch.ops.aten.add.Tensor(primals_200, 1)
Input Tensors:
tensor199, Name: primals_200, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor544, Name: add_63, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 211, Name: torch.ops.aten.var_mean.correction(convolution_12, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor543, Name: convolution_12, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor545, Name: getitem_26, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
tensor546, Name: getitem_27, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 212, Name: torch.ops.aten.add.Tensor(getitem_26, 1e-05)
Input Tensors:
tensor545, Name: getitem_26, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor547, Name: add_64, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 213, Name: torch.ops.aten.rsqrt.default(add_64)
Input Tensors:
tensor547, Name: add_64, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor548, Name: rsqrt_12, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 214, Name: torch.ops.aten.sub.Tensor(convolution_12, getitem_27)
Input Tensors:
tensor543, Name: convolution_12, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor546, Name: getitem_27, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor549, Name: sub_12, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 215, Name: torch.ops.aten.mul.Tensor(sub_12, rsqrt_12)
Input Tensors:
tensor549, Name: sub_12, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor548, Name: rsqrt_12, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor550, Name: mul_84, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 216, Name: torch.ops.aten.mul.Tensor(squeeze_36, 0.1)
Input Tensors:
tensor546, Name: squeeze_36, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor551, Name: mul_85, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 217, Name: torch.ops.aten.mul.Tensor(primals_198, 0.9)
Input Tensors:
tensor197, Name: primals_198, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor552, Name: mul_86, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 218, Name: torch.ops.aten.add.Tensor(mul_85, mul_86)
Input Tensors:
tensor551, Name: mul_85, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor552, Name: mul_86, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor553, Name: add_65, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 219, Name: torch.ops.aten.mul.Tensor(squeeze_38, 1.0000199302441455)
Input Tensors:
tensor545, Name: squeeze_38, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor554, Name: mul_87, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 220, Name: torch.ops.aten.mul.Tensor(mul_87, 0.1)
Input Tensors:
tensor554, Name: mul_87, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor555, Name: mul_88, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 221, Name: torch.ops.aten.mul.Tensor(primals_199, 0.9)
Input Tensors:
tensor198, Name: primals_199, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor556, Name: mul_89, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 222, Name: torch.ops.aten.add.Tensor(mul_88, mul_89)
Input Tensors:
tensor555, Name: mul_88, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor556, Name: mul_89, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor557, Name: add_66, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 223, Name: torch.ops.aten.mul.Tensor(mul_84, unsqueeze_49)
Input Tensors:
tensor550, Name: mul_84, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor37, Name: unsqueeze_49, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor558, Name: mul_90, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 224, Name: torch.ops.aten.add.Tensor(mul_90, unsqueeze_51)
Input Tensors:
tensor558, Name: mul_90, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor38, Name: unsqueeze_51, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor559, Name: add_67, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 225, Name: torch.ops.aten.relu.default(add_67)
Input Tensors:
tensor559, Name: add_67, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor560, Name: relu_11, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 226, Name: torch.ops.aten.convolution.default(relu_11, primals_40, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor560, Name: relu_11, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor39, Name: primals_40, Is global?: 1: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
Output Tensors:
tensor561, Name: convolution_13, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 227, Name: torch.ops.aten.add.Tensor(primals_203, 1)
Input Tensors:
tensor202, Name: primals_203, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor562, Name: add_68, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 228, Name: torch.ops.aten.var_mean.correction(convolution_13, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor561, Name: convolution_13, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor563, Name: getitem_28, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor564, Name: getitem_29, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 229, Name: torch.ops.aten.add.Tensor(getitem_28, 1e-05)
Input Tensors:
tensor563, Name: getitem_28, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor565, Name: add_69, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 230, Name: torch.ops.aten.rsqrt.default(add_69)
Input Tensors:
tensor565, Name: add_69, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor566, Name: rsqrt_13, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 231, Name: torch.ops.aten.sub.Tensor(convolution_13, getitem_29)
Input Tensors:
tensor561, Name: convolution_13, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor564, Name: getitem_29, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor567, Name: sub_13, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 232, Name: torch.ops.aten.mul.Tensor(sub_13, rsqrt_13)
Input Tensors:
tensor567, Name: sub_13, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor566, Name: rsqrt_13, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor568, Name: mul_91, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 233, Name: torch.ops.aten.mul.Tensor(squeeze_39, 0.1)
Input Tensors:
tensor564, Name: squeeze_39, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor569, Name: mul_92, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 234, Name: torch.ops.aten.mul.Tensor(primals_201, 0.9)
Input Tensors:
tensor200, Name: primals_201, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor570, Name: mul_93, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 235, Name: torch.ops.aten.add.Tensor(mul_92, mul_93)
Input Tensors:
tensor569, Name: mul_92, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor570, Name: mul_93, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor571, Name: add_70, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 236, Name: torch.ops.aten.mul.Tensor(squeeze_41, 1.0000199302441455)
Input Tensors:
tensor563, Name: squeeze_41, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor572, Name: mul_94, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 237, Name: torch.ops.aten.mul.Tensor(mul_94, 0.1)
Input Tensors:
tensor572, Name: mul_94, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor573, Name: mul_95, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 238, Name: torch.ops.aten.mul.Tensor(primals_202, 0.9)
Input Tensors:
tensor201, Name: primals_202, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor574, Name: mul_96, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 239, Name: torch.ops.aten.add.Tensor(mul_95, mul_96)
Input Tensors:
tensor573, Name: mul_95, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor574, Name: mul_96, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor575, Name: add_71, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 240, Name: torch.ops.aten.mul.Tensor(mul_91, unsqueeze_53)
Input Tensors:
tensor568, Name: mul_91, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor40, Name: unsqueeze_53, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor576, Name: mul_97, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 241, Name: torch.ops.aten.add.Tensor(mul_97, unsqueeze_55)
Input Tensors:
tensor576, Name: mul_97, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor41, Name: unsqueeze_55, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor577, Name: add_72, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 242, Name: torch.ops.aten.convolution.default(relu_9, primals_43, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor524, Name: relu_9, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor42, Name: primals_43, Is global?: 1: Size in byte: 524288, Dimensions: f32[512, 256, 1, 1]
Output Tensors:
tensor578, Name: convolution_14, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 243, Name: torch.ops.aten.add.Tensor(primals_206, 1)
Input Tensors:
tensor205, Name: primals_206, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor579, Name: add_73, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 244, Name: torch.ops.aten.var_mean.correction(convolution_14, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor578, Name: convolution_14, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor580, Name: getitem_30, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor581, Name: getitem_31, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 245, Name: torch.ops.aten.add.Tensor(getitem_30, 1e-05)
Input Tensors:
tensor580, Name: getitem_30, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor582, Name: add_74, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 246, Name: torch.ops.aten.rsqrt.default(add_74)
Input Tensors:
tensor582, Name: add_74, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor583, Name: rsqrt_14, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 247, Name: torch.ops.aten.sub.Tensor(convolution_14, getitem_31)
Input Tensors:
tensor578, Name: convolution_14, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor581, Name: getitem_31, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor584, Name: sub_14, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 248, Name: torch.ops.aten.mul.Tensor(sub_14, rsqrt_14)
Input Tensors:
tensor584, Name: sub_14, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor583, Name: rsqrt_14, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor585, Name: mul_98, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 249, Name: torch.ops.aten.mul.Tensor(squeeze_42, 0.1)
Input Tensors:
tensor581, Name: squeeze_42, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor586, Name: mul_99, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 250, Name: torch.ops.aten.mul.Tensor(primals_204, 0.9)
Input Tensors:
tensor203, Name: primals_204, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor587, Name: mul_100, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 251, Name: torch.ops.aten.add.Tensor(mul_99, mul_100)
Input Tensors:
tensor586, Name: mul_99, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor587, Name: mul_100, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor588, Name: add_75, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 252, Name: torch.ops.aten.mul.Tensor(squeeze_44, 1.0000199302441455)
Input Tensors:
tensor580, Name: squeeze_44, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor589, Name: mul_101, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 253, Name: torch.ops.aten.mul.Tensor(mul_101, 0.1)
Input Tensors:
tensor589, Name: mul_101, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor590, Name: mul_102, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 254, Name: torch.ops.aten.mul.Tensor(primals_205, 0.9)
Input Tensors:
tensor204, Name: primals_205, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor591, Name: mul_103, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 255, Name: torch.ops.aten.add.Tensor(mul_102, mul_103)
Input Tensors:
tensor590, Name: mul_102, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor591, Name: mul_103, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor592, Name: add_76, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 256, Name: torch.ops.aten.mul.Tensor(mul_98, unsqueeze_57)
Input Tensors:
tensor585, Name: mul_98, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor43, Name: unsqueeze_57, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor593, Name: mul_104, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 257, Name: torch.ops.aten.add.Tensor(mul_104, unsqueeze_59)
Input Tensors:
tensor593, Name: mul_104, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor44, Name: unsqueeze_59, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor594, Name: add_77, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 258, Name: torch.ops.aten.add.Tensor(add_72, add_77)
Input Tensors:
tensor577, Name: add_72, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor594, Name: add_77, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor595, Name: add_78, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 259, Name: torch.ops.aten.relu.default(add_78)
Input Tensors:
tensor595, Name: add_78, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor596, Name: relu_12, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 260, Name: torch.ops.aten.convolution.default(relu_12, primals_46, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor596, Name: relu_12, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor45, Name: primals_46, Is global?: 1: Size in byte: 262144, Dimensions: f32[128, 512, 1, 1]
Output Tensors:
tensor597, Name: convolution_15, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 261, Name: torch.ops.aten.add.Tensor(primals_209, 1)
Input Tensors:
tensor208, Name: primals_209, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor598, Name: add_79, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 262, Name: torch.ops.aten.var_mean.correction(convolution_15, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor597, Name: convolution_15, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor599, Name: getitem_32, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
tensor600, Name: getitem_33, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 263, Name: torch.ops.aten.add.Tensor(getitem_32, 1e-05)
Input Tensors:
tensor599, Name: getitem_32, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor601, Name: add_80, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 264, Name: torch.ops.aten.rsqrt.default(add_80)
Input Tensors:
tensor601, Name: add_80, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor602, Name: rsqrt_15, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 265, Name: torch.ops.aten.sub.Tensor(convolution_15, getitem_33)
Input Tensors:
tensor597, Name: convolution_15, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor600, Name: getitem_33, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor603, Name: sub_15, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 266, Name: torch.ops.aten.mul.Tensor(sub_15, rsqrt_15)
Input Tensors:
tensor603, Name: sub_15, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor602, Name: rsqrt_15, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor604, Name: mul_105, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 267, Name: torch.ops.aten.mul.Tensor(squeeze_45, 0.1)
Input Tensors:
tensor600, Name: squeeze_45, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor605, Name: mul_106, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 268, Name: torch.ops.aten.mul.Tensor(primals_207, 0.9)
Input Tensors:
tensor206, Name: primals_207, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor606, Name: mul_107, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 269, Name: torch.ops.aten.add.Tensor(mul_106, mul_107)
Input Tensors:
tensor605, Name: mul_106, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor606, Name: mul_107, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor607, Name: add_81, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 270, Name: torch.ops.aten.mul.Tensor(squeeze_47, 1.0000199302441455)
Input Tensors:
tensor599, Name: squeeze_47, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor608, Name: mul_108, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 271, Name: torch.ops.aten.mul.Tensor(mul_108, 0.1)
Input Tensors:
tensor608, Name: mul_108, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor609, Name: mul_109, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 272, Name: torch.ops.aten.mul.Tensor(primals_208, 0.9)
Input Tensors:
tensor207, Name: primals_208, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor610, Name: mul_110, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 273, Name: torch.ops.aten.add.Tensor(mul_109, mul_110)
Input Tensors:
tensor609, Name: mul_109, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor610, Name: mul_110, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor611, Name: add_82, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 274, Name: torch.ops.aten.mul.Tensor(mul_105, unsqueeze_61)
Input Tensors:
tensor604, Name: mul_105, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor46, Name: unsqueeze_61, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor612, Name: mul_111, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 275, Name: torch.ops.aten.add.Tensor(mul_111, unsqueeze_63)
Input Tensors:
tensor612, Name: mul_111, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor47, Name: unsqueeze_63, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor613, Name: add_83, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 276, Name: torch.ops.aten.relu.default(add_83)
Input Tensors:
tensor613, Name: add_83, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor614, Name: relu_13, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 277, Name: torch.ops.aten.convolution.default(relu_13, primals_49, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor614, Name: relu_13, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor48, Name: primals_49, Is global?: 1: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
Output Tensors:
tensor615, Name: convolution_16, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 278, Name: torch.ops.aten.add.Tensor(primals_212, 1)
Input Tensors:
tensor211, Name: primals_212, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor616, Name: add_84, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 279, Name: torch.ops.aten.var_mean.correction(convolution_16, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor615, Name: convolution_16, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor617, Name: getitem_34, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
tensor618, Name: getitem_35, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 280, Name: torch.ops.aten.add.Tensor(getitem_34, 1e-05)
Input Tensors:
tensor617, Name: getitem_34, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor619, Name: add_85, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 281, Name: torch.ops.aten.rsqrt.default(add_85)
Input Tensors:
tensor619, Name: add_85, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor620, Name: rsqrt_16, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 282, Name: torch.ops.aten.sub.Tensor(convolution_16, getitem_35)
Input Tensors:
tensor615, Name: convolution_16, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor618, Name: getitem_35, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor621, Name: sub_16, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 283, Name: torch.ops.aten.mul.Tensor(sub_16, rsqrt_16)
Input Tensors:
tensor621, Name: sub_16, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor620, Name: rsqrt_16, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor622, Name: mul_112, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 284, Name: torch.ops.aten.mul.Tensor(squeeze_48, 0.1)
Input Tensors:
tensor618, Name: squeeze_48, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor623, Name: mul_113, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 285, Name: torch.ops.aten.mul.Tensor(primals_210, 0.9)
Input Tensors:
tensor209, Name: primals_210, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor624, Name: mul_114, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 286, Name: torch.ops.aten.add.Tensor(mul_113, mul_114)
Input Tensors:
tensor623, Name: mul_113, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor624, Name: mul_114, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor625, Name: add_86, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 287, Name: torch.ops.aten.mul.Tensor(squeeze_50, 1.0000199302441455)
Input Tensors:
tensor617, Name: squeeze_50, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor626, Name: mul_115, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 288, Name: torch.ops.aten.mul.Tensor(mul_115, 0.1)
Input Tensors:
tensor626, Name: mul_115, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor627, Name: mul_116, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 289, Name: torch.ops.aten.mul.Tensor(primals_211, 0.9)
Input Tensors:
tensor210, Name: primals_211, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor628, Name: mul_117, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 290, Name: torch.ops.aten.add.Tensor(mul_116, mul_117)
Input Tensors:
tensor627, Name: mul_116, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor628, Name: mul_117, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor629, Name: add_87, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 291, Name: torch.ops.aten.mul.Tensor(mul_112, unsqueeze_65)
Input Tensors:
tensor622, Name: mul_112, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor49, Name: unsqueeze_65, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor630, Name: mul_118, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 292, Name: torch.ops.aten.add.Tensor(mul_118, unsqueeze_67)
Input Tensors:
tensor630, Name: mul_118, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor50, Name: unsqueeze_67, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor631, Name: add_88, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 293, Name: torch.ops.aten.relu.default(add_88)
Input Tensors:
tensor631, Name: add_88, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor632, Name: relu_14, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 294, Name: torch.ops.aten.convolution.default(relu_14, primals_52, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor632, Name: relu_14, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor51, Name: primals_52, Is global?: 1: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
Output Tensors:
tensor633, Name: convolution_17, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 295, Name: torch.ops.aten.add.Tensor(primals_215, 1)
Input Tensors:
tensor214, Name: primals_215, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor634, Name: add_89, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 296, Name: torch.ops.aten.var_mean.correction(convolution_17, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor633, Name: convolution_17, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor635, Name: getitem_36, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor636, Name: getitem_37, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 297, Name: torch.ops.aten.add.Tensor(getitem_36, 1e-05)
Input Tensors:
tensor635, Name: getitem_36, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor637, Name: add_90, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 298, Name: torch.ops.aten.rsqrt.default(add_90)
Input Tensors:
tensor637, Name: add_90, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor638, Name: rsqrt_17, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 299, Name: torch.ops.aten.sub.Tensor(convolution_17, getitem_37)
Input Tensors:
tensor633, Name: convolution_17, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor636, Name: getitem_37, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor639, Name: sub_17, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 300, Name: torch.ops.aten.mul.Tensor(sub_17, rsqrt_17)
Input Tensors:
tensor639, Name: sub_17, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor638, Name: rsqrt_17, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor640, Name: mul_119, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 301, Name: torch.ops.aten.mul.Tensor(squeeze_51, 0.1)
Input Tensors:
tensor636, Name: squeeze_51, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor641, Name: mul_120, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 302, Name: torch.ops.aten.mul.Tensor(primals_213, 0.9)
Input Tensors:
tensor212, Name: primals_213, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor642, Name: mul_121, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 303, Name: torch.ops.aten.add.Tensor(mul_120, mul_121)
Input Tensors:
tensor641, Name: mul_120, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor642, Name: mul_121, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor643, Name: add_91, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 304, Name: torch.ops.aten.mul.Tensor(squeeze_53, 1.0000199302441455)
Input Tensors:
tensor635, Name: squeeze_53, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor644, Name: mul_122, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 305, Name: torch.ops.aten.mul.Tensor(mul_122, 0.1)
Input Tensors:
tensor644, Name: mul_122, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor645, Name: mul_123, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 306, Name: torch.ops.aten.mul.Tensor(primals_214, 0.9)
Input Tensors:
tensor213, Name: primals_214, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor646, Name: mul_124, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 307, Name: torch.ops.aten.add.Tensor(mul_123, mul_124)
Input Tensors:
tensor645, Name: mul_123, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor646, Name: mul_124, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor647, Name: add_92, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 308, Name: torch.ops.aten.mul.Tensor(mul_119, unsqueeze_69)
Input Tensors:
tensor640, Name: mul_119, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor52, Name: unsqueeze_69, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor648, Name: mul_125, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 309, Name: torch.ops.aten.add.Tensor(mul_125, unsqueeze_71)
Input Tensors:
tensor648, Name: mul_125, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor53, Name: unsqueeze_71, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor649, Name: add_93, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 310, Name: torch.ops.aten.add.Tensor(add_93, relu_12)
Input Tensors:
tensor649, Name: add_93, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor596, Name: relu_12, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor650, Name: add_94, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 311, Name: torch.ops.aten.relu.default(add_94)
Input Tensors:
tensor650, Name: add_94, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor651, Name: relu_15, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 312, Name: torch.ops.aten.convolution.default(relu_15, primals_55, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor651, Name: relu_15, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor54, Name: primals_55, Is global?: 1: Size in byte: 262144, Dimensions: f32[128, 512, 1, 1]
Output Tensors:
tensor652, Name: convolution_18, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 313, Name: torch.ops.aten.add.Tensor(primals_218, 1)
Input Tensors:
tensor217, Name: primals_218, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor653, Name: add_95, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 314, Name: torch.ops.aten.var_mean.correction(convolution_18, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor652, Name: convolution_18, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor654, Name: getitem_38, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
tensor655, Name: getitem_39, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 315, Name: torch.ops.aten.add.Tensor(getitem_38, 1e-05)
Input Tensors:
tensor654, Name: getitem_38, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor656, Name: add_96, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 316, Name: torch.ops.aten.rsqrt.default(add_96)
Input Tensors:
tensor656, Name: add_96, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor657, Name: rsqrt_18, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 317, Name: torch.ops.aten.sub.Tensor(convolution_18, getitem_39)
Input Tensors:
tensor652, Name: convolution_18, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor655, Name: getitem_39, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor658, Name: sub_18, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 318, Name: torch.ops.aten.mul.Tensor(sub_18, rsqrt_18)
Input Tensors:
tensor658, Name: sub_18, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor657, Name: rsqrt_18, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor659, Name: mul_126, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 319, Name: torch.ops.aten.mul.Tensor(squeeze_54, 0.1)
Input Tensors:
tensor655, Name: squeeze_54, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor660, Name: mul_127, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 320, Name: torch.ops.aten.mul.Tensor(primals_216, 0.9)
Input Tensors:
tensor215, Name: primals_216, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor661, Name: mul_128, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 321, Name: torch.ops.aten.add.Tensor(mul_127, mul_128)
Input Tensors:
tensor660, Name: mul_127, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor661, Name: mul_128, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor662, Name: add_97, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 322, Name: torch.ops.aten.mul.Tensor(squeeze_56, 1.0000199302441455)
Input Tensors:
tensor654, Name: squeeze_56, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor663, Name: mul_129, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 323, Name: torch.ops.aten.mul.Tensor(mul_129, 0.1)
Input Tensors:
tensor663, Name: mul_129, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor664, Name: mul_130, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 324, Name: torch.ops.aten.mul.Tensor(primals_217, 0.9)
Input Tensors:
tensor216, Name: primals_217, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor665, Name: mul_131, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 325, Name: torch.ops.aten.add.Tensor(mul_130, mul_131)
Input Tensors:
tensor664, Name: mul_130, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor665, Name: mul_131, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor666, Name: add_98, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 326, Name: torch.ops.aten.mul.Tensor(mul_126, unsqueeze_73)
Input Tensors:
tensor659, Name: mul_126, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor55, Name: unsqueeze_73, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor667, Name: mul_132, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 327, Name: torch.ops.aten.add.Tensor(mul_132, unsqueeze_75)
Input Tensors:
tensor667, Name: mul_132, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor56, Name: unsqueeze_75, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor668, Name: add_99, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 328, Name: torch.ops.aten.relu.default(add_99)
Input Tensors:
tensor668, Name: add_99, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor669, Name: relu_16, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 329, Name: torch.ops.aten.convolution.default(relu_16, primals_58, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor669, Name: relu_16, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor57, Name: primals_58, Is global?: 1: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
Output Tensors:
tensor670, Name: convolution_19, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 330, Name: torch.ops.aten.add.Tensor(primals_221, 1)
Input Tensors:
tensor220, Name: primals_221, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor671, Name: add_100, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 331, Name: torch.ops.aten.var_mean.correction(convolution_19, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor670, Name: convolution_19, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor672, Name: getitem_40, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
tensor673, Name: getitem_41, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 332, Name: torch.ops.aten.add.Tensor(getitem_40, 1e-05)
Input Tensors:
tensor672, Name: getitem_40, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor674, Name: add_101, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 333, Name: torch.ops.aten.rsqrt.default(add_101)
Input Tensors:
tensor674, Name: add_101, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor675, Name: rsqrt_19, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 334, Name: torch.ops.aten.sub.Tensor(convolution_19, getitem_41)
Input Tensors:
tensor670, Name: convolution_19, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor673, Name: getitem_41, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor676, Name: sub_19, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 335, Name: torch.ops.aten.mul.Tensor(sub_19, rsqrt_19)
Input Tensors:
tensor676, Name: sub_19, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor675, Name: rsqrt_19, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor677, Name: mul_133, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 336, Name: torch.ops.aten.mul.Tensor(squeeze_57, 0.1)
Input Tensors:
tensor673, Name: squeeze_57, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor678, Name: mul_134, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 337, Name: torch.ops.aten.mul.Tensor(primals_219, 0.9)
Input Tensors:
tensor218, Name: primals_219, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor679, Name: mul_135, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 338, Name: torch.ops.aten.add.Tensor(mul_134, mul_135)
Input Tensors:
tensor678, Name: mul_134, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor679, Name: mul_135, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor680, Name: add_102, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 339, Name: torch.ops.aten.mul.Tensor(squeeze_59, 1.0000199302441455)
Input Tensors:
tensor672, Name: squeeze_59, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor681, Name: mul_136, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 340, Name: torch.ops.aten.mul.Tensor(mul_136, 0.1)
Input Tensors:
tensor681, Name: mul_136, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor682, Name: mul_137, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 341, Name: torch.ops.aten.mul.Tensor(primals_220, 0.9)
Input Tensors:
tensor219, Name: primals_220, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor683, Name: mul_138, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 342, Name: torch.ops.aten.add.Tensor(mul_137, mul_138)
Input Tensors:
tensor682, Name: mul_137, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor683, Name: mul_138, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor684, Name: add_103, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 343, Name: torch.ops.aten.mul.Tensor(mul_133, unsqueeze_77)
Input Tensors:
tensor677, Name: mul_133, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor58, Name: unsqueeze_77, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor685, Name: mul_139, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 344, Name: torch.ops.aten.add.Tensor(mul_139, unsqueeze_79)
Input Tensors:
tensor685, Name: mul_139, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor59, Name: unsqueeze_79, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor686, Name: add_104, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 345, Name: torch.ops.aten.relu.default(add_104)
Input Tensors:
tensor686, Name: add_104, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor687, Name: relu_17, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 346, Name: torch.ops.aten.convolution.default(relu_17, primals_61, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor687, Name: relu_17, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor60, Name: primals_61, Is global?: 1: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
Output Tensors:
tensor688, Name: convolution_20, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 347, Name: torch.ops.aten.add.Tensor(primals_224, 1)
Input Tensors:
tensor223, Name: primals_224, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor689, Name: add_105, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 348, Name: torch.ops.aten.var_mean.correction(convolution_20, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor688, Name: convolution_20, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor690, Name: getitem_42, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor691, Name: getitem_43, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 349, Name: torch.ops.aten.add.Tensor(getitem_42, 1e-05)
Input Tensors:
tensor690, Name: getitem_42, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor692, Name: add_106, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 350, Name: torch.ops.aten.rsqrt.default(add_106)
Input Tensors:
tensor692, Name: add_106, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor693, Name: rsqrt_20, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 351, Name: torch.ops.aten.sub.Tensor(convolution_20, getitem_43)
Input Tensors:
tensor688, Name: convolution_20, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor691, Name: getitem_43, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor694, Name: sub_20, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 352, Name: torch.ops.aten.mul.Tensor(sub_20, rsqrt_20)
Input Tensors:
tensor694, Name: sub_20, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor693, Name: rsqrt_20, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor695, Name: mul_140, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 353, Name: torch.ops.aten.mul.Tensor(squeeze_60, 0.1)
Input Tensors:
tensor691, Name: squeeze_60, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor696, Name: mul_141, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 354, Name: torch.ops.aten.mul.Tensor(primals_222, 0.9)
Input Tensors:
tensor221, Name: primals_222, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor697, Name: mul_142, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 355, Name: torch.ops.aten.add.Tensor(mul_141, mul_142)
Input Tensors:
tensor696, Name: mul_141, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor697, Name: mul_142, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor698, Name: add_107, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 356, Name: torch.ops.aten.mul.Tensor(squeeze_62, 1.0000199302441455)
Input Tensors:
tensor690, Name: squeeze_62, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor699, Name: mul_143, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 357, Name: torch.ops.aten.mul.Tensor(mul_143, 0.1)
Input Tensors:
tensor699, Name: mul_143, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor700, Name: mul_144, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 358, Name: torch.ops.aten.mul.Tensor(primals_223, 0.9)
Input Tensors:
tensor222, Name: primals_223, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor701, Name: mul_145, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 359, Name: torch.ops.aten.add.Tensor(mul_144, mul_145)
Input Tensors:
tensor700, Name: mul_144, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor701, Name: mul_145, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor702, Name: add_108, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 360, Name: torch.ops.aten.mul.Tensor(mul_140, unsqueeze_81)
Input Tensors:
tensor695, Name: mul_140, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor61, Name: unsqueeze_81, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor703, Name: mul_146, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 361, Name: torch.ops.aten.add.Tensor(mul_146, unsqueeze_83)
Input Tensors:
tensor703, Name: mul_146, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor62, Name: unsqueeze_83, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor704, Name: add_109, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 362, Name: torch.ops.aten.add.Tensor(add_109, relu_15)
Input Tensors:
tensor704, Name: add_109, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor651, Name: relu_15, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor705, Name: add_110, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 363, Name: torch.ops.aten.relu.default(add_110)
Input Tensors:
tensor705, Name: add_110, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor706, Name: relu_18, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 364, Name: torch.ops.aten.convolution.default(relu_18, primals_64, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor706, Name: relu_18, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor63, Name: primals_64, Is global?: 1: Size in byte: 262144, Dimensions: f32[128, 512, 1, 1]
Output Tensors:
tensor707, Name: convolution_21, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 365, Name: torch.ops.aten.add.Tensor(primals_227, 1)
Input Tensors:
tensor226, Name: primals_227, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor708, Name: add_111, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 366, Name: torch.ops.aten.var_mean.correction(convolution_21, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor707, Name: convolution_21, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor709, Name: getitem_44, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
tensor710, Name: getitem_45, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 367, Name: torch.ops.aten.add.Tensor(getitem_44, 1e-05)
Input Tensors:
tensor709, Name: getitem_44, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor711, Name: add_112, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 368, Name: torch.ops.aten.rsqrt.default(add_112)
Input Tensors:
tensor711, Name: add_112, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor712, Name: rsqrt_21, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 369, Name: torch.ops.aten.sub.Tensor(convolution_21, getitem_45)
Input Tensors:
tensor707, Name: convolution_21, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor710, Name: getitem_45, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor713, Name: sub_21, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 370, Name: torch.ops.aten.mul.Tensor(sub_21, rsqrt_21)
Input Tensors:
tensor713, Name: sub_21, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor712, Name: rsqrt_21, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor714, Name: mul_147, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 371, Name: torch.ops.aten.mul.Tensor(squeeze_63, 0.1)
Input Tensors:
tensor710, Name: squeeze_63, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor715, Name: mul_148, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 372, Name: torch.ops.aten.mul.Tensor(primals_225, 0.9)
Input Tensors:
tensor224, Name: primals_225, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor716, Name: mul_149, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 373, Name: torch.ops.aten.add.Tensor(mul_148, mul_149)
Input Tensors:
tensor715, Name: mul_148, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor716, Name: mul_149, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor717, Name: add_113, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 374, Name: torch.ops.aten.mul.Tensor(squeeze_65, 1.0000199302441455)
Input Tensors:
tensor709, Name: squeeze_65, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor718, Name: mul_150, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 375, Name: torch.ops.aten.mul.Tensor(mul_150, 0.1)
Input Tensors:
tensor718, Name: mul_150, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor719, Name: mul_151, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 376, Name: torch.ops.aten.mul.Tensor(primals_226, 0.9)
Input Tensors:
tensor225, Name: primals_226, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor720, Name: mul_152, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 377, Name: torch.ops.aten.add.Tensor(mul_151, mul_152)
Input Tensors:
tensor719, Name: mul_151, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor720, Name: mul_152, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor721, Name: add_114, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 378, Name: torch.ops.aten.mul.Tensor(mul_147, unsqueeze_85)
Input Tensors:
tensor714, Name: mul_147, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor64, Name: unsqueeze_85, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor722, Name: mul_153, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 379, Name: torch.ops.aten.add.Tensor(mul_153, unsqueeze_87)
Input Tensors:
tensor722, Name: mul_153, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor65, Name: unsqueeze_87, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor723, Name: add_115, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 380, Name: torch.ops.aten.relu.default(add_115)
Input Tensors:
tensor723, Name: add_115, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor724, Name: relu_19, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 381, Name: torch.ops.aten.convolution.default(relu_19, primals_67, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor724, Name: relu_19, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor66, Name: primals_67, Is global?: 1: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
Output Tensors:
tensor725, Name: convolution_22, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 382, Name: torch.ops.aten.add.Tensor(primals_230, 1)
Input Tensors:
tensor229, Name: primals_230, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor726, Name: add_116, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 383, Name: torch.ops.aten.var_mean.correction(convolution_22, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor725, Name: convolution_22, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor727, Name: getitem_46, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
tensor728, Name: getitem_47, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 384, Name: torch.ops.aten.add.Tensor(getitem_46, 1e-05)
Input Tensors:
tensor727, Name: getitem_46, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor729, Name: add_117, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 385, Name: torch.ops.aten.rsqrt.default(add_117)
Input Tensors:
tensor729, Name: add_117, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor730, Name: rsqrt_22, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
____________________________________________________________________
Kernel ID: 386, Name: torch.ops.aten.sub.Tensor(convolution_22, getitem_47)
Input Tensors:
tensor725, Name: convolution_22, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor728, Name: getitem_47, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor731, Name: sub_22, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 387, Name: torch.ops.aten.mul.Tensor(sub_22, rsqrt_22)
Input Tensors:
tensor731, Name: sub_22, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor730, Name: rsqrt_22, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor732, Name: mul_154, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 388, Name: torch.ops.aten.mul.Tensor(squeeze_66, 0.1)
Input Tensors:
tensor728, Name: squeeze_66, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor733, Name: mul_155, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 389, Name: torch.ops.aten.mul.Tensor(primals_228, 0.9)
Input Tensors:
tensor227, Name: primals_228, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor734, Name: mul_156, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 390, Name: torch.ops.aten.add.Tensor(mul_155, mul_156)
Input Tensors:
tensor733, Name: mul_155, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor734, Name: mul_156, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor735, Name: add_118, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 391, Name: torch.ops.aten.mul.Tensor(squeeze_68, 1.0000199302441455)
Input Tensors:
tensor727, Name: squeeze_68, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor736, Name: mul_157, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 392, Name: torch.ops.aten.mul.Tensor(mul_157, 0.1)
Input Tensors:
tensor736, Name: mul_157, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor737, Name: mul_158, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 393, Name: torch.ops.aten.mul.Tensor(primals_229, 0.9)
Input Tensors:
tensor228, Name: primals_229, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor738, Name: mul_159, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 394, Name: torch.ops.aten.add.Tensor(mul_158, mul_159)
Input Tensors:
tensor737, Name: mul_158, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor738, Name: mul_159, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor739, Name: add_119, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 395, Name: torch.ops.aten.mul.Tensor(mul_154, unsqueeze_89)
Input Tensors:
tensor732, Name: mul_154, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor67, Name: unsqueeze_89, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor740, Name: mul_160, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 396, Name: torch.ops.aten.add.Tensor(mul_160, unsqueeze_91)
Input Tensors:
tensor740, Name: mul_160, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor68, Name: unsqueeze_91, Is global?: 1: Size in byte: 512, Dimensions: f32[128, 1, 1]
Output Tensors:
tensor741, Name: add_120, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 397, Name: torch.ops.aten.relu.default(add_120)
Input Tensors:
tensor741, Name: add_120, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor742, Name: relu_20, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 398, Name: torch.ops.aten.convolution.default(relu_20, primals_70, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor742, Name: relu_20, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor69, Name: primals_70, Is global?: 1: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
Output Tensors:
tensor743, Name: convolution_23, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 399, Name: torch.ops.aten.add.Tensor(primals_233, 1)
Input Tensors:
tensor232, Name: primals_233, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor744, Name: add_121, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 400, Name: torch.ops.aten.var_mean.correction(convolution_23, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor743, Name: convolution_23, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor745, Name: getitem_48, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor746, Name: getitem_49, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 401, Name: torch.ops.aten.add.Tensor(getitem_48, 1e-05)
Input Tensors:
tensor745, Name: getitem_48, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor747, Name: add_122, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 402, Name: torch.ops.aten.rsqrt.default(add_122)
Input Tensors:
tensor747, Name: add_122, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor748, Name: rsqrt_23, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 403, Name: torch.ops.aten.sub.Tensor(convolution_23, getitem_49)
Input Tensors:
tensor743, Name: convolution_23, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor746, Name: getitem_49, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor749, Name: sub_23, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 404, Name: torch.ops.aten.mul.Tensor(sub_23, rsqrt_23)
Input Tensors:
tensor749, Name: sub_23, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor748, Name: rsqrt_23, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor750, Name: mul_161, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 405, Name: torch.ops.aten.mul.Tensor(squeeze_69, 0.1)
Input Tensors:
tensor746, Name: squeeze_69, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor751, Name: mul_162, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 406, Name: torch.ops.aten.mul.Tensor(primals_231, 0.9)
Input Tensors:
tensor230, Name: primals_231, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor752, Name: mul_163, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 407, Name: torch.ops.aten.add.Tensor(mul_162, mul_163)
Input Tensors:
tensor751, Name: mul_162, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor752, Name: mul_163, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor753, Name: add_123, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 408, Name: torch.ops.aten.mul.Tensor(squeeze_71, 1.0000199302441455)
Input Tensors:
tensor745, Name: squeeze_71, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor754, Name: mul_164, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 409, Name: torch.ops.aten.mul.Tensor(mul_164, 0.1)
Input Tensors:
tensor754, Name: mul_164, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor755, Name: mul_165, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 410, Name: torch.ops.aten.mul.Tensor(primals_232, 0.9)
Input Tensors:
tensor231, Name: primals_232, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor756, Name: mul_166, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 411, Name: torch.ops.aten.add.Tensor(mul_165, mul_166)
Input Tensors:
tensor755, Name: mul_165, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor756, Name: mul_166, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor757, Name: add_124, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 412, Name: torch.ops.aten.mul.Tensor(mul_161, unsqueeze_93)
Input Tensors:
tensor750, Name: mul_161, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor70, Name: unsqueeze_93, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor758, Name: mul_167, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 413, Name: torch.ops.aten.add.Tensor(mul_167, unsqueeze_95)
Input Tensors:
tensor758, Name: mul_167, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor71, Name: unsqueeze_95, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor759, Name: add_125, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 414, Name: torch.ops.aten.add.Tensor(add_125, relu_18)
Input Tensors:
tensor759, Name: add_125, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor706, Name: relu_18, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor760, Name: add_126, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 415, Name: torch.ops.aten.relu.default(add_126)
Input Tensors:
tensor760, Name: add_126, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor761, Name: relu_21, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 416, Name: torch.ops.aten.convolution.default(relu_21, primals_73, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor761, Name: relu_21, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor72, Name: primals_73, Is global?: 1: Size in byte: 524288, Dimensions: f32[256, 512, 1, 1]
Output Tensors:
tensor762, Name: convolution_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 417, Name: torch.ops.aten.add.Tensor(primals_236, 1)
Input Tensors:
tensor235, Name: primals_236, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor763, Name: add_127, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 418, Name: torch.ops.aten.var_mean.correction(convolution_24, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor762, Name: convolution_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
Output Tensors:
tensor764, Name: getitem_50, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor765, Name: getitem_51, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 419, Name: torch.ops.aten.add.Tensor(getitem_50, 1e-05)
Input Tensors:
tensor764, Name: getitem_50, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor766, Name: add_128, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 420, Name: torch.ops.aten.rsqrt.default(add_128)
Input Tensors:
tensor766, Name: add_128, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor767, Name: rsqrt_24, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 421, Name: torch.ops.aten.sub.Tensor(convolution_24, getitem_51)
Input Tensors:
tensor762, Name: convolution_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor765, Name: getitem_51, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor768, Name: sub_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 422, Name: torch.ops.aten.mul.Tensor(sub_24, rsqrt_24)
Input Tensors:
tensor768, Name: sub_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor767, Name: rsqrt_24, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor769, Name: mul_168, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 423, Name: torch.ops.aten.mul.Tensor(squeeze_72, 0.1)
Input Tensors:
tensor765, Name: squeeze_72, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor770, Name: mul_169, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 424, Name: torch.ops.aten.mul.Tensor(primals_234, 0.9)
Input Tensors:
tensor233, Name: primals_234, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor771, Name: mul_170, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 425, Name: torch.ops.aten.add.Tensor(mul_169, mul_170)
Input Tensors:
tensor770, Name: mul_169, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor771, Name: mul_170, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor772, Name: add_129, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 426, Name: torch.ops.aten.mul.Tensor(squeeze_74, 1.0000199302441455)
Input Tensors:
tensor764, Name: squeeze_74, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor773, Name: mul_171, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 427, Name: torch.ops.aten.mul.Tensor(mul_171, 0.1)
Input Tensors:
tensor773, Name: mul_171, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor774, Name: mul_172, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 428, Name: torch.ops.aten.mul.Tensor(primals_235, 0.9)
Input Tensors:
tensor234, Name: primals_235, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor775, Name: mul_173, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 429, Name: torch.ops.aten.add.Tensor(mul_172, mul_173)
Input Tensors:
tensor774, Name: mul_172, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor775, Name: mul_173, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor776, Name: add_130, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 430, Name: torch.ops.aten.mul.Tensor(mul_168, unsqueeze_97)
Input Tensors:
tensor769, Name: mul_168, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor73, Name: unsqueeze_97, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor777, Name: mul_174, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 431, Name: torch.ops.aten.add.Tensor(mul_174, unsqueeze_99)
Input Tensors:
tensor777, Name: mul_174, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor74, Name: unsqueeze_99, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor778, Name: add_131, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 432, Name: torch.ops.aten.relu.default(add_131)
Input Tensors:
tensor778, Name: add_131, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
Output Tensors:
tensor779, Name: relu_22, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 433, Name: torch.ops.aten.convolution.default(relu_22, primals_76, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor779, Name: relu_22, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor75, Name: primals_76, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor780, Name: convolution_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 434, Name: torch.ops.aten.add.Tensor(primals_239, 1)
Input Tensors:
tensor238, Name: primals_239, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor781, Name: add_132, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 435, Name: torch.ops.aten.var_mean.correction(convolution_25, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor780, Name: convolution_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor782, Name: getitem_52, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor783, Name: getitem_53, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 436, Name: torch.ops.aten.add.Tensor(getitem_52, 1e-05)
Input Tensors:
tensor782, Name: getitem_52, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor784, Name: add_133, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 437, Name: torch.ops.aten.rsqrt.default(add_133)
Input Tensors:
tensor784, Name: add_133, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor785, Name: rsqrt_25, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 438, Name: torch.ops.aten.sub.Tensor(convolution_25, getitem_53)
Input Tensors:
tensor780, Name: convolution_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor783, Name: getitem_53, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor786, Name: sub_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 439, Name: torch.ops.aten.mul.Tensor(sub_25, rsqrt_25)
Input Tensors:
tensor786, Name: sub_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor785, Name: rsqrt_25, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor787, Name: mul_175, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 440, Name: torch.ops.aten.mul.Tensor(squeeze_75, 0.1)
Input Tensors:
tensor783, Name: squeeze_75, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor788, Name: mul_176, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 441, Name: torch.ops.aten.mul.Tensor(primals_237, 0.9)
Input Tensors:
tensor236, Name: primals_237, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor789, Name: mul_177, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 442, Name: torch.ops.aten.add.Tensor(mul_176, mul_177)
Input Tensors:
tensor788, Name: mul_176, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor789, Name: mul_177, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor790, Name: add_134, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 443, Name: torch.ops.aten.mul.Tensor(squeeze_77, 1.0000797257434426)
Input Tensors:
tensor782, Name: squeeze_77, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor791, Name: mul_178, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 444, Name: torch.ops.aten.mul.Tensor(mul_178, 0.1)
Input Tensors:
tensor791, Name: mul_178, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor792, Name: mul_179, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 445, Name: torch.ops.aten.mul.Tensor(primals_238, 0.9)
Input Tensors:
tensor237, Name: primals_238, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor793, Name: mul_180, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 446, Name: torch.ops.aten.add.Tensor(mul_179, mul_180)
Input Tensors:
tensor792, Name: mul_179, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor793, Name: mul_180, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor794, Name: add_135, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 447, Name: torch.ops.aten.mul.Tensor(mul_175, unsqueeze_101)
Input Tensors:
tensor787, Name: mul_175, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor76, Name: unsqueeze_101, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor795, Name: mul_181, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 448, Name: torch.ops.aten.add.Tensor(mul_181, unsqueeze_103)
Input Tensors:
tensor795, Name: mul_181, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor77, Name: unsqueeze_103, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor796, Name: add_136, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 449, Name: torch.ops.aten.relu.default(add_136)
Input Tensors:
tensor796, Name: add_136, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor797, Name: relu_23, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 450, Name: torch.ops.aten.convolution.default(relu_23, primals_79, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor797, Name: relu_23, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor78, Name: primals_79, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor798, Name: convolution_26, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 451, Name: torch.ops.aten.add.Tensor(primals_242, 1)
Input Tensors:
tensor241, Name: primals_242, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor799, Name: add_137, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 452, Name: torch.ops.aten.var_mean.correction(convolution_26, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor798, Name: convolution_26, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor800, Name: getitem_54, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
tensor801, Name: getitem_55, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 453, Name: torch.ops.aten.add.Tensor(getitem_54, 1e-05)
Input Tensors:
tensor800, Name: getitem_54, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor802, Name: add_138, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 454, Name: torch.ops.aten.rsqrt.default(add_138)
Input Tensors:
tensor802, Name: add_138, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor803, Name: rsqrt_26, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 455, Name: torch.ops.aten.sub.Tensor(convolution_26, getitem_55)
Input Tensors:
tensor798, Name: convolution_26, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor801, Name: getitem_55, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor804, Name: sub_26, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 456, Name: torch.ops.aten.mul.Tensor(sub_26, rsqrt_26)
Input Tensors:
tensor804, Name: sub_26, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor803, Name: rsqrt_26, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor805, Name: mul_182, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 457, Name: torch.ops.aten.mul.Tensor(squeeze_78, 0.1)
Input Tensors:
tensor801, Name: squeeze_78, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor806, Name: mul_183, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 458, Name: torch.ops.aten.mul.Tensor(primals_240, 0.9)
Input Tensors:
tensor239, Name: primals_240, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor807, Name: mul_184, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 459, Name: torch.ops.aten.add.Tensor(mul_183, mul_184)
Input Tensors:
tensor806, Name: mul_183, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor807, Name: mul_184, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor808, Name: add_139, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 460, Name: torch.ops.aten.mul.Tensor(squeeze_80, 1.0000797257434426)
Input Tensors:
tensor800, Name: squeeze_80, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor809, Name: mul_185, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 461, Name: torch.ops.aten.mul.Tensor(mul_185, 0.1)
Input Tensors:
tensor809, Name: mul_185, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor810, Name: mul_186, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 462, Name: torch.ops.aten.mul.Tensor(primals_241, 0.9)
Input Tensors:
tensor240, Name: primals_241, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor811, Name: mul_187, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 463, Name: torch.ops.aten.add.Tensor(mul_186, mul_187)
Input Tensors:
tensor810, Name: mul_186, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor811, Name: mul_187, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor812, Name: add_140, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 464, Name: torch.ops.aten.mul.Tensor(mul_182, unsqueeze_105)
Input Tensors:
tensor805, Name: mul_182, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor79, Name: unsqueeze_105, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor813, Name: mul_188, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 465, Name: torch.ops.aten.add.Tensor(mul_188, unsqueeze_107)
Input Tensors:
tensor813, Name: mul_188, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor80, Name: unsqueeze_107, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor814, Name: add_141, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 466, Name: torch.ops.aten.convolution.default(relu_21, primals_82, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor761, Name: relu_21, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor81, Name: primals_82, Is global?: 1: Size in byte: 2097152, Dimensions: f32[1024, 512, 1, 1]
Output Tensors:
tensor815, Name: convolution_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 467, Name: torch.ops.aten.add.Tensor(primals_245, 1)
Input Tensors:
tensor244, Name: primals_245, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor816, Name: add_142, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 468, Name: torch.ops.aten.var_mean.correction(convolution_27, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor815, Name: convolution_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor817, Name: getitem_56, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
tensor818, Name: getitem_57, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 469, Name: torch.ops.aten.add.Tensor(getitem_56, 1e-05)
Input Tensors:
tensor817, Name: getitem_56, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor819, Name: add_143, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 470, Name: torch.ops.aten.rsqrt.default(add_143)
Input Tensors:
tensor819, Name: add_143, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor820, Name: rsqrt_27, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 471, Name: torch.ops.aten.sub.Tensor(convolution_27, getitem_57)
Input Tensors:
tensor815, Name: convolution_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor818, Name: getitem_57, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor821, Name: sub_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 472, Name: torch.ops.aten.mul.Tensor(sub_27, rsqrt_27)
Input Tensors:
tensor821, Name: sub_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor820, Name: rsqrt_27, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor822, Name: mul_189, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 473, Name: torch.ops.aten.mul.Tensor(squeeze_81, 0.1)
Input Tensors:
tensor818, Name: squeeze_81, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor823, Name: mul_190, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 474, Name: torch.ops.aten.mul.Tensor(primals_243, 0.9)
Input Tensors:
tensor242, Name: primals_243, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor824, Name: mul_191, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 475, Name: torch.ops.aten.add.Tensor(mul_190, mul_191)
Input Tensors:
tensor823, Name: mul_190, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor824, Name: mul_191, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor825, Name: add_144, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 476, Name: torch.ops.aten.mul.Tensor(squeeze_83, 1.0000797257434426)
Input Tensors:
tensor817, Name: squeeze_83, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor826, Name: mul_192, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 477, Name: torch.ops.aten.mul.Tensor(mul_192, 0.1)
Input Tensors:
tensor826, Name: mul_192, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor827, Name: mul_193, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 478, Name: torch.ops.aten.mul.Tensor(primals_244, 0.9)
Input Tensors:
tensor243, Name: primals_244, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor828, Name: mul_194, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 479, Name: torch.ops.aten.add.Tensor(mul_193, mul_194)
Input Tensors:
tensor827, Name: mul_193, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor828, Name: mul_194, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor829, Name: add_145, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 480, Name: torch.ops.aten.mul.Tensor(mul_189, unsqueeze_109)
Input Tensors:
tensor822, Name: mul_189, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor82, Name: unsqueeze_109, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor830, Name: mul_195, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 481, Name: torch.ops.aten.add.Tensor(mul_195, unsqueeze_111)
Input Tensors:
tensor830, Name: mul_195, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor83, Name: unsqueeze_111, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor831, Name: add_146, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 482, Name: torch.ops.aten.add.Tensor(add_141, add_146)
Input Tensors:
tensor814, Name: add_141, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor831, Name: add_146, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor832, Name: add_147, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 483, Name: torch.ops.aten.relu.default(add_147)
Input Tensors:
tensor832, Name: add_147, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor833, Name: relu_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 484, Name: torch.ops.aten.convolution.default(relu_24, primals_85, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor833, Name: relu_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor84, Name: primals_85, Is global?: 1: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
Output Tensors:
tensor834, Name: convolution_28, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 485, Name: torch.ops.aten.add.Tensor(primals_248, 1)
Input Tensors:
tensor247, Name: primals_248, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor835, Name: add_148, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 486, Name: torch.ops.aten.var_mean.correction(convolution_28, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor834, Name: convolution_28, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor836, Name: getitem_58, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor837, Name: getitem_59, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 487, Name: torch.ops.aten.add.Tensor(getitem_58, 1e-05)
Input Tensors:
tensor836, Name: getitem_58, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor838, Name: add_149, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 488, Name: torch.ops.aten.rsqrt.default(add_149)
Input Tensors:
tensor838, Name: add_149, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor839, Name: rsqrt_28, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 489, Name: torch.ops.aten.sub.Tensor(convolution_28, getitem_59)
Input Tensors:
tensor834, Name: convolution_28, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor837, Name: getitem_59, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor840, Name: sub_28, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 490, Name: torch.ops.aten.mul.Tensor(sub_28, rsqrt_28)
Input Tensors:
tensor840, Name: sub_28, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor839, Name: rsqrt_28, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor841, Name: mul_196, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 491, Name: torch.ops.aten.mul.Tensor(squeeze_84, 0.1)
Input Tensors:
tensor837, Name: squeeze_84, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor842, Name: mul_197, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 492, Name: torch.ops.aten.mul.Tensor(primals_246, 0.9)
Input Tensors:
tensor245, Name: primals_246, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor843, Name: mul_198, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 493, Name: torch.ops.aten.add.Tensor(mul_197, mul_198)
Input Tensors:
tensor842, Name: mul_197, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor843, Name: mul_198, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor844, Name: add_150, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 494, Name: torch.ops.aten.mul.Tensor(squeeze_86, 1.0000797257434426)
Input Tensors:
tensor836, Name: squeeze_86, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor845, Name: mul_199, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 495, Name: torch.ops.aten.mul.Tensor(mul_199, 0.1)
Input Tensors:
tensor845, Name: mul_199, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor846, Name: mul_200, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 496, Name: torch.ops.aten.mul.Tensor(primals_247, 0.9)
Input Tensors:
tensor246, Name: primals_247, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor847, Name: mul_201, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 497, Name: torch.ops.aten.add.Tensor(mul_200, mul_201)
Input Tensors:
tensor846, Name: mul_200, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor847, Name: mul_201, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor848, Name: add_151, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 498, Name: torch.ops.aten.mul.Tensor(mul_196, unsqueeze_113)
Input Tensors:
tensor841, Name: mul_196, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor85, Name: unsqueeze_113, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor849, Name: mul_202, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 499, Name: torch.ops.aten.add.Tensor(mul_202, unsqueeze_115)
Input Tensors:
tensor849, Name: mul_202, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor86, Name: unsqueeze_115, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor850, Name: add_152, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 500, Name: torch.ops.aten.relu.default(add_152)
Input Tensors:
tensor850, Name: add_152, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor851, Name: relu_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 501, Name: torch.ops.aten.convolution.default(relu_25, primals_88, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor851, Name: relu_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor87, Name: primals_88, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor852, Name: convolution_29, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 502, Name: torch.ops.aten.add.Tensor(primals_251, 1)
Input Tensors:
tensor250, Name: primals_251, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor853, Name: add_153, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 503, Name: torch.ops.aten.var_mean.correction(convolution_29, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor852, Name: convolution_29, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor854, Name: getitem_60, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor855, Name: getitem_61, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 504, Name: torch.ops.aten.add.Tensor(getitem_60, 1e-05)
Input Tensors:
tensor854, Name: getitem_60, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor856, Name: add_154, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 505, Name: torch.ops.aten.rsqrt.default(add_154)
Input Tensors:
tensor856, Name: add_154, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor857, Name: rsqrt_29, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 506, Name: torch.ops.aten.sub.Tensor(convolution_29, getitem_61)
Input Tensors:
tensor852, Name: convolution_29, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor855, Name: getitem_61, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor858, Name: sub_29, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 507, Name: torch.ops.aten.mul.Tensor(sub_29, rsqrt_29)
Input Tensors:
tensor858, Name: sub_29, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor857, Name: rsqrt_29, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor859, Name: mul_203, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 508, Name: torch.ops.aten.mul.Tensor(squeeze_87, 0.1)
Input Tensors:
tensor855, Name: squeeze_87, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor860, Name: mul_204, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 509, Name: torch.ops.aten.mul.Tensor(primals_249, 0.9)
Input Tensors:
tensor248, Name: primals_249, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor861, Name: mul_205, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 510, Name: torch.ops.aten.add.Tensor(mul_204, mul_205)
Input Tensors:
tensor860, Name: mul_204, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor861, Name: mul_205, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor862, Name: add_155, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 511, Name: torch.ops.aten.mul.Tensor(squeeze_89, 1.0000797257434426)
Input Tensors:
tensor854, Name: squeeze_89, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor863, Name: mul_206, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 512, Name: torch.ops.aten.mul.Tensor(mul_206, 0.1)
Input Tensors:
tensor863, Name: mul_206, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor864, Name: mul_207, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 513, Name: torch.ops.aten.mul.Tensor(primals_250, 0.9)
Input Tensors:
tensor249, Name: primals_250, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor865, Name: mul_208, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 514, Name: torch.ops.aten.add.Tensor(mul_207, mul_208)
Input Tensors:
tensor864, Name: mul_207, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor865, Name: mul_208, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor866, Name: add_156, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 515, Name: torch.ops.aten.mul.Tensor(mul_203, unsqueeze_117)
Input Tensors:
tensor859, Name: mul_203, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor88, Name: unsqueeze_117, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor867, Name: mul_209, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 516, Name: torch.ops.aten.add.Tensor(mul_209, unsqueeze_119)
Input Tensors:
tensor867, Name: mul_209, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor89, Name: unsqueeze_119, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor868, Name: add_157, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 517, Name: torch.ops.aten.relu.default(add_157)
Input Tensors:
tensor868, Name: add_157, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor869, Name: relu_26, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 518, Name: torch.ops.aten.convolution.default(relu_26, primals_91, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor869, Name: relu_26, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor90, Name: primals_91, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor870, Name: convolution_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 519, Name: torch.ops.aten.add.Tensor(primals_254, 1)
Input Tensors:
tensor253, Name: primals_254, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor871, Name: add_158, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 520, Name: torch.ops.aten.var_mean.correction(convolution_30, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor870, Name: convolution_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor872, Name: getitem_62, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
tensor873, Name: getitem_63, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 521, Name: torch.ops.aten.add.Tensor(getitem_62, 1e-05)
Input Tensors:
tensor872, Name: getitem_62, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor874, Name: add_159, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 522, Name: torch.ops.aten.rsqrt.default(add_159)
Input Tensors:
tensor874, Name: add_159, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor875, Name: rsqrt_30, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 523, Name: torch.ops.aten.sub.Tensor(convolution_30, getitem_63)
Input Tensors:
tensor870, Name: convolution_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor873, Name: getitem_63, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor876, Name: sub_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 524, Name: torch.ops.aten.mul.Tensor(sub_30, rsqrt_30)
Input Tensors:
tensor876, Name: sub_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor875, Name: rsqrt_30, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor877, Name: mul_210, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 525, Name: torch.ops.aten.mul.Tensor(squeeze_90, 0.1)
Input Tensors:
tensor873, Name: squeeze_90, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor878, Name: mul_211, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 526, Name: torch.ops.aten.mul.Tensor(primals_252, 0.9)
Input Tensors:
tensor251, Name: primals_252, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor879, Name: mul_212, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 527, Name: torch.ops.aten.add.Tensor(mul_211, mul_212)
Input Tensors:
tensor878, Name: mul_211, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor879, Name: mul_212, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor880, Name: add_160, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 528, Name: torch.ops.aten.mul.Tensor(squeeze_92, 1.0000797257434426)
Input Tensors:
tensor872, Name: squeeze_92, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor881, Name: mul_213, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 529, Name: torch.ops.aten.mul.Tensor(mul_213, 0.1)
Input Tensors:
tensor881, Name: mul_213, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor882, Name: mul_214, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 530, Name: torch.ops.aten.mul.Tensor(primals_253, 0.9)
Input Tensors:
tensor252, Name: primals_253, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor883, Name: mul_215, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 531, Name: torch.ops.aten.add.Tensor(mul_214, mul_215)
Input Tensors:
tensor882, Name: mul_214, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor883, Name: mul_215, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor884, Name: add_161, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 532, Name: torch.ops.aten.mul.Tensor(mul_210, unsqueeze_121)
Input Tensors:
tensor877, Name: mul_210, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor91, Name: unsqueeze_121, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor885, Name: mul_216, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 533, Name: torch.ops.aten.add.Tensor(mul_216, unsqueeze_123)
Input Tensors:
tensor885, Name: mul_216, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor92, Name: unsqueeze_123, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor886, Name: add_162, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 534, Name: torch.ops.aten.add.Tensor(add_162, relu_24)
Input Tensors:
tensor886, Name: add_162, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor833, Name: relu_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor887, Name: add_163, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 535, Name: torch.ops.aten.relu.default(add_163)
Input Tensors:
tensor887, Name: add_163, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor888, Name: relu_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 536, Name: torch.ops.aten.convolution.default(relu_27, primals_94, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor888, Name: relu_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor93, Name: primals_94, Is global?: 1: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
Output Tensors:
tensor889, Name: convolution_31, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 537, Name: torch.ops.aten.add.Tensor(primals_257, 1)
Input Tensors:
tensor256, Name: primals_257, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor890, Name: add_164, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 538, Name: torch.ops.aten.var_mean.correction(convolution_31, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor889, Name: convolution_31, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor891, Name: getitem_64, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor892, Name: getitem_65, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 539, Name: torch.ops.aten.add.Tensor(getitem_64, 1e-05)
Input Tensors:
tensor891, Name: getitem_64, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor893, Name: add_165, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 540, Name: torch.ops.aten.rsqrt.default(add_165)
Input Tensors:
tensor893, Name: add_165, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor894, Name: rsqrt_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 541, Name: torch.ops.aten.sub.Tensor(convolution_31, getitem_65)
Input Tensors:
tensor889, Name: convolution_31, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor892, Name: getitem_65, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor895, Name: sub_31, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 542, Name: torch.ops.aten.mul.Tensor(sub_31, rsqrt_31)
Input Tensors:
tensor895, Name: sub_31, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor894, Name: rsqrt_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor896, Name: mul_217, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 543, Name: torch.ops.aten.mul.Tensor(squeeze_93, 0.1)
Input Tensors:
tensor892, Name: squeeze_93, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor897, Name: mul_218, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 544, Name: torch.ops.aten.mul.Tensor(primals_255, 0.9)
Input Tensors:
tensor254, Name: primals_255, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor898, Name: mul_219, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 545, Name: torch.ops.aten.add.Tensor(mul_218, mul_219)
Input Tensors:
tensor897, Name: mul_218, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor898, Name: mul_219, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor899, Name: add_166, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 546, Name: torch.ops.aten.mul.Tensor(squeeze_95, 1.0000797257434426)
Input Tensors:
tensor891, Name: squeeze_95, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor900, Name: mul_220, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 547, Name: torch.ops.aten.mul.Tensor(mul_220, 0.1)
Input Tensors:
tensor900, Name: mul_220, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor901, Name: mul_221, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 548, Name: torch.ops.aten.mul.Tensor(primals_256, 0.9)
Input Tensors:
tensor255, Name: primals_256, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor902, Name: mul_222, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 549, Name: torch.ops.aten.add.Tensor(mul_221, mul_222)
Input Tensors:
tensor901, Name: mul_221, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor902, Name: mul_222, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor903, Name: add_167, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 550, Name: torch.ops.aten.mul.Tensor(mul_217, unsqueeze_125)
Input Tensors:
tensor896, Name: mul_217, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor94, Name: unsqueeze_125, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor904, Name: mul_223, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 551, Name: torch.ops.aten.add.Tensor(mul_223, unsqueeze_127)
Input Tensors:
tensor904, Name: mul_223, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor95, Name: unsqueeze_127, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor905, Name: add_168, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 552, Name: torch.ops.aten.relu.default(add_168)
Input Tensors:
tensor905, Name: add_168, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor906, Name: relu_28, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 553, Name: torch.ops.aten.convolution.default(relu_28, primals_97, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor906, Name: relu_28, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor96, Name: primals_97, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor907, Name: convolution_32, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 554, Name: torch.ops.aten.add.Tensor(primals_260, 1)
Input Tensors:
tensor259, Name: primals_260, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor908, Name: add_169, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 555, Name: torch.ops.aten.var_mean.correction(convolution_32, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor907, Name: convolution_32, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor909, Name: getitem_66, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor910, Name: getitem_67, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 556, Name: torch.ops.aten.add.Tensor(getitem_66, 1e-05)
Input Tensors:
tensor909, Name: getitem_66, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor911, Name: add_170, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 557, Name: torch.ops.aten.rsqrt.default(add_170)
Input Tensors:
tensor911, Name: add_170, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor912, Name: rsqrt_32, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 558, Name: torch.ops.aten.sub.Tensor(convolution_32, getitem_67)
Input Tensors:
tensor907, Name: convolution_32, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor910, Name: getitem_67, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor913, Name: sub_32, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 559, Name: torch.ops.aten.mul.Tensor(sub_32, rsqrt_32)
Input Tensors:
tensor913, Name: sub_32, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor912, Name: rsqrt_32, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor914, Name: mul_224, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 560, Name: torch.ops.aten.mul.Tensor(squeeze_96, 0.1)
Input Tensors:
tensor910, Name: squeeze_96, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor915, Name: mul_225, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 561, Name: torch.ops.aten.mul.Tensor(primals_258, 0.9)
Input Tensors:
tensor257, Name: primals_258, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor916, Name: mul_226, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 562, Name: torch.ops.aten.add.Tensor(mul_225, mul_226)
Input Tensors:
tensor915, Name: mul_225, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor916, Name: mul_226, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor917, Name: add_171, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 563, Name: torch.ops.aten.mul.Tensor(squeeze_98, 1.0000797257434426)
Input Tensors:
tensor909, Name: squeeze_98, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor918, Name: mul_227, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 564, Name: torch.ops.aten.mul.Tensor(mul_227, 0.1)
Input Tensors:
tensor918, Name: mul_227, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor919, Name: mul_228, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 565, Name: torch.ops.aten.mul.Tensor(primals_259, 0.9)
Input Tensors:
tensor258, Name: primals_259, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor920, Name: mul_229, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 566, Name: torch.ops.aten.add.Tensor(mul_228, mul_229)
Input Tensors:
tensor919, Name: mul_228, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor920, Name: mul_229, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor921, Name: add_172, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 567, Name: torch.ops.aten.mul.Tensor(mul_224, unsqueeze_129)
Input Tensors:
tensor914, Name: mul_224, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor97, Name: unsqueeze_129, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor922, Name: mul_230, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 568, Name: torch.ops.aten.add.Tensor(mul_230, unsqueeze_131)
Input Tensors:
tensor922, Name: mul_230, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor98, Name: unsqueeze_131, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor923, Name: add_173, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 569, Name: torch.ops.aten.relu.default(add_173)
Input Tensors:
tensor923, Name: add_173, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor924, Name: relu_29, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 570, Name: torch.ops.aten.convolution.default(relu_29, primals_100, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor924, Name: relu_29, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor99, Name: primals_100, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor925, Name: convolution_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 571, Name: torch.ops.aten.add.Tensor(primals_263, 1)
Input Tensors:
tensor262, Name: primals_263, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor926, Name: add_174, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 572, Name: torch.ops.aten.var_mean.correction(convolution_33, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor925, Name: convolution_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor927, Name: getitem_68, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
tensor928, Name: getitem_69, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 573, Name: torch.ops.aten.add.Tensor(getitem_68, 1e-05)
Input Tensors:
tensor927, Name: getitem_68, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor929, Name: add_175, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 574, Name: torch.ops.aten.rsqrt.default(add_175)
Input Tensors:
tensor929, Name: add_175, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor930, Name: rsqrt_33, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 575, Name: torch.ops.aten.sub.Tensor(convolution_33, getitem_69)
Input Tensors:
tensor925, Name: convolution_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor928, Name: getitem_69, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor931, Name: sub_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 576, Name: torch.ops.aten.mul.Tensor(sub_33, rsqrt_33)
Input Tensors:
tensor931, Name: sub_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor930, Name: rsqrt_33, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor932, Name: mul_231, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 577, Name: torch.ops.aten.mul.Tensor(squeeze_99, 0.1)
Input Tensors:
tensor928, Name: squeeze_99, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor933, Name: mul_232, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 578, Name: torch.ops.aten.mul.Tensor(primals_261, 0.9)
Input Tensors:
tensor260, Name: primals_261, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor934, Name: mul_233, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 579, Name: torch.ops.aten.add.Tensor(mul_232, mul_233)
Input Tensors:
tensor933, Name: mul_232, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor934, Name: mul_233, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor935, Name: add_176, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 580, Name: torch.ops.aten.mul.Tensor(squeeze_101, 1.0000797257434426)
Input Tensors:
tensor927, Name: squeeze_101, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor936, Name: mul_234, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 581, Name: torch.ops.aten.mul.Tensor(mul_234, 0.1)
Input Tensors:
tensor936, Name: mul_234, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor937, Name: mul_235, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 582, Name: torch.ops.aten.mul.Tensor(primals_262, 0.9)
Input Tensors:
tensor261, Name: primals_262, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor938, Name: mul_236, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 583, Name: torch.ops.aten.add.Tensor(mul_235, mul_236)
Input Tensors:
tensor937, Name: mul_235, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor938, Name: mul_236, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor939, Name: add_177, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 584, Name: torch.ops.aten.mul.Tensor(mul_231, unsqueeze_133)
Input Tensors:
tensor932, Name: mul_231, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor100, Name: unsqueeze_133, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor940, Name: mul_237, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 585, Name: torch.ops.aten.add.Tensor(mul_237, unsqueeze_135)
Input Tensors:
tensor940, Name: mul_237, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor101, Name: unsqueeze_135, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor941, Name: add_178, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 586, Name: torch.ops.aten.add.Tensor(add_178, relu_27)
Input Tensors:
tensor941, Name: add_178, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor888, Name: relu_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor942, Name: add_179, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 587, Name: torch.ops.aten.relu.default(add_179)
Input Tensors:
tensor942, Name: add_179, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor943, Name: relu_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 588, Name: torch.ops.aten.convolution.default(relu_30, primals_103, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor943, Name: relu_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor102, Name: primals_103, Is global?: 1: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
Output Tensors:
tensor944, Name: convolution_34, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 589, Name: torch.ops.aten.add.Tensor(primals_266, 1)
Input Tensors:
tensor265, Name: primals_266, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor945, Name: add_180, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 590, Name: torch.ops.aten.var_mean.correction(convolution_34, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor944, Name: convolution_34, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor946, Name: getitem_70, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor947, Name: getitem_71, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 591, Name: torch.ops.aten.add.Tensor(getitem_70, 1e-05)
Input Tensors:
tensor946, Name: getitem_70, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor948, Name: add_181, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 592, Name: torch.ops.aten.rsqrt.default(add_181)
Input Tensors:
tensor948, Name: add_181, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor949, Name: rsqrt_34, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 593, Name: torch.ops.aten.sub.Tensor(convolution_34, getitem_71)
Input Tensors:
tensor944, Name: convolution_34, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor947, Name: getitem_71, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor950, Name: sub_34, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 594, Name: torch.ops.aten.mul.Tensor(sub_34, rsqrt_34)
Input Tensors:
tensor950, Name: sub_34, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor949, Name: rsqrt_34, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor951, Name: mul_238, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 595, Name: torch.ops.aten.mul.Tensor(squeeze_102, 0.1)
Input Tensors:
tensor947, Name: squeeze_102, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor952, Name: mul_239, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 596, Name: torch.ops.aten.mul.Tensor(primals_264, 0.9)
Input Tensors:
tensor263, Name: primals_264, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor953, Name: mul_240, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 597, Name: torch.ops.aten.add.Tensor(mul_239, mul_240)
Input Tensors:
tensor952, Name: mul_239, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor953, Name: mul_240, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor954, Name: add_182, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 598, Name: torch.ops.aten.mul.Tensor(squeeze_104, 1.0000797257434426)
Input Tensors:
tensor946, Name: squeeze_104, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor955, Name: mul_241, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 599, Name: torch.ops.aten.mul.Tensor(mul_241, 0.1)
Input Tensors:
tensor955, Name: mul_241, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor956, Name: mul_242, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 600, Name: torch.ops.aten.mul.Tensor(primals_265, 0.9)
Input Tensors:
tensor264, Name: primals_265, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor957, Name: mul_243, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 601, Name: torch.ops.aten.add.Tensor(mul_242, mul_243)
Input Tensors:
tensor956, Name: mul_242, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor957, Name: mul_243, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor958, Name: add_183, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 602, Name: torch.ops.aten.mul.Tensor(mul_238, unsqueeze_137)
Input Tensors:
tensor951, Name: mul_238, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor103, Name: unsqueeze_137, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor959, Name: mul_244, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 603, Name: torch.ops.aten.add.Tensor(mul_244, unsqueeze_139)
Input Tensors:
tensor959, Name: mul_244, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor104, Name: unsqueeze_139, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor960, Name: add_184, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 604, Name: torch.ops.aten.relu.default(add_184)
Input Tensors:
tensor960, Name: add_184, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor961, Name: relu_31, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 605, Name: torch.ops.aten.convolution.default(relu_31, primals_106, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor961, Name: relu_31, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor105, Name: primals_106, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor962, Name: convolution_35, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 606, Name: torch.ops.aten.add.Tensor(primals_269, 1)
Input Tensors:
tensor268, Name: primals_269, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor963, Name: add_185, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 607, Name: torch.ops.aten.var_mean.correction(convolution_35, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor962, Name: convolution_35, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor964, Name: getitem_72, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor965, Name: getitem_73, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 608, Name: torch.ops.aten.add.Tensor(getitem_72, 1e-05)
Input Tensors:
tensor964, Name: getitem_72, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor966, Name: add_186, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 609, Name: torch.ops.aten.rsqrt.default(add_186)
Input Tensors:
tensor966, Name: add_186, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor967, Name: rsqrt_35, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 610, Name: torch.ops.aten.sub.Tensor(convolution_35, getitem_73)
Input Tensors:
tensor962, Name: convolution_35, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor965, Name: getitem_73, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor968, Name: sub_35, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 611, Name: torch.ops.aten.mul.Tensor(sub_35, rsqrt_35)
Input Tensors:
tensor968, Name: sub_35, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor967, Name: rsqrt_35, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor969, Name: mul_245, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 612, Name: torch.ops.aten.mul.Tensor(squeeze_105, 0.1)
Input Tensors:
tensor965, Name: squeeze_105, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor970, Name: mul_246, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 613, Name: torch.ops.aten.mul.Tensor(primals_267, 0.9)
Input Tensors:
tensor266, Name: primals_267, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor971, Name: mul_247, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 614, Name: torch.ops.aten.add.Tensor(mul_246, mul_247)
Input Tensors:
tensor970, Name: mul_246, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor971, Name: mul_247, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor972, Name: add_187, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 615, Name: torch.ops.aten.mul.Tensor(squeeze_107, 1.0000797257434426)
Input Tensors:
tensor964, Name: squeeze_107, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor973, Name: mul_248, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 616, Name: torch.ops.aten.mul.Tensor(mul_248, 0.1)
Input Tensors:
tensor973, Name: mul_248, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor974, Name: mul_249, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 617, Name: torch.ops.aten.mul.Tensor(primals_268, 0.9)
Input Tensors:
tensor267, Name: primals_268, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor975, Name: mul_250, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 618, Name: torch.ops.aten.add.Tensor(mul_249, mul_250)
Input Tensors:
tensor974, Name: mul_249, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor975, Name: mul_250, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor976, Name: add_188, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 619, Name: torch.ops.aten.mul.Tensor(mul_245, unsqueeze_141)
Input Tensors:
tensor969, Name: mul_245, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor106, Name: unsqueeze_141, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor977, Name: mul_251, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 620, Name: torch.ops.aten.add.Tensor(mul_251, unsqueeze_143)
Input Tensors:
tensor977, Name: mul_251, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor107, Name: unsqueeze_143, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor978, Name: add_189, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 621, Name: torch.ops.aten.relu.default(add_189)
Input Tensors:
tensor978, Name: add_189, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor979, Name: relu_32, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 622, Name: torch.ops.aten.convolution.default(relu_32, primals_109, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor979, Name: relu_32, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor108, Name: primals_109, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor980, Name: convolution_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 623, Name: torch.ops.aten.add.Tensor(primals_272, 1)
Input Tensors:
tensor271, Name: primals_272, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor981, Name: add_190, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 624, Name: torch.ops.aten.var_mean.correction(convolution_36, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor980, Name: convolution_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor982, Name: getitem_74, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
tensor983, Name: getitem_75, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 625, Name: torch.ops.aten.add.Tensor(getitem_74, 1e-05)
Input Tensors:
tensor982, Name: getitem_74, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor984, Name: add_191, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 626, Name: torch.ops.aten.rsqrt.default(add_191)
Input Tensors:
tensor984, Name: add_191, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor985, Name: rsqrt_36, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 627, Name: torch.ops.aten.sub.Tensor(convolution_36, getitem_75)
Input Tensors:
tensor980, Name: convolution_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor983, Name: getitem_75, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor986, Name: sub_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 628, Name: torch.ops.aten.mul.Tensor(sub_36, rsqrt_36)
Input Tensors:
tensor986, Name: sub_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor985, Name: rsqrt_36, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor987, Name: mul_252, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 629, Name: torch.ops.aten.mul.Tensor(squeeze_108, 0.1)
Input Tensors:
tensor983, Name: squeeze_108, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor988, Name: mul_253, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 630, Name: torch.ops.aten.mul.Tensor(primals_270, 0.9)
Input Tensors:
tensor269, Name: primals_270, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor989, Name: mul_254, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 631, Name: torch.ops.aten.add.Tensor(mul_253, mul_254)
Input Tensors:
tensor988, Name: mul_253, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor989, Name: mul_254, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor990, Name: add_192, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 632, Name: torch.ops.aten.mul.Tensor(squeeze_110, 1.0000797257434426)
Input Tensors:
tensor982, Name: squeeze_110, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor991, Name: mul_255, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 633, Name: torch.ops.aten.mul.Tensor(mul_255, 0.1)
Input Tensors:
tensor991, Name: mul_255, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor992, Name: mul_256, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 634, Name: torch.ops.aten.mul.Tensor(primals_271, 0.9)
Input Tensors:
tensor270, Name: primals_271, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor993, Name: mul_257, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 635, Name: torch.ops.aten.add.Tensor(mul_256, mul_257)
Input Tensors:
tensor992, Name: mul_256, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor993, Name: mul_257, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor994, Name: add_193, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 636, Name: torch.ops.aten.mul.Tensor(mul_252, unsqueeze_145)
Input Tensors:
tensor987, Name: mul_252, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor109, Name: unsqueeze_145, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor995, Name: mul_258, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 637, Name: torch.ops.aten.add.Tensor(mul_258, unsqueeze_147)
Input Tensors:
tensor995, Name: mul_258, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor110, Name: unsqueeze_147, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor996, Name: add_194, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 638, Name: torch.ops.aten.add.Tensor(add_194, relu_30)
Input Tensors:
tensor996, Name: add_194, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor943, Name: relu_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor997, Name: add_195, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 639, Name: torch.ops.aten.relu.default(add_195)
Input Tensors:
tensor997, Name: add_195, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor998, Name: relu_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 640, Name: torch.ops.aten.convolution.default(relu_33, primals_112, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor998, Name: relu_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor111, Name: primals_112, Is global?: 1: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
Output Tensors:
tensor999, Name: convolution_37, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 641, Name: torch.ops.aten.add.Tensor(primals_275, 1)
Input Tensors:
tensor274, Name: primals_275, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1000, Name: add_196, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 642, Name: torch.ops.aten.var_mean.correction(convolution_37, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor999, Name: convolution_37, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1001, Name: getitem_76, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor1002, Name: getitem_77, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 643, Name: torch.ops.aten.add.Tensor(getitem_76, 1e-05)
Input Tensors:
tensor1001, Name: getitem_76, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1003, Name: add_197, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 644, Name: torch.ops.aten.rsqrt.default(add_197)
Input Tensors:
tensor1003, Name: add_197, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1004, Name: rsqrt_37, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 645, Name: torch.ops.aten.sub.Tensor(convolution_37, getitem_77)
Input Tensors:
tensor999, Name: convolution_37, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1002, Name: getitem_77, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1005, Name: sub_37, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 646, Name: torch.ops.aten.mul.Tensor(sub_37, rsqrt_37)
Input Tensors:
tensor1005, Name: sub_37, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1004, Name: rsqrt_37, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1006, Name: mul_259, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 647, Name: torch.ops.aten.mul.Tensor(squeeze_111, 0.1)
Input Tensors:
tensor1002, Name: squeeze_111, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1007, Name: mul_260, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 648, Name: torch.ops.aten.mul.Tensor(primals_273, 0.9)
Input Tensors:
tensor272, Name: primals_273, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1008, Name: mul_261, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 649, Name: torch.ops.aten.add.Tensor(mul_260, mul_261)
Input Tensors:
tensor1007, Name: mul_260, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1008, Name: mul_261, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1009, Name: add_198, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 650, Name: torch.ops.aten.mul.Tensor(squeeze_113, 1.0000797257434426)
Input Tensors:
tensor1001, Name: squeeze_113, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1010, Name: mul_262, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 651, Name: torch.ops.aten.mul.Tensor(mul_262, 0.1)
Input Tensors:
tensor1010, Name: mul_262, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1011, Name: mul_263, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 652, Name: torch.ops.aten.mul.Tensor(primals_274, 0.9)
Input Tensors:
tensor273, Name: primals_274, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1012, Name: mul_264, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 653, Name: torch.ops.aten.add.Tensor(mul_263, mul_264)
Input Tensors:
tensor1011, Name: mul_263, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1012, Name: mul_264, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1013, Name: add_199, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 654, Name: torch.ops.aten.mul.Tensor(mul_259, unsqueeze_149)
Input Tensors:
tensor1006, Name: mul_259, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor112, Name: unsqueeze_149, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor1014, Name: mul_265, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 655, Name: torch.ops.aten.add.Tensor(mul_265, unsqueeze_151)
Input Tensors:
tensor1014, Name: mul_265, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor113, Name: unsqueeze_151, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor1015, Name: add_200, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 656, Name: torch.ops.aten.relu.default(add_200)
Input Tensors:
tensor1015, Name: add_200, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1016, Name: relu_34, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 657, Name: torch.ops.aten.convolution.default(relu_34, primals_115, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1016, Name: relu_34, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor114, Name: primals_115, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor1017, Name: convolution_38, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 658, Name: torch.ops.aten.add.Tensor(primals_278, 1)
Input Tensors:
tensor277, Name: primals_278, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1018, Name: add_201, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 659, Name: torch.ops.aten.var_mean.correction(convolution_38, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1017, Name: convolution_38, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1019, Name: getitem_78, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor1020, Name: getitem_79, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 660, Name: torch.ops.aten.add.Tensor(getitem_78, 1e-05)
Input Tensors:
tensor1019, Name: getitem_78, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1021, Name: add_202, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 661, Name: torch.ops.aten.rsqrt.default(add_202)
Input Tensors:
tensor1021, Name: add_202, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1022, Name: rsqrt_38, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 662, Name: torch.ops.aten.sub.Tensor(convolution_38, getitem_79)
Input Tensors:
tensor1017, Name: convolution_38, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1020, Name: getitem_79, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1023, Name: sub_38, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 663, Name: torch.ops.aten.mul.Tensor(sub_38, rsqrt_38)
Input Tensors:
tensor1023, Name: sub_38, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1022, Name: rsqrt_38, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1024, Name: mul_266, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 664, Name: torch.ops.aten.mul.Tensor(squeeze_114, 0.1)
Input Tensors:
tensor1020, Name: squeeze_114, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1025, Name: mul_267, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 665, Name: torch.ops.aten.mul.Tensor(primals_276, 0.9)
Input Tensors:
tensor275, Name: primals_276, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1026, Name: mul_268, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 666, Name: torch.ops.aten.add.Tensor(mul_267, mul_268)
Input Tensors:
tensor1025, Name: mul_267, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1026, Name: mul_268, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1027, Name: add_203, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 667, Name: torch.ops.aten.mul.Tensor(squeeze_116, 1.0000797257434426)
Input Tensors:
tensor1019, Name: squeeze_116, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1028, Name: mul_269, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 668, Name: torch.ops.aten.mul.Tensor(mul_269, 0.1)
Input Tensors:
tensor1028, Name: mul_269, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1029, Name: mul_270, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 669, Name: torch.ops.aten.mul.Tensor(primals_277, 0.9)
Input Tensors:
tensor276, Name: primals_277, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1030, Name: mul_271, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 670, Name: torch.ops.aten.add.Tensor(mul_270, mul_271)
Input Tensors:
tensor1029, Name: mul_270, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1030, Name: mul_271, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1031, Name: add_204, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 671, Name: torch.ops.aten.mul.Tensor(mul_266, unsqueeze_153)
Input Tensors:
tensor1024, Name: mul_266, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor115, Name: unsqueeze_153, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor1032, Name: mul_272, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 672, Name: torch.ops.aten.add.Tensor(mul_272, unsqueeze_155)
Input Tensors:
tensor1032, Name: mul_272, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor116, Name: unsqueeze_155, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor1033, Name: add_205, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 673, Name: torch.ops.aten.relu.default(add_205)
Input Tensors:
tensor1033, Name: add_205, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1034, Name: relu_35, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 674, Name: torch.ops.aten.convolution.default(relu_35, primals_118, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1034, Name: relu_35, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor117, Name: primals_118, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor1035, Name: convolution_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 675, Name: torch.ops.aten.add.Tensor(primals_281, 1)
Input Tensors:
tensor280, Name: primals_281, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1036, Name: add_206, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 676, Name: torch.ops.aten.var_mean.correction(convolution_39, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1035, Name: convolution_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1037, Name: getitem_80, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
tensor1038, Name: getitem_81, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 677, Name: torch.ops.aten.add.Tensor(getitem_80, 1e-05)
Input Tensors:
tensor1037, Name: getitem_80, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1039, Name: add_207, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 678, Name: torch.ops.aten.rsqrt.default(add_207)
Input Tensors:
tensor1039, Name: add_207, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1040, Name: rsqrt_39, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 679, Name: torch.ops.aten.sub.Tensor(convolution_39, getitem_81)
Input Tensors:
tensor1035, Name: convolution_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1038, Name: getitem_81, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1041, Name: sub_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 680, Name: torch.ops.aten.mul.Tensor(sub_39, rsqrt_39)
Input Tensors:
tensor1041, Name: sub_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1040, Name: rsqrt_39, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1042, Name: mul_273, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 681, Name: torch.ops.aten.mul.Tensor(squeeze_117, 0.1)
Input Tensors:
tensor1038, Name: squeeze_117, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1043, Name: mul_274, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 682, Name: torch.ops.aten.mul.Tensor(primals_279, 0.9)
Input Tensors:
tensor278, Name: primals_279, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1044, Name: mul_275, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 683, Name: torch.ops.aten.add.Tensor(mul_274, mul_275)
Input Tensors:
tensor1043, Name: mul_274, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1044, Name: mul_275, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1045, Name: add_208, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 684, Name: torch.ops.aten.mul.Tensor(squeeze_119, 1.0000797257434426)
Input Tensors:
tensor1037, Name: squeeze_119, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1046, Name: mul_276, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 685, Name: torch.ops.aten.mul.Tensor(mul_276, 0.1)
Input Tensors:
tensor1046, Name: mul_276, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1047, Name: mul_277, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 686, Name: torch.ops.aten.mul.Tensor(primals_280, 0.9)
Input Tensors:
tensor279, Name: primals_280, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1048, Name: mul_278, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 687, Name: torch.ops.aten.add.Tensor(mul_277, mul_278)
Input Tensors:
tensor1047, Name: mul_277, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1048, Name: mul_278, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1049, Name: add_209, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 688, Name: torch.ops.aten.mul.Tensor(mul_273, unsqueeze_157)
Input Tensors:
tensor1042, Name: mul_273, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor118, Name: unsqueeze_157, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor1050, Name: mul_279, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 689, Name: torch.ops.aten.add.Tensor(mul_279, unsqueeze_159)
Input Tensors:
tensor1050, Name: mul_279, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor119, Name: unsqueeze_159, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor1051, Name: add_210, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 690, Name: torch.ops.aten.add.Tensor(add_210, relu_33)
Input Tensors:
tensor1051, Name: add_210, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor998, Name: relu_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1052, Name: add_211, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 691, Name: torch.ops.aten.relu.default(add_211)
Input Tensors:
tensor1052, Name: add_211, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1053, Name: relu_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 692, Name: torch.ops.aten.convolution.default(relu_36, primals_121, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1053, Name: relu_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor120, Name: primals_121, Is global?: 1: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
Output Tensors:
tensor1054, Name: convolution_40, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 693, Name: torch.ops.aten.add.Tensor(primals_284, 1)
Input Tensors:
tensor283, Name: primals_284, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1055, Name: add_212, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 694, Name: torch.ops.aten.var_mean.correction(convolution_40, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1054, Name: convolution_40, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1056, Name: getitem_82, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor1057, Name: getitem_83, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 695, Name: torch.ops.aten.add.Tensor(getitem_82, 1e-05)
Input Tensors:
tensor1056, Name: getitem_82, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1058, Name: add_213, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 696, Name: torch.ops.aten.rsqrt.default(add_213)
Input Tensors:
tensor1058, Name: add_213, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1059, Name: rsqrt_40, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 697, Name: torch.ops.aten.sub.Tensor(convolution_40, getitem_83)
Input Tensors:
tensor1054, Name: convolution_40, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1057, Name: getitem_83, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1060, Name: sub_40, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 698, Name: torch.ops.aten.mul.Tensor(sub_40, rsqrt_40)
Input Tensors:
tensor1060, Name: sub_40, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1059, Name: rsqrt_40, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1061, Name: mul_280, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 699, Name: torch.ops.aten.mul.Tensor(squeeze_120, 0.1)
Input Tensors:
tensor1057, Name: squeeze_120, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1062, Name: mul_281, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 700, Name: torch.ops.aten.mul.Tensor(primals_282, 0.9)
Input Tensors:
tensor281, Name: primals_282, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1063, Name: mul_282, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 701, Name: torch.ops.aten.add.Tensor(mul_281, mul_282)
Input Tensors:
tensor1062, Name: mul_281, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1063, Name: mul_282, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1064, Name: add_214, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 702, Name: torch.ops.aten.mul.Tensor(squeeze_122, 1.0000797257434426)
Input Tensors:
tensor1056, Name: squeeze_122, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1065, Name: mul_283, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 703, Name: torch.ops.aten.mul.Tensor(mul_283, 0.1)
Input Tensors:
tensor1065, Name: mul_283, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1066, Name: mul_284, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 704, Name: torch.ops.aten.mul.Tensor(primals_283, 0.9)
Input Tensors:
tensor282, Name: primals_283, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1067, Name: mul_285, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 705, Name: torch.ops.aten.add.Tensor(mul_284, mul_285)
Input Tensors:
tensor1066, Name: mul_284, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1067, Name: mul_285, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1068, Name: add_215, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 706, Name: torch.ops.aten.mul.Tensor(mul_280, unsqueeze_161)
Input Tensors:
tensor1061, Name: mul_280, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor121, Name: unsqueeze_161, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor1069, Name: mul_286, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 707, Name: torch.ops.aten.add.Tensor(mul_286, unsqueeze_163)
Input Tensors:
tensor1069, Name: mul_286, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor122, Name: unsqueeze_163, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor1070, Name: add_216, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 708, Name: torch.ops.aten.relu.default(add_216)
Input Tensors:
tensor1070, Name: add_216, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1071, Name: relu_37, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 709, Name: torch.ops.aten.convolution.default(relu_37, primals_124, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1071, Name: relu_37, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor123, Name: primals_124, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor1072, Name: convolution_41, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 710, Name: torch.ops.aten.add.Tensor(primals_287, 1)
Input Tensors:
tensor286, Name: primals_287, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1073, Name: add_217, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 711, Name: torch.ops.aten.var_mean.correction(convolution_41, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1072, Name: convolution_41, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1074, Name: getitem_84, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
tensor1075, Name: getitem_85, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 712, Name: torch.ops.aten.add.Tensor(getitem_84, 1e-05)
Input Tensors:
tensor1074, Name: getitem_84, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1076, Name: add_218, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 713, Name: torch.ops.aten.rsqrt.default(add_218)
Input Tensors:
tensor1076, Name: add_218, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1077, Name: rsqrt_41, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
____________________________________________________________________
Kernel ID: 714, Name: torch.ops.aten.sub.Tensor(convolution_41, getitem_85)
Input Tensors:
tensor1072, Name: convolution_41, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1075, Name: getitem_85, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1078, Name: sub_41, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 715, Name: torch.ops.aten.mul.Tensor(sub_41, rsqrt_41)
Input Tensors:
tensor1078, Name: sub_41, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1077, Name: rsqrt_41, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1079, Name: mul_287, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 716, Name: torch.ops.aten.mul.Tensor(squeeze_123, 0.1)
Input Tensors:
tensor1075, Name: squeeze_123, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1080, Name: mul_288, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 717, Name: torch.ops.aten.mul.Tensor(primals_285, 0.9)
Input Tensors:
tensor284, Name: primals_285, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1081, Name: mul_289, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 718, Name: torch.ops.aten.add.Tensor(mul_288, mul_289)
Input Tensors:
tensor1080, Name: mul_288, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1081, Name: mul_289, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1082, Name: add_219, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 719, Name: torch.ops.aten.mul.Tensor(squeeze_125, 1.0000797257434426)
Input Tensors:
tensor1074, Name: squeeze_125, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1083, Name: mul_290, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 720, Name: torch.ops.aten.mul.Tensor(mul_290, 0.1)
Input Tensors:
tensor1083, Name: mul_290, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1084, Name: mul_291, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 721, Name: torch.ops.aten.mul.Tensor(primals_286, 0.9)
Input Tensors:
tensor285, Name: primals_286, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1085, Name: mul_292, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 722, Name: torch.ops.aten.add.Tensor(mul_291, mul_292)
Input Tensors:
tensor1084, Name: mul_291, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1085, Name: mul_292, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1086, Name: add_220, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 723, Name: torch.ops.aten.mul.Tensor(mul_287, unsqueeze_165)
Input Tensors:
tensor1079, Name: mul_287, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor124, Name: unsqueeze_165, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor1087, Name: mul_293, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 724, Name: torch.ops.aten.add.Tensor(mul_293, unsqueeze_167)
Input Tensors:
tensor1087, Name: mul_293, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor125, Name: unsqueeze_167, Is global?: 1: Size in byte: 1024, Dimensions: f32[256, 1, 1]
Output Tensors:
tensor1088, Name: add_221, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 725, Name: torch.ops.aten.relu.default(add_221)
Input Tensors:
tensor1088, Name: add_221, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1089, Name: relu_38, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 726, Name: torch.ops.aten.convolution.default(relu_38, primals_127, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1089, Name: relu_38, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor126, Name: primals_127, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor1090, Name: convolution_42, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 727, Name: torch.ops.aten.add.Tensor(primals_290, 1)
Input Tensors:
tensor289, Name: primals_290, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1091, Name: add_222, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 728, Name: torch.ops.aten.var_mean.correction(convolution_42, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1090, Name: convolution_42, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1092, Name: getitem_86, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
tensor1093, Name: getitem_87, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 729, Name: torch.ops.aten.add.Tensor(getitem_86, 1e-05)
Input Tensors:
tensor1092, Name: getitem_86, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1094, Name: add_223, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 730, Name: torch.ops.aten.rsqrt.default(add_223)
Input Tensors:
tensor1094, Name: add_223, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1095, Name: rsqrt_42, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 731, Name: torch.ops.aten.sub.Tensor(convolution_42, getitem_87)
Input Tensors:
tensor1090, Name: convolution_42, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1093, Name: getitem_87, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1096, Name: sub_42, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 732, Name: torch.ops.aten.mul.Tensor(sub_42, rsqrt_42)
Input Tensors:
tensor1096, Name: sub_42, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1095, Name: rsqrt_42, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1097, Name: mul_294, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 733, Name: torch.ops.aten.mul.Tensor(squeeze_126, 0.1)
Input Tensors:
tensor1093, Name: squeeze_126, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1098, Name: mul_295, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 734, Name: torch.ops.aten.mul.Tensor(primals_288, 0.9)
Input Tensors:
tensor287, Name: primals_288, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1099, Name: mul_296, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 735, Name: torch.ops.aten.add.Tensor(mul_295, mul_296)
Input Tensors:
tensor1098, Name: mul_295, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1099, Name: mul_296, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1100, Name: add_224, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 736, Name: torch.ops.aten.mul.Tensor(squeeze_128, 1.0000797257434426)
Input Tensors:
tensor1092, Name: squeeze_128, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1101, Name: mul_297, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 737, Name: torch.ops.aten.mul.Tensor(mul_297, 0.1)
Input Tensors:
tensor1101, Name: mul_297, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1102, Name: mul_298, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 738, Name: torch.ops.aten.mul.Tensor(primals_289, 0.9)
Input Tensors:
tensor288, Name: primals_289, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1103, Name: mul_299, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 739, Name: torch.ops.aten.add.Tensor(mul_298, mul_299)
Input Tensors:
tensor1102, Name: mul_298, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1103, Name: mul_299, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1104, Name: add_225, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 740, Name: torch.ops.aten.mul.Tensor(mul_294, unsqueeze_169)
Input Tensors:
tensor1097, Name: mul_294, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor127, Name: unsqueeze_169, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor1105, Name: mul_300, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 741, Name: torch.ops.aten.add.Tensor(mul_300, unsqueeze_171)
Input Tensors:
tensor1105, Name: mul_300, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor128, Name: unsqueeze_171, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024, 1, 1]
Output Tensors:
tensor1106, Name: add_226, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 742, Name: torch.ops.aten.add.Tensor(add_226, relu_36)
Input Tensors:
tensor1106, Name: add_226, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1053, Name: relu_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1107, Name: add_227, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 743, Name: torch.ops.aten.relu.default(add_227)
Input Tensors:
tensor1107, Name: add_227, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1108, Name: relu_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 744, Name: torch.ops.aten.convolution.default(relu_39, primals_130, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1108, Name: relu_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor129, Name: primals_130, Is global?: 1: Size in byte: 2097152, Dimensions: f32[512, 1024, 1, 1]
Output Tensors:
tensor1109, Name: convolution_43, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 745, Name: torch.ops.aten.add.Tensor(primals_293, 1)
Input Tensors:
tensor292, Name: primals_293, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1110, Name: add_228, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 746, Name: torch.ops.aten.var_mean.correction(convolution_43, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1109, Name: convolution_43, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
Output Tensors:
tensor1111, Name: getitem_88, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor1112, Name: getitem_89, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 747, Name: torch.ops.aten.add.Tensor(getitem_88, 1e-05)
Input Tensors:
tensor1111, Name: getitem_88, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1113, Name: add_229, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 748, Name: torch.ops.aten.rsqrt.default(add_229)
Input Tensors:
tensor1113, Name: add_229, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1114, Name: rsqrt_43, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 749, Name: torch.ops.aten.sub.Tensor(convolution_43, getitem_89)
Input Tensors:
tensor1109, Name: convolution_43, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor1112, Name: getitem_89, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1115, Name: sub_43, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 750, Name: torch.ops.aten.mul.Tensor(sub_43, rsqrt_43)
Input Tensors:
tensor1115, Name: sub_43, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor1114, Name: rsqrt_43, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1116, Name: mul_301, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 751, Name: torch.ops.aten.mul.Tensor(squeeze_129, 0.1)
Input Tensors:
tensor1112, Name: squeeze_129, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1117, Name: mul_302, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 752, Name: torch.ops.aten.mul.Tensor(primals_291, 0.9)
Input Tensors:
tensor290, Name: primals_291, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1118, Name: mul_303, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 753, Name: torch.ops.aten.add.Tensor(mul_302, mul_303)
Input Tensors:
tensor1117, Name: mul_302, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1118, Name: mul_303, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1119, Name: add_230, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 754, Name: torch.ops.aten.mul.Tensor(squeeze_131, 1.0000797257434426)
Input Tensors:
tensor1111, Name: squeeze_131, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1120, Name: mul_304, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 755, Name: torch.ops.aten.mul.Tensor(mul_304, 0.1)
Input Tensors:
tensor1120, Name: mul_304, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1121, Name: mul_305, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 756, Name: torch.ops.aten.mul.Tensor(primals_292, 0.9)
Input Tensors:
tensor291, Name: primals_292, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1122, Name: mul_306, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 757, Name: torch.ops.aten.add.Tensor(mul_305, mul_306)
Input Tensors:
tensor1121, Name: mul_305, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1122, Name: mul_306, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1123, Name: add_231, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 758, Name: torch.ops.aten.mul.Tensor(mul_301, unsqueeze_173)
Input Tensors:
tensor1116, Name: mul_301, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor130, Name: unsqueeze_173, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1124, Name: mul_307, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 759, Name: torch.ops.aten.add.Tensor(mul_307, unsqueeze_175)
Input Tensors:
tensor1124, Name: mul_307, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor131, Name: unsqueeze_175, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1125, Name: add_232, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 760, Name: torch.ops.aten.relu.default(add_232)
Input Tensors:
tensor1125, Name: add_232, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
Output Tensors:
tensor1126, Name: relu_40, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 761, Name: torch.ops.aten.convolution.default(relu_40, primals_133, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1126, Name: relu_40, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor132, Name: primals_133, Is global?: 1: Size in byte: 9437184, Dimensions: f32[512, 512, 3, 3]
Output Tensors:
tensor1127, Name: convolution_44, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 762, Name: torch.ops.aten.add.Tensor(primals_296, 1)
Input Tensors:
tensor295, Name: primals_296, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1128, Name: add_233, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 763, Name: torch.ops.aten.var_mean.correction(convolution_44, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1127, Name: convolution_44, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1129, Name: getitem_90, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor1130, Name: getitem_91, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 764, Name: torch.ops.aten.add.Tensor(getitem_90, 1e-05)
Input Tensors:
tensor1129, Name: getitem_90, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1131, Name: add_234, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 765, Name: torch.ops.aten.rsqrt.default(add_234)
Input Tensors:
tensor1131, Name: add_234, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1132, Name: rsqrt_44, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 766, Name: torch.ops.aten.sub.Tensor(convolution_44, getitem_91)
Input Tensors:
tensor1127, Name: convolution_44, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1130, Name: getitem_91, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1133, Name: sub_44, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 767, Name: torch.ops.aten.mul.Tensor(sub_44, rsqrt_44)
Input Tensors:
tensor1133, Name: sub_44, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1132, Name: rsqrt_44, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1134, Name: mul_308, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 768, Name: torch.ops.aten.mul.Tensor(squeeze_132, 0.1)
Input Tensors:
tensor1130, Name: squeeze_132, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1135, Name: mul_309, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 769, Name: torch.ops.aten.mul.Tensor(primals_294, 0.9)
Input Tensors:
tensor293, Name: primals_294, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1136, Name: mul_310, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 770, Name: torch.ops.aten.add.Tensor(mul_309, mul_310)
Input Tensors:
tensor1135, Name: mul_309, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1136, Name: mul_310, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1137, Name: add_235, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 771, Name: torch.ops.aten.mul.Tensor(squeeze_134, 1.0003189792663476)
Input Tensors:
tensor1129, Name: squeeze_134, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1138, Name: mul_311, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 772, Name: torch.ops.aten.mul.Tensor(mul_311, 0.1)
Input Tensors:
tensor1138, Name: mul_311, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1139, Name: mul_312, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 773, Name: torch.ops.aten.mul.Tensor(primals_295, 0.9)
Input Tensors:
tensor294, Name: primals_295, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1140, Name: mul_313, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 774, Name: torch.ops.aten.add.Tensor(mul_312, mul_313)
Input Tensors:
tensor1139, Name: mul_312, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1140, Name: mul_313, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1141, Name: add_236, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 775, Name: torch.ops.aten.mul.Tensor(mul_308, unsqueeze_177)
Input Tensors:
tensor1134, Name: mul_308, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor133, Name: unsqueeze_177, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1142, Name: mul_314, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 776, Name: torch.ops.aten.add.Tensor(mul_314, unsqueeze_179)
Input Tensors:
tensor1142, Name: mul_314, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor134, Name: unsqueeze_179, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1143, Name: add_237, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 777, Name: torch.ops.aten.relu.default(add_237)
Input Tensors:
tensor1143, Name: add_237, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1144, Name: relu_41, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 778, Name: torch.ops.aten.convolution.default(relu_41, primals_136, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1144, Name: relu_41, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor135, Name: primals_136, Is global?: 1: Size in byte: 4194304, Dimensions: f32[2048, 512, 1, 1]
Output Tensors:
tensor1145, Name: convolution_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 779, Name: torch.ops.aten.add.Tensor(primals_299, 1)
Input Tensors:
tensor298, Name: primals_299, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1146, Name: add_238, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 780, Name: torch.ops.aten.var_mean.correction(convolution_45, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1145, Name: convolution_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1147, Name: getitem_92, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
tensor1148, Name: getitem_93, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 781, Name: torch.ops.aten.add.Tensor(getitem_92, 1e-05)
Input Tensors:
tensor1147, Name: getitem_92, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1149, Name: add_239, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 782, Name: torch.ops.aten.rsqrt.default(add_239)
Input Tensors:
tensor1149, Name: add_239, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1150, Name: rsqrt_45, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 783, Name: torch.ops.aten.sub.Tensor(convolution_45, getitem_93)
Input Tensors:
tensor1145, Name: convolution_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1148, Name: getitem_93, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1151, Name: sub_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 784, Name: torch.ops.aten.mul.Tensor(sub_45, rsqrt_45)
Input Tensors:
tensor1151, Name: sub_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1150, Name: rsqrt_45, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1152, Name: mul_315, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 785, Name: torch.ops.aten.mul.Tensor(squeeze_135, 0.1)
Input Tensors:
tensor1148, Name: squeeze_135, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1153, Name: mul_316, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 786, Name: torch.ops.aten.mul.Tensor(primals_297, 0.9)
Input Tensors:
tensor296, Name: primals_297, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1154, Name: mul_317, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 787, Name: torch.ops.aten.add.Tensor(mul_316, mul_317)
Input Tensors:
tensor1153, Name: mul_316, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1154, Name: mul_317, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1155, Name: add_240, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 788, Name: torch.ops.aten.mul.Tensor(squeeze_137, 1.0003189792663476)
Input Tensors:
tensor1147, Name: squeeze_137, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1156, Name: mul_318, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 789, Name: torch.ops.aten.mul.Tensor(mul_318, 0.1)
Input Tensors:
tensor1156, Name: mul_318, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1157, Name: mul_319, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 790, Name: torch.ops.aten.mul.Tensor(primals_298, 0.9)
Input Tensors:
tensor297, Name: primals_298, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1158, Name: mul_320, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 791, Name: torch.ops.aten.add.Tensor(mul_319, mul_320)
Input Tensors:
tensor1157, Name: mul_319, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1158, Name: mul_320, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1159, Name: add_241, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 792, Name: torch.ops.aten.mul.Tensor(mul_315, unsqueeze_181)
Input Tensors:
tensor1152, Name: mul_315, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor136, Name: unsqueeze_181, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048, 1, 1]
Output Tensors:
tensor1160, Name: mul_321, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 793, Name: torch.ops.aten.add.Tensor(mul_321, unsqueeze_183)
Input Tensors:
tensor1160, Name: mul_321, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor137, Name: unsqueeze_183, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048, 1, 1]
Output Tensors:
tensor1161, Name: add_242, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 794, Name: torch.ops.aten.convolution.default(relu_39, primals_139, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1108, Name: relu_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor138, Name: primals_139, Is global?: 1: Size in byte: 8388608, Dimensions: f32[2048, 1024, 1, 1]
Output Tensors:
tensor1162, Name: convolution_46, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 795, Name: torch.ops.aten.add.Tensor(primals_302, 1)
Input Tensors:
tensor301, Name: primals_302, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1163, Name: add_243, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 796, Name: torch.ops.aten.var_mean.correction(convolution_46, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1162, Name: convolution_46, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1164, Name: getitem_94, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
tensor1165, Name: getitem_95, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 797, Name: torch.ops.aten.add.Tensor(getitem_94, 1e-05)
Input Tensors:
tensor1164, Name: getitem_94, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1166, Name: add_244, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 798, Name: torch.ops.aten.rsqrt.default(add_244)
Input Tensors:
tensor1166, Name: add_244, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1167, Name: rsqrt_46, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 799, Name: torch.ops.aten.sub.Tensor(convolution_46, getitem_95)
Input Tensors:
tensor1162, Name: convolution_46, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1165, Name: getitem_95, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1168, Name: sub_46, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 800, Name: torch.ops.aten.mul.Tensor(sub_46, rsqrt_46)
Input Tensors:
tensor1168, Name: sub_46, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1167, Name: rsqrt_46, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1169, Name: mul_322, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 801, Name: torch.ops.aten.mul.Tensor(squeeze_138, 0.1)
Input Tensors:
tensor1165, Name: squeeze_138, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1170, Name: mul_323, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 802, Name: torch.ops.aten.mul.Tensor(primals_300, 0.9)
Input Tensors:
tensor299, Name: primals_300, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1171, Name: mul_324, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 803, Name: torch.ops.aten.add.Tensor(mul_323, mul_324)
Input Tensors:
tensor1170, Name: mul_323, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1171, Name: mul_324, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1172, Name: add_245, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 804, Name: torch.ops.aten.mul.Tensor(squeeze_140, 1.0003189792663476)
Input Tensors:
tensor1164, Name: squeeze_140, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1173, Name: mul_325, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 805, Name: torch.ops.aten.mul.Tensor(mul_325, 0.1)
Input Tensors:
tensor1173, Name: mul_325, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1174, Name: mul_326, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 806, Name: torch.ops.aten.mul.Tensor(primals_301, 0.9)
Input Tensors:
tensor300, Name: primals_301, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1175, Name: mul_327, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 807, Name: torch.ops.aten.add.Tensor(mul_326, mul_327)
Input Tensors:
tensor1174, Name: mul_326, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1175, Name: mul_327, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1176, Name: add_246, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 808, Name: torch.ops.aten.mul.Tensor(mul_322, unsqueeze_185)
Input Tensors:
tensor1169, Name: mul_322, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor139, Name: unsqueeze_185, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048, 1, 1]
Output Tensors:
tensor1177, Name: mul_328, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 809, Name: torch.ops.aten.add.Tensor(mul_328, unsqueeze_187)
Input Tensors:
tensor1177, Name: mul_328, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor140, Name: unsqueeze_187, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048, 1, 1]
Output Tensors:
tensor1178, Name: add_247, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 810, Name: torch.ops.aten.add.Tensor(add_242, add_247)
Input Tensors:
tensor1161, Name: add_242, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1178, Name: add_247, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1179, Name: add_248, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 811, Name: torch.ops.aten.relu.default(add_248)
Input Tensors:
tensor1179, Name: add_248, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1180, Name: relu_42, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 812, Name: torch.ops.aten.convolution.default(relu_42, primals_142, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1180, Name: relu_42, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor141, Name: primals_142, Is global?: 1: Size in byte: 4194304, Dimensions: f32[512, 2048, 1, 1]
Output Tensors:
tensor1181, Name: convolution_47, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 813, Name: torch.ops.aten.add.Tensor(primals_305, 1)
Input Tensors:
tensor304, Name: primals_305, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1182, Name: add_249, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 814, Name: torch.ops.aten.var_mean.correction(convolution_47, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1181, Name: convolution_47, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1183, Name: getitem_96, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor1184, Name: getitem_97, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 815, Name: torch.ops.aten.add.Tensor(getitem_96, 1e-05)
Input Tensors:
tensor1183, Name: getitem_96, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1185, Name: add_250, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 816, Name: torch.ops.aten.rsqrt.default(add_250)
Input Tensors:
tensor1185, Name: add_250, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1186, Name: rsqrt_47, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 817, Name: torch.ops.aten.sub.Tensor(convolution_47, getitem_97)
Input Tensors:
tensor1181, Name: convolution_47, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1184, Name: getitem_97, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1187, Name: sub_47, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 818, Name: torch.ops.aten.mul.Tensor(sub_47, rsqrt_47)
Input Tensors:
tensor1187, Name: sub_47, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1186, Name: rsqrt_47, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1188, Name: mul_329, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 819, Name: torch.ops.aten.mul.Tensor(squeeze_141, 0.1)
Input Tensors:
tensor1184, Name: squeeze_141, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1189, Name: mul_330, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 820, Name: torch.ops.aten.mul.Tensor(primals_303, 0.9)
Input Tensors:
tensor302, Name: primals_303, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1190, Name: mul_331, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 821, Name: torch.ops.aten.add.Tensor(mul_330, mul_331)
Input Tensors:
tensor1189, Name: mul_330, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1190, Name: mul_331, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1191, Name: add_251, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 822, Name: torch.ops.aten.mul.Tensor(squeeze_143, 1.0003189792663476)
Input Tensors:
tensor1183, Name: squeeze_143, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1192, Name: mul_332, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 823, Name: torch.ops.aten.mul.Tensor(mul_332, 0.1)
Input Tensors:
tensor1192, Name: mul_332, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1193, Name: mul_333, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 824, Name: torch.ops.aten.mul.Tensor(primals_304, 0.9)
Input Tensors:
tensor303, Name: primals_304, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1194, Name: mul_334, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 825, Name: torch.ops.aten.add.Tensor(mul_333, mul_334)
Input Tensors:
tensor1193, Name: mul_333, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1194, Name: mul_334, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1195, Name: add_252, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 826, Name: torch.ops.aten.mul.Tensor(mul_329, unsqueeze_189)
Input Tensors:
tensor1188, Name: mul_329, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor142, Name: unsqueeze_189, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1196, Name: mul_335, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 827, Name: torch.ops.aten.add.Tensor(mul_335, unsqueeze_191)
Input Tensors:
tensor1196, Name: mul_335, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor143, Name: unsqueeze_191, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1197, Name: add_253, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 828, Name: torch.ops.aten.relu.default(add_253)
Input Tensors:
tensor1197, Name: add_253, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1198, Name: relu_43, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 829, Name: torch.ops.aten.convolution.default(relu_43, primals_145, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1198, Name: relu_43, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor144, Name: primals_145, Is global?: 1: Size in byte: 9437184, Dimensions: f32[512, 512, 3, 3]
Output Tensors:
tensor1199, Name: convolution_48, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 830, Name: torch.ops.aten.add.Tensor(primals_308, 1)
Input Tensors:
tensor307, Name: primals_308, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1200, Name: add_254, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 831, Name: torch.ops.aten.var_mean.correction(convolution_48, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1199, Name: convolution_48, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1201, Name: getitem_98, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor1202, Name: getitem_99, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 832, Name: torch.ops.aten.add.Tensor(getitem_98, 1e-05)
Input Tensors:
tensor1201, Name: getitem_98, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1203, Name: add_255, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 833, Name: torch.ops.aten.rsqrt.default(add_255)
Input Tensors:
tensor1203, Name: add_255, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1204, Name: rsqrt_48, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 834, Name: torch.ops.aten.sub.Tensor(convolution_48, getitem_99)
Input Tensors:
tensor1199, Name: convolution_48, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1202, Name: getitem_99, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1205, Name: sub_48, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 835, Name: torch.ops.aten.mul.Tensor(sub_48, rsqrt_48)
Input Tensors:
tensor1205, Name: sub_48, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1204, Name: rsqrt_48, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1206, Name: mul_336, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 836, Name: torch.ops.aten.mul.Tensor(squeeze_144, 0.1)
Input Tensors:
tensor1202, Name: squeeze_144, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1207, Name: mul_337, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 837, Name: torch.ops.aten.mul.Tensor(primals_306, 0.9)
Input Tensors:
tensor305, Name: primals_306, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1208, Name: mul_338, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 838, Name: torch.ops.aten.add.Tensor(mul_337, mul_338)
Input Tensors:
tensor1207, Name: mul_337, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1208, Name: mul_338, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1209, Name: add_256, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 839, Name: torch.ops.aten.mul.Tensor(squeeze_146, 1.0003189792663476)
Input Tensors:
tensor1201, Name: squeeze_146, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1210, Name: mul_339, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 840, Name: torch.ops.aten.mul.Tensor(mul_339, 0.1)
Input Tensors:
tensor1210, Name: mul_339, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1211, Name: mul_340, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 841, Name: torch.ops.aten.mul.Tensor(primals_307, 0.9)
Input Tensors:
tensor306, Name: primals_307, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1212, Name: mul_341, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 842, Name: torch.ops.aten.add.Tensor(mul_340, mul_341)
Input Tensors:
tensor1211, Name: mul_340, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1212, Name: mul_341, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1213, Name: add_257, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 843, Name: torch.ops.aten.mul.Tensor(mul_336, unsqueeze_193)
Input Tensors:
tensor1206, Name: mul_336, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor145, Name: unsqueeze_193, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1214, Name: mul_342, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 844, Name: torch.ops.aten.add.Tensor(mul_342, unsqueeze_195)
Input Tensors:
tensor1214, Name: mul_342, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor146, Name: unsqueeze_195, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1215, Name: add_258, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 845, Name: torch.ops.aten.relu.default(add_258)
Input Tensors:
tensor1215, Name: add_258, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1216, Name: relu_44, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 846, Name: torch.ops.aten.convolution.default(relu_44, primals_148, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1216, Name: relu_44, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor147, Name: primals_148, Is global?: 1: Size in byte: 4194304, Dimensions: f32[2048, 512, 1, 1]
Output Tensors:
tensor1217, Name: convolution_49, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 847, Name: torch.ops.aten.add.Tensor(primals_311, 1)
Input Tensors:
tensor310, Name: primals_311, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1218, Name: add_259, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 848, Name: torch.ops.aten.var_mean.correction(convolution_49, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1217, Name: convolution_49, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1219, Name: getitem_100, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
tensor1220, Name: getitem_101, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 849, Name: torch.ops.aten.add.Tensor(getitem_100, 1e-05)
Input Tensors:
tensor1219, Name: getitem_100, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1221, Name: add_260, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 850, Name: torch.ops.aten.rsqrt.default(add_260)
Input Tensors:
tensor1221, Name: add_260, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1222, Name: rsqrt_49, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 851, Name: torch.ops.aten.sub.Tensor(convolution_49, getitem_101)
Input Tensors:
tensor1217, Name: convolution_49, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1220, Name: getitem_101, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1223, Name: sub_49, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 852, Name: torch.ops.aten.mul.Tensor(sub_49, rsqrt_49)
Input Tensors:
tensor1223, Name: sub_49, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1222, Name: rsqrt_49, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1224, Name: mul_343, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 853, Name: torch.ops.aten.mul.Tensor(squeeze_147, 0.1)
Input Tensors:
tensor1220, Name: squeeze_147, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1225, Name: mul_344, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 854, Name: torch.ops.aten.mul.Tensor(primals_309, 0.9)
Input Tensors:
tensor308, Name: primals_309, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1226, Name: mul_345, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 855, Name: torch.ops.aten.add.Tensor(mul_344, mul_345)
Input Tensors:
tensor1225, Name: mul_344, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1226, Name: mul_345, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1227, Name: add_261, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 856, Name: torch.ops.aten.mul.Tensor(squeeze_149, 1.0003189792663476)
Input Tensors:
tensor1219, Name: squeeze_149, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1228, Name: mul_346, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 857, Name: torch.ops.aten.mul.Tensor(mul_346, 0.1)
Input Tensors:
tensor1228, Name: mul_346, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1229, Name: mul_347, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 858, Name: torch.ops.aten.mul.Tensor(primals_310, 0.9)
Input Tensors:
tensor309, Name: primals_310, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1230, Name: mul_348, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 859, Name: torch.ops.aten.add.Tensor(mul_347, mul_348)
Input Tensors:
tensor1229, Name: mul_347, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1230, Name: mul_348, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1231, Name: add_262, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 860, Name: torch.ops.aten.mul.Tensor(mul_343, unsqueeze_197)
Input Tensors:
tensor1224, Name: mul_343, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor148, Name: unsqueeze_197, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048, 1, 1]
Output Tensors:
tensor1232, Name: mul_349, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 861, Name: torch.ops.aten.add.Tensor(mul_349, unsqueeze_199)
Input Tensors:
tensor1232, Name: mul_349, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor149, Name: unsqueeze_199, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048, 1, 1]
Output Tensors:
tensor1233, Name: add_263, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 862, Name: torch.ops.aten.add.Tensor(add_263, relu_42)
Input Tensors:
tensor1233, Name: add_263, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1180, Name: relu_42, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1234, Name: add_264, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 863, Name: torch.ops.aten.relu.default(add_264)
Input Tensors:
tensor1234, Name: add_264, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1235, Name: relu_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 864, Name: torch.ops.aten.convolution.default(relu_45, primals_151, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1235, Name: relu_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor150, Name: primals_151, Is global?: 1: Size in byte: 4194304, Dimensions: f32[512, 2048, 1, 1]
Output Tensors:
tensor1236, Name: convolution_50, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 865, Name: torch.ops.aten.add.Tensor(primals_314, 1)
Input Tensors:
tensor313, Name: primals_314, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1237, Name: add_265, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 866, Name: torch.ops.aten.var_mean.correction(convolution_50, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1236, Name: convolution_50, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1238, Name: getitem_102, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor1239, Name: getitem_103, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 867, Name: torch.ops.aten.add.Tensor(getitem_102, 1e-05)
Input Tensors:
tensor1238, Name: getitem_102, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1240, Name: add_266, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 868, Name: torch.ops.aten.rsqrt.default(add_266)
Input Tensors:
tensor1240, Name: add_266, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1241, Name: rsqrt_50, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 869, Name: torch.ops.aten.sub.Tensor(convolution_50, getitem_103)
Input Tensors:
tensor1236, Name: convolution_50, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1239, Name: getitem_103, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1242, Name: sub_50, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 870, Name: torch.ops.aten.mul.Tensor(sub_50, rsqrt_50)
Input Tensors:
tensor1242, Name: sub_50, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1241, Name: rsqrt_50, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1243, Name: mul_350, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 871, Name: torch.ops.aten.mul.Tensor(squeeze_150, 0.1)
Input Tensors:
tensor1239, Name: squeeze_150, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1244, Name: mul_351, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 872, Name: torch.ops.aten.mul.Tensor(primals_312, 0.9)
Input Tensors:
tensor311, Name: primals_312, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1245, Name: mul_352, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 873, Name: torch.ops.aten.add.Tensor(mul_351, mul_352)
Input Tensors:
tensor1244, Name: mul_351, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1245, Name: mul_352, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1246, Name: add_267, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 874, Name: torch.ops.aten.mul.Tensor(squeeze_152, 1.0003189792663476)
Input Tensors:
tensor1238, Name: squeeze_152, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1247, Name: mul_353, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 875, Name: torch.ops.aten.mul.Tensor(mul_353, 0.1)
Input Tensors:
tensor1247, Name: mul_353, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1248, Name: mul_354, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 876, Name: torch.ops.aten.mul.Tensor(primals_313, 0.9)
Input Tensors:
tensor312, Name: primals_313, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1249, Name: mul_355, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 877, Name: torch.ops.aten.add.Tensor(mul_354, mul_355)
Input Tensors:
tensor1248, Name: mul_354, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1249, Name: mul_355, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1250, Name: add_268, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 878, Name: torch.ops.aten.mul.Tensor(mul_350, unsqueeze_201)
Input Tensors:
tensor1243, Name: mul_350, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor151, Name: unsqueeze_201, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1251, Name: mul_356, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 879, Name: torch.ops.aten.add.Tensor(mul_356, unsqueeze_203)
Input Tensors:
tensor1251, Name: mul_356, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor152, Name: unsqueeze_203, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1252, Name: add_269, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 880, Name: torch.ops.aten.relu.default(add_269)
Input Tensors:
tensor1252, Name: add_269, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1253, Name: relu_46, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 881, Name: torch.ops.aten.convolution.default(relu_46, primals_154, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1253, Name: relu_46, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor153, Name: primals_154, Is global?: 1: Size in byte: 9437184, Dimensions: f32[512, 512, 3, 3]
Output Tensors:
tensor1254, Name: convolution_51, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 882, Name: torch.ops.aten.add.Tensor(primals_317, 1)
Input Tensors:
tensor316, Name: primals_317, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1255, Name: add_270, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 883, Name: torch.ops.aten.var_mean.correction(convolution_51, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1254, Name: convolution_51, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1256, Name: getitem_104, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
tensor1257, Name: getitem_105, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 884, Name: torch.ops.aten.add.Tensor(getitem_104, 1e-05)
Input Tensors:
tensor1256, Name: getitem_104, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1258, Name: add_271, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 885, Name: torch.ops.aten.rsqrt.default(add_271)
Input Tensors:
tensor1258, Name: add_271, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1259, Name: rsqrt_51, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
____________________________________________________________________
Kernel ID: 886, Name: torch.ops.aten.sub.Tensor(convolution_51, getitem_105)
Input Tensors:
tensor1254, Name: convolution_51, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1257, Name: getitem_105, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1260, Name: sub_51, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 887, Name: torch.ops.aten.mul.Tensor(sub_51, rsqrt_51)
Input Tensors:
tensor1260, Name: sub_51, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1259, Name: rsqrt_51, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1261, Name: mul_357, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 888, Name: torch.ops.aten.mul.Tensor(squeeze_153, 0.1)
Input Tensors:
tensor1257, Name: squeeze_153, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1262, Name: mul_358, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 889, Name: torch.ops.aten.mul.Tensor(primals_315, 0.9)
Input Tensors:
tensor314, Name: primals_315, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1263, Name: mul_359, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 890, Name: torch.ops.aten.add.Tensor(mul_358, mul_359)
Input Tensors:
tensor1262, Name: mul_358, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1263, Name: mul_359, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1264, Name: add_272, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 891, Name: torch.ops.aten.mul.Tensor(squeeze_155, 1.0003189792663476)
Input Tensors:
tensor1256, Name: squeeze_155, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1265, Name: mul_360, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 892, Name: torch.ops.aten.mul.Tensor(mul_360, 0.1)
Input Tensors:
tensor1265, Name: mul_360, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1266, Name: mul_361, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 893, Name: torch.ops.aten.mul.Tensor(primals_316, 0.9)
Input Tensors:
tensor315, Name: primals_316, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1267, Name: mul_362, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 894, Name: torch.ops.aten.add.Tensor(mul_361, mul_362)
Input Tensors:
tensor1266, Name: mul_361, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1267, Name: mul_362, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1268, Name: add_273, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 895, Name: torch.ops.aten.mul.Tensor(mul_357, unsqueeze_205)
Input Tensors:
tensor1261, Name: mul_357, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor154, Name: unsqueeze_205, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1269, Name: mul_363, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 896, Name: torch.ops.aten.add.Tensor(mul_363, unsqueeze_207)
Input Tensors:
tensor1269, Name: mul_363, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor155, Name: unsqueeze_207, Is global?: 1: Size in byte: 2048, Dimensions: f32[512, 1, 1]
Output Tensors:
tensor1270, Name: add_274, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 897, Name: torch.ops.aten.relu.default(add_274)
Input Tensors:
tensor1270, Name: add_274, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1271, Name: relu_47, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 898, Name: torch.ops.aten.convolution.default(relu_47, primals_157, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
Input Tensors:
tensor1271, Name: relu_47, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor156, Name: primals_157, Is global?: 1: Size in byte: 4194304, Dimensions: f32[2048, 512, 1, 1]
Output Tensors:
tensor1272, Name: convolution_52, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 899, Name: torch.ops.aten.add.Tensor(primals_320, 1)
Input Tensors:
tensor319, Name: primals_320, Is global?: 1: Size in byte: 8, Dimensions: i64[]
Output Tensors:
tensor1273, Name: add_275, Is global?: 0: Size in byte: 8, Dimensions: i64[]
____________________________________________________________________
Kernel ID: 900, Name: torch.ops.aten.var_mean.correction(convolution_52, [0, 2, 3], correction = 0, keepdim = True)
Input Tensors:
tensor1272, Name: convolution_52, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1274, Name: getitem_106, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
tensor1275, Name: getitem_107, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 901, Name: torch.ops.aten.add.Tensor(getitem_106, 1e-05)
Input Tensors:
tensor1274, Name: getitem_106, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1276, Name: add_276, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 902, Name: torch.ops.aten.rsqrt.default(add_276)
Input Tensors:
tensor1276, Name: add_276, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1277, Name: rsqrt_52, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 903, Name: torch.ops.aten.sub.Tensor(convolution_52, getitem_107)
Input Tensors:
tensor1272, Name: convolution_52, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1275, Name: getitem_107, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1278, Name: sub_52, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 904, Name: torch.ops.aten.mul.Tensor(sub_52, rsqrt_52)
Input Tensors:
tensor1278, Name: sub_52, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1277, Name: rsqrt_52, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1279, Name: mul_364, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 905, Name: torch.ops.aten.mul.Tensor(squeeze_156, 0.1)
Input Tensors:
tensor1275, Name: squeeze_156, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1280, Name: mul_365, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 906, Name: torch.ops.aten.mul.Tensor(primals_318, 0.9)
Input Tensors:
tensor317, Name: primals_318, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1281, Name: mul_366, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 907, Name: torch.ops.aten.add.Tensor(mul_365, mul_366)
Input Tensors:
tensor1280, Name: mul_365, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1281, Name: mul_366, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1282, Name: add_277, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 908, Name: torch.ops.aten.mul.Tensor(squeeze_158, 1.0003189792663476)
Input Tensors:
tensor1274, Name: squeeze_158, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1283, Name: mul_367, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 909, Name: torch.ops.aten.mul.Tensor(mul_367, 0.1)
Input Tensors:
tensor1283, Name: mul_367, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1284, Name: mul_368, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 910, Name: torch.ops.aten.mul.Tensor(primals_319, 0.9)
Input Tensors:
tensor318, Name: primals_319, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1285, Name: mul_369, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 911, Name: torch.ops.aten.add.Tensor(mul_368, mul_369)
Input Tensors:
tensor1284, Name: mul_368, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1285, Name: mul_369, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1286, Name: add_278, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 912, Name: torch.ops.aten.mul.Tensor(mul_364, unsqueeze_209)
Input Tensors:
tensor1279, Name: mul_364, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor157, Name: unsqueeze_209, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048, 1, 1]
Output Tensors:
tensor1287, Name: mul_370, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 913, Name: torch.ops.aten.add.Tensor(mul_370, unsqueeze_211)
Input Tensors:
tensor1287, Name: mul_370, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor158, Name: unsqueeze_211, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048, 1, 1]
Output Tensors:
tensor1288, Name: add_279, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 914, Name: torch.ops.aten.add.Tensor(add_279, relu_45)
Input Tensors:
tensor1288, Name: add_279, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1235, Name: relu_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1289, Name: add_280, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 915, Name: torch.ops.aten.relu.default(add_280)
Input Tensors:
tensor1289, Name: add_280, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1290, Name: relu_48, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 916, Name: torch.ops.aten.mean.dim(relu_48, [-1, -2], True)
Input Tensors:
tensor1290, Name: relu_48, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1291, Name: mean, Is global?: 0: Size in byte: 524288, Dimensions: f32[64, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 917, Name: torch.ops.aten.reshape.default(mean, [64, -1])
Input Tensors:
tensor1291, Name: mean, Is global?: 0: Size in byte: 524288, Dimensions: f32[64, 2048, 1, 1]
Output Tensors:
tensor1292, Name: view, Is global?: 0: Size in byte: 524288, Dimensions: f32[64, 2048]
____________________________________________________________________
Kernel ID: 918, Name: torch.ops.aten.permute.default(primals_160, [1, 0])
Input Tensors:
tensor159, Name: primals_160, Is global?: 1: Size in byte: 8192000, Dimensions: f32[1000, 2048]
Output Tensors:
tensor1293, Name: permute, Is global?: 0: Size in byte: 8192000, Dimensions: f32[2048, 1000]
____________________________________________________________________
Kernel ID: 919, Name: torch.ops.aten.addmm.default(primals_161, view, permute)
Input Tensors:
tensor160, Name: primals_161, Is global?: 1: Size in byte: 4000, Dimensions: f32[1000]
tensor1292, Name: view, Is global?: 0: Size in byte: 524288, Dimensions: f32[64, 2048]
tensor1293, Name: permute, Is global?: 0: Size in byte: 8192000, Dimensions: f32[2048, 1000]
Output Tensors:
tensor1294, Name: addmm, Is global?: 0: Size in byte: 256000, Dimensions: f32[64, 1000]
____________________________________________________________________
Kernel ID: 920, Name: torch.ops.aten.permute.default(permute, [1, 0])
Input Tensors:
tensor1293, Name: permute, Is global?: 0: Size in byte: 8192000, Dimensions: f32[2048, 1000]
Output Tensors:
tensor1295, Name: permute_1, Is global?: 0: Size in byte: 8192000, Dimensions: f32[1000, 2048]
____________________________________________________________________
Kernel ID: 921, Name: torch.ops.aten.le.Scalar(relu_48, 0)
Input Tensors:
tensor1290, Name: relu_48, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1296, Name: le, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 922, Name: torch.ops.aten.mm.default(tangents_1, permute_1)
Input Tensors:
tensor1297, Name: tangents_1, Is global?: 0: Size in byte: 256000, Dimensions: f32[64, 1000]
tensor1295, Name: permute_1, Is global?: 0: Size in byte: 8192000, Dimensions: f32[1000, 2048]
Output Tensors:
tensor1298, Name: mm, Is global?: 0: Size in byte: 524288, Dimensions: f32[64, 2048]
____________________________________________________________________
Kernel ID: 923, Name: torch.ops.aten.permute.default(tangents_1, [1, 0])
Input Tensors:
tensor1297, Name: tangents_1, Is global?: 0: Size in byte: 256000, Dimensions: f32[64, 1000]
Output Tensors:
tensor1299, Name: permute_2, Is global?: 0: Size in byte: 256000, Dimensions: f32[1000, 64]
____________________________________________________________________
Kernel ID: 924, Name: torch.ops.aten.mm.default(permute_2, view)
Input Tensors:
tensor1299, Name: permute_2, Is global?: 0: Size in byte: 256000, Dimensions: f32[1000, 64]
tensor1292, Name: view, Is global?: 0: Size in byte: 524288, Dimensions: f32[64, 2048]
Output Tensors:
tensor1300, Name: mm_1, Is global?: 0: Size in byte: 8192000, Dimensions: f32[1000, 2048]
____________________________________________________________________
Kernel ID: 925, Name: torch.ops.aten.permute.default(mm_1, [1, 0])
Input Tensors:
tensor1300, Name: mm_1, Is global?: 0: Size in byte: 8192000, Dimensions: f32[1000, 2048]
Output Tensors:
tensor1301, Name: permute_3, Is global?: 0: Size in byte: 8192000, Dimensions: f32[2048, 1000]
____________________________________________________________________
Kernel ID: 926, Name: torch.ops.aten.sum.dim_IntList(tangents_1, [0], True)
Input Tensors:
tensor1297, Name: tangents_1, Is global?: 0: Size in byte: 256000, Dimensions: f32[64, 1000]
Output Tensors:
tensor1302, Name: sum_1, Is global?: 0: Size in byte: 4000, Dimensions: f32[1, 1000]
____________________________________________________________________
Kernel ID: 927, Name: torch.ops.aten.reshape.default(sum_1, [1000])
Input Tensors:
tensor1302, Name: sum_1, Is global?: 0: Size in byte: 4000, Dimensions: f32[1, 1000]
Output Tensors:
tensor1303, Name: view_1, Is global?: 0: Size in byte: 4000, Dimensions: f32[1000]
____________________________________________________________________
Kernel ID: 928, Name: torch.ops.aten.permute.default(permute_3, [1, 0])
Input Tensors:
tensor1301, Name: permute_3, Is global?: 0: Size in byte: 8192000, Dimensions: f32[2048, 1000]
Output Tensors:
tensor1304, Name: permute_4, Is global?: 0: Size in byte: 8192000, Dimensions: f32[1000, 2048]
____________________________________________________________________
Kernel ID: 929, Name: torch.ops.aten.reshape.default(mm, [64, 2048, 1, 1])
Input Tensors:
tensor1298, Name: mm, Is global?: 0: Size in byte: 524288, Dimensions: f32[64, 2048]
Output Tensors:
tensor1305, Name: view_2, Is global?: 0: Size in byte: 524288, Dimensions: f32[64, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 930, Name: torch.ops.aten.expand.default(view_2, [64, 2048, 7, 7])
Input Tensors:
tensor1305, Name: view_2, Is global?: 0: Size in byte: 524288, Dimensions: f32[64, 2048, 1, 1]
Output Tensors:
tensor1306, Name: expand, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 931, Name: torch.ops.aten.div.Scalar(expand, 49)
Input Tensors:
tensor1306, Name: expand, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1307, Name: div, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 932, Name: torch.ops.aten.full.default([], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
Input Tensors:
Output Tensors:
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
____________________________________________________________________
Kernel ID: 933, Name: torch.ops.aten.where.self(le, full_default, div)
Input Tensors:
tensor1296, Name: le, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 2048, 7, 7]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1307, Name: div, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1309, Name: where, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 934, Name: torch.ops.aten.sum.dim_IntList(where, [0, 2, 3])
Input Tensors:
tensor1309, Name: where, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1310, Name: sum_2, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 935, Name: torch.ops.aten.sub.Tensor(convolution_52, unsqueeze_214)
Input Tensors:
tensor1272, Name: convolution_52, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1275, Name: unsqueeze_214, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1311, Name: sub_53, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 936, Name: torch.ops.aten.mul.Tensor(where, sub_53)
Input Tensors:
tensor1309, Name: where, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1311, Name: sub_53, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1312, Name: mul_371, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 937, Name: torch.ops.aten.sum.dim_IntList(mul_371, [0, 2, 3])
Input Tensors:
tensor1312, Name: mul_371, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1313, Name: sum_3, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 938, Name: torch.ops.aten.mul.Tensor(sum_2, 0.00031887755102040814)
Input Tensors:
tensor1310, Name: sum_2, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1314, Name: mul_372, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 939, Name: torch.ops.aten.mul.Tensor(sum_3, 0.00031887755102040814)
Input Tensors:
tensor1313, Name: sum_3, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1315, Name: mul_373, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 940, Name: torch.ops.aten.mul.Tensor(squeeze_157, squeeze_157)
Input Tensors:
tensor1277, Name: squeeze_157, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1277, Name: squeeze_157, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1316, Name: mul_374, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 941, Name: torch.ops.aten.mul.Tensor(mul_373, mul_374)
Input Tensors:
tensor1315, Name: mul_373, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1316, Name: mul_374, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1317, Name: mul_375, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 942, Name: torch.ops.aten.mul.Tensor(squeeze_157, primals_158)
Input Tensors:
tensor1277, Name: squeeze_157, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor157, Name: primals_158, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1318, Name: mul_376, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 943, Name: torch.ops.aten.mul.Tensor(sub_53, unsqueeze_220)
Input Tensors:
tensor1311, Name: sub_53, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1317, Name: unsqueeze_220, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1319, Name: mul_377, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 944, Name: torch.ops.aten.sub.Tensor(where, mul_377)
Input Tensors:
tensor1309, Name: where, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1319, Name: mul_377, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1320, Name: sub_55, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 945, Name: torch.ops.aten.sub.Tensor(sub_55, unsqueeze_217)
Input Tensors:
tensor1320, Name: sub_55, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1314, Name: unsqueeze_217, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1321, Name: sub_56, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 946, Name: torch.ops.aten.mul.Tensor(sub_56, unsqueeze_223)
Input Tensors:
tensor1321, Name: sub_56, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1318, Name: unsqueeze_223, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1322, Name: mul_378, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 947, Name: torch.ops.aten.mul.Tensor(sum_3, squeeze_157)
Input Tensors:
tensor1313, Name: sum_3, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1277, Name: squeeze_157, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1323, Name: mul_379, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 948, Name: torch.ops.aten.convolution_backward.default(mul_378, relu_47, primals_157, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1322, Name: mul_378, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1271, Name: relu_47, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor156, Name: primals_157, Is global?: 1: Size in byte: 4194304, Dimensions: f32[2048, 512, 1, 1]
Output Tensors:
tensor1324, Name: getitem_108, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1325, Name: getitem_109, Is global?: 0: Size in byte: 4194304, Dimensions: f32[2048, 512, 1, 1]
____________________________________________________________________
Kernel ID: 949, Name: torch.ops.aten.le.Scalar(relu_47, 0)
Input Tensors:
tensor1271, Name: relu_47, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1326, Name: le_1, Is global?: 0: Size in byte: 1605632, Dimensions: b8[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 950, Name: torch.ops.aten.where.self(le_1, full_default, getitem_108)
Input Tensors:
tensor1326, Name: le_1, Is global?: 0: Size in byte: 1605632, Dimensions: b8[64, 512, 7, 7]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1324, Name: getitem_108, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1327, Name: where_1, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 951, Name: torch.ops.aten.sum.dim_IntList(where_1, [0, 2, 3])
Input Tensors:
tensor1327, Name: where_1, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1328, Name: sum_4, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 952, Name: torch.ops.aten.sub.Tensor(convolution_51, unsqueeze_226)
Input Tensors:
tensor1254, Name: convolution_51, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1257, Name: unsqueeze_226, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1329, Name: sub_57, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 953, Name: torch.ops.aten.mul.Tensor(where_1, sub_57)
Input Tensors:
tensor1327, Name: where_1, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1329, Name: sub_57, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1330, Name: mul_380, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 954, Name: torch.ops.aten.sum.dim_IntList(mul_380, [0, 2, 3])
Input Tensors:
tensor1330, Name: mul_380, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1331, Name: sum_5, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 955, Name: torch.ops.aten.mul.Tensor(sum_4, 0.00031887755102040814)
Input Tensors:
tensor1328, Name: sum_4, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1332, Name: mul_381, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 956, Name: torch.ops.aten.mul.Tensor(sum_5, 0.00031887755102040814)
Input Tensors:
tensor1331, Name: sum_5, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1333, Name: mul_382, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 957, Name: torch.ops.aten.mul.Tensor(squeeze_154, squeeze_154)
Input Tensors:
tensor1259, Name: squeeze_154, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1259, Name: squeeze_154, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1334, Name: mul_383, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 958, Name: torch.ops.aten.mul.Tensor(mul_382, mul_383)
Input Tensors:
tensor1333, Name: mul_382, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1334, Name: mul_383, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1335, Name: mul_384, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 959, Name: torch.ops.aten.mul.Tensor(squeeze_154, primals_155)
Input Tensors:
tensor1259, Name: squeeze_154, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor154, Name: primals_155, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1336, Name: mul_385, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 960, Name: torch.ops.aten.mul.Tensor(sub_57, unsqueeze_232)
Input Tensors:
tensor1329, Name: sub_57, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1335, Name: unsqueeze_232, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1337, Name: mul_386, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 961, Name: torch.ops.aten.sub.Tensor(where_1, mul_386)
Input Tensors:
tensor1327, Name: where_1, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1337, Name: mul_386, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1338, Name: sub_59, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 962, Name: torch.ops.aten.sub.Tensor(sub_59, unsqueeze_229)
Input Tensors:
tensor1338, Name: sub_59, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1332, Name: unsqueeze_229, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1339, Name: sub_60, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 963, Name: torch.ops.aten.mul.Tensor(sub_60, unsqueeze_235)
Input Tensors:
tensor1339, Name: sub_60, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1336, Name: unsqueeze_235, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1340, Name: mul_387, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 964, Name: torch.ops.aten.mul.Tensor(sum_5, squeeze_154)
Input Tensors:
tensor1331, Name: sum_5, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1259, Name: squeeze_154, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1341, Name: mul_388, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 965, Name: torch.ops.aten.convolution_backward.default(mul_387, relu_46, primals_154, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1340, Name: mul_387, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1253, Name: relu_46, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor153, Name: primals_154, Is global?: 1: Size in byte: 9437184, Dimensions: f32[512, 512, 3, 3]
Output Tensors:
tensor1342, Name: getitem_111, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1343, Name: getitem_112, Is global?: 0: Size in byte: 9437184, Dimensions: f32[512, 512, 3, 3]
____________________________________________________________________
Kernel ID: 966, Name: torch.ops.aten.le.Scalar(relu_46, 0)
Input Tensors:
tensor1253, Name: relu_46, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1344, Name: le_2, Is global?: 0: Size in byte: 1605632, Dimensions: b8[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 967, Name: torch.ops.aten.where.self(le_2, full_default, getitem_111)
Input Tensors:
tensor1344, Name: le_2, Is global?: 0: Size in byte: 1605632, Dimensions: b8[64, 512, 7, 7]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1342, Name: getitem_111, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1345, Name: where_2, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 968, Name: torch.ops.aten.sum.dim_IntList(where_2, [0, 2, 3])
Input Tensors:
tensor1345, Name: where_2, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1346, Name: sum_6, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 969, Name: torch.ops.aten.sub.Tensor(convolution_50, unsqueeze_238)
Input Tensors:
tensor1236, Name: convolution_50, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1239, Name: unsqueeze_238, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1347, Name: sub_61, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 970, Name: torch.ops.aten.mul.Tensor(where_2, sub_61)
Input Tensors:
tensor1345, Name: where_2, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1347, Name: sub_61, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1348, Name: mul_389, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 971, Name: torch.ops.aten.sum.dim_IntList(mul_389, [0, 2, 3])
Input Tensors:
tensor1348, Name: mul_389, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1349, Name: sum_7, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 972, Name: torch.ops.aten.mul.Tensor(sum_6, 0.00031887755102040814)
Input Tensors:
tensor1346, Name: sum_6, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1350, Name: mul_390, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 973, Name: torch.ops.aten.mul.Tensor(sum_7, 0.00031887755102040814)
Input Tensors:
tensor1349, Name: sum_7, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1351, Name: mul_391, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 974, Name: torch.ops.aten.mul.Tensor(squeeze_151, squeeze_151)
Input Tensors:
tensor1241, Name: squeeze_151, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1241, Name: squeeze_151, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1352, Name: mul_392, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 975, Name: torch.ops.aten.mul.Tensor(mul_391, mul_392)
Input Tensors:
tensor1351, Name: mul_391, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1352, Name: mul_392, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1353, Name: mul_393, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 976, Name: torch.ops.aten.mul.Tensor(squeeze_151, primals_152)
Input Tensors:
tensor1241, Name: squeeze_151, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor151, Name: primals_152, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1354, Name: mul_394, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 977, Name: torch.ops.aten.mul.Tensor(sub_61, unsqueeze_244)
Input Tensors:
tensor1347, Name: sub_61, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1353, Name: unsqueeze_244, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1355, Name: mul_395, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 978, Name: torch.ops.aten.sub.Tensor(where_2, mul_395)
Input Tensors:
tensor1345, Name: where_2, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1355, Name: mul_395, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1356, Name: sub_63, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 979, Name: torch.ops.aten.sub.Tensor(sub_63, unsqueeze_241)
Input Tensors:
tensor1356, Name: sub_63, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1350, Name: unsqueeze_241, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1357, Name: sub_64, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 980, Name: torch.ops.aten.mul.Tensor(sub_64, unsqueeze_247)
Input Tensors:
tensor1357, Name: sub_64, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1354, Name: unsqueeze_247, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1358, Name: mul_396, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 981, Name: torch.ops.aten.mul.Tensor(sum_7, squeeze_151)
Input Tensors:
tensor1349, Name: sum_7, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1241, Name: squeeze_151, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1359, Name: mul_397, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 982, Name: torch.ops.aten.convolution_backward.default(mul_396, relu_45, primals_151, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1358, Name: mul_396, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1235, Name: relu_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor150, Name: primals_151, Is global?: 1: Size in byte: 4194304, Dimensions: f32[512, 2048, 1, 1]
Output Tensors:
tensor1360, Name: getitem_114, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1361, Name: getitem_115, Is global?: 0: Size in byte: 4194304, Dimensions: f32[512, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 983, Name: torch.ops.aten.add.Tensor(where, getitem_114)
Input Tensors:
tensor1309, Name: where, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1360, Name: getitem_114, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1362, Name: add_281, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 984, Name: torch.ops.aten.le.Scalar(relu_45, 0)
Input Tensors:
tensor1235, Name: relu_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1363, Name: le_3, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 985, Name: torch.ops.aten.where.self(le_3, full_default, add_281)
Input Tensors:
tensor1363, Name: le_3, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 2048, 7, 7]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1362, Name: add_281, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1364, Name: where_3, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 986, Name: torch.ops.aten.sum.dim_IntList(where_3, [0, 2, 3])
Input Tensors:
tensor1364, Name: where_3, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1365, Name: sum_8, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 987, Name: torch.ops.aten.sub.Tensor(convolution_49, unsqueeze_250)
Input Tensors:
tensor1217, Name: convolution_49, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1220, Name: unsqueeze_250, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1366, Name: sub_65, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 988, Name: torch.ops.aten.mul.Tensor(where_3, sub_65)
Input Tensors:
tensor1364, Name: where_3, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1366, Name: sub_65, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1367, Name: mul_398, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 989, Name: torch.ops.aten.sum.dim_IntList(mul_398, [0, 2, 3])
Input Tensors:
tensor1367, Name: mul_398, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1368, Name: sum_9, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 990, Name: torch.ops.aten.mul.Tensor(sum_8, 0.00031887755102040814)
Input Tensors:
tensor1365, Name: sum_8, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1369, Name: mul_399, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 991, Name: torch.ops.aten.mul.Tensor(sum_9, 0.00031887755102040814)
Input Tensors:
tensor1368, Name: sum_9, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1370, Name: mul_400, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 992, Name: torch.ops.aten.mul.Tensor(squeeze_148, squeeze_148)
Input Tensors:
tensor1222, Name: squeeze_148, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1222, Name: squeeze_148, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1371, Name: mul_401, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 993, Name: torch.ops.aten.mul.Tensor(mul_400, mul_401)
Input Tensors:
tensor1370, Name: mul_400, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1371, Name: mul_401, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1372, Name: mul_402, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 994, Name: torch.ops.aten.mul.Tensor(squeeze_148, primals_149)
Input Tensors:
tensor1222, Name: squeeze_148, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor148, Name: primals_149, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1373, Name: mul_403, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 995, Name: torch.ops.aten.mul.Tensor(sub_65, unsqueeze_256)
Input Tensors:
tensor1366, Name: sub_65, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1372, Name: unsqueeze_256, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1374, Name: mul_404, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 996, Name: torch.ops.aten.sub.Tensor(where_3, mul_404)
Input Tensors:
tensor1364, Name: where_3, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1374, Name: mul_404, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1375, Name: sub_67, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 997, Name: torch.ops.aten.sub.Tensor(sub_67, unsqueeze_253)
Input Tensors:
tensor1375, Name: sub_67, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1369, Name: unsqueeze_253, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1376, Name: sub_68, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 998, Name: torch.ops.aten.mul.Tensor(sub_68, unsqueeze_259)
Input Tensors:
tensor1376, Name: sub_68, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1373, Name: unsqueeze_259, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1377, Name: mul_405, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 999, Name: torch.ops.aten.mul.Tensor(sum_9, squeeze_148)
Input Tensors:
tensor1368, Name: sum_9, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1222, Name: squeeze_148, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1378, Name: mul_406, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1000, Name: torch.ops.aten.convolution_backward.default(mul_405, relu_44, primals_148, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1377, Name: mul_405, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1216, Name: relu_44, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor147, Name: primals_148, Is global?: 1: Size in byte: 4194304, Dimensions: f32[2048, 512, 1, 1]
Output Tensors:
tensor1379, Name: getitem_117, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1380, Name: getitem_118, Is global?: 0: Size in byte: 4194304, Dimensions: f32[2048, 512, 1, 1]
____________________________________________________________________
Kernel ID: 1001, Name: torch.ops.aten.le.Scalar(relu_44, 0)
Input Tensors:
tensor1216, Name: relu_44, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1381, Name: le_4, Is global?: 0: Size in byte: 1605632, Dimensions: b8[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1002, Name: torch.ops.aten.where.self(le_4, full_default, getitem_117)
Input Tensors:
tensor1381, Name: le_4, Is global?: 0: Size in byte: 1605632, Dimensions: b8[64, 512, 7, 7]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1379, Name: getitem_117, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1382, Name: where_4, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1003, Name: torch.ops.aten.sum.dim_IntList(where_4, [0, 2, 3])
Input Tensors:
tensor1382, Name: where_4, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1383, Name: sum_10, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1004, Name: torch.ops.aten.sub.Tensor(convolution_48, unsqueeze_262)
Input Tensors:
tensor1199, Name: convolution_48, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1202, Name: unsqueeze_262, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1384, Name: sub_69, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1005, Name: torch.ops.aten.mul.Tensor(where_4, sub_69)
Input Tensors:
tensor1382, Name: where_4, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1384, Name: sub_69, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1385, Name: mul_407, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1006, Name: torch.ops.aten.sum.dim_IntList(mul_407, [0, 2, 3])
Input Tensors:
tensor1385, Name: mul_407, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1386, Name: sum_11, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1007, Name: torch.ops.aten.mul.Tensor(sum_10, 0.00031887755102040814)
Input Tensors:
tensor1383, Name: sum_10, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1387, Name: mul_408, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1008, Name: torch.ops.aten.mul.Tensor(sum_11, 0.00031887755102040814)
Input Tensors:
tensor1386, Name: sum_11, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1388, Name: mul_409, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1009, Name: torch.ops.aten.mul.Tensor(squeeze_145, squeeze_145)
Input Tensors:
tensor1204, Name: squeeze_145, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1204, Name: squeeze_145, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1389, Name: mul_410, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1010, Name: torch.ops.aten.mul.Tensor(mul_409, mul_410)
Input Tensors:
tensor1388, Name: mul_409, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1389, Name: mul_410, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1390, Name: mul_411, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1011, Name: torch.ops.aten.mul.Tensor(squeeze_145, primals_146)
Input Tensors:
tensor1204, Name: squeeze_145, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor145, Name: primals_146, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1391, Name: mul_412, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1012, Name: torch.ops.aten.mul.Tensor(sub_69, unsqueeze_268)
Input Tensors:
tensor1384, Name: sub_69, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1390, Name: unsqueeze_268, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1392, Name: mul_413, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1013, Name: torch.ops.aten.sub.Tensor(where_4, mul_413)
Input Tensors:
tensor1382, Name: where_4, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1392, Name: mul_413, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1393, Name: sub_71, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1014, Name: torch.ops.aten.sub.Tensor(sub_71, unsqueeze_265)
Input Tensors:
tensor1393, Name: sub_71, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1387, Name: unsqueeze_265, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1394, Name: sub_72, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1015, Name: torch.ops.aten.mul.Tensor(sub_72, unsqueeze_271)
Input Tensors:
tensor1394, Name: sub_72, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1391, Name: unsqueeze_271, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1395, Name: mul_414, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1016, Name: torch.ops.aten.mul.Tensor(sum_11, squeeze_145)
Input Tensors:
tensor1386, Name: sum_11, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1204, Name: squeeze_145, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1396, Name: mul_415, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1017, Name: torch.ops.aten.convolution_backward.default(mul_414, relu_43, primals_145, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1395, Name: mul_414, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1198, Name: relu_43, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor144, Name: primals_145, Is global?: 1: Size in byte: 9437184, Dimensions: f32[512, 512, 3, 3]
Output Tensors:
tensor1397, Name: getitem_120, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1398, Name: getitem_121, Is global?: 0: Size in byte: 9437184, Dimensions: f32[512, 512, 3, 3]
____________________________________________________________________
Kernel ID: 1018, Name: torch.ops.aten.le.Scalar(relu_43, 0)
Input Tensors:
tensor1198, Name: relu_43, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1399, Name: le_5, Is global?: 0: Size in byte: 1605632, Dimensions: b8[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1019, Name: torch.ops.aten.where.self(le_5, full_default, getitem_120)
Input Tensors:
tensor1399, Name: le_5, Is global?: 0: Size in byte: 1605632, Dimensions: b8[64, 512, 7, 7]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1397, Name: getitem_120, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1400, Name: where_5, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1020, Name: torch.ops.aten.sum.dim_IntList(where_5, [0, 2, 3])
Input Tensors:
tensor1400, Name: where_5, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1401, Name: sum_12, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1021, Name: torch.ops.aten.sub.Tensor(convolution_47, unsqueeze_274)
Input Tensors:
tensor1181, Name: convolution_47, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1184, Name: unsqueeze_274, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1402, Name: sub_73, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1022, Name: torch.ops.aten.mul.Tensor(where_5, sub_73)
Input Tensors:
tensor1400, Name: where_5, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1402, Name: sub_73, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1403, Name: mul_416, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1023, Name: torch.ops.aten.sum.dim_IntList(mul_416, [0, 2, 3])
Input Tensors:
tensor1403, Name: mul_416, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1404, Name: sum_13, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1024, Name: torch.ops.aten.mul.Tensor(sum_12, 0.00031887755102040814)
Input Tensors:
tensor1401, Name: sum_12, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1405, Name: mul_417, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1025, Name: torch.ops.aten.mul.Tensor(sum_13, 0.00031887755102040814)
Input Tensors:
tensor1404, Name: sum_13, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1406, Name: mul_418, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1026, Name: torch.ops.aten.mul.Tensor(squeeze_142, squeeze_142)
Input Tensors:
tensor1186, Name: squeeze_142, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1186, Name: squeeze_142, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1407, Name: mul_419, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1027, Name: torch.ops.aten.mul.Tensor(mul_418, mul_419)
Input Tensors:
tensor1406, Name: mul_418, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1407, Name: mul_419, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1408, Name: mul_420, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1028, Name: torch.ops.aten.mul.Tensor(squeeze_142, primals_143)
Input Tensors:
tensor1186, Name: squeeze_142, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor142, Name: primals_143, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1409, Name: mul_421, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1029, Name: torch.ops.aten.mul.Tensor(sub_73, unsqueeze_280)
Input Tensors:
tensor1402, Name: sub_73, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1408, Name: unsqueeze_280, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1410, Name: mul_422, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1030, Name: torch.ops.aten.sub.Tensor(where_5, mul_422)
Input Tensors:
tensor1400, Name: where_5, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1410, Name: mul_422, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1411, Name: sub_75, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1031, Name: torch.ops.aten.sub.Tensor(sub_75, unsqueeze_277)
Input Tensors:
tensor1411, Name: sub_75, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1405, Name: unsqueeze_277, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1412, Name: sub_76, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1032, Name: torch.ops.aten.mul.Tensor(sub_76, unsqueeze_283)
Input Tensors:
tensor1412, Name: sub_76, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1409, Name: unsqueeze_283, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1413, Name: mul_423, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1033, Name: torch.ops.aten.mul.Tensor(sum_13, squeeze_142)
Input Tensors:
tensor1404, Name: sum_13, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1186, Name: squeeze_142, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1414, Name: mul_424, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1034, Name: torch.ops.aten.convolution_backward.default(mul_423, relu_42, primals_142, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1413, Name: mul_423, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1180, Name: relu_42, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor141, Name: primals_142, Is global?: 1: Size in byte: 4194304, Dimensions: f32[512, 2048, 1, 1]
Output Tensors:
tensor1415, Name: getitem_123, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1416, Name: getitem_124, Is global?: 0: Size in byte: 4194304, Dimensions: f32[512, 2048, 1, 1]
____________________________________________________________________
Kernel ID: 1035, Name: torch.ops.aten.add.Tensor(where_3, getitem_123)
Input Tensors:
tensor1364, Name: where_3, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1415, Name: getitem_123, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1417, Name: add_282, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1036, Name: torch.ops.aten.le.Scalar(relu_42, 0)
Input Tensors:
tensor1180, Name: relu_42, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1418, Name: le_6, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1037, Name: torch.ops.aten.where.self(le_6, full_default, add_282)
Input Tensors:
tensor1418, Name: le_6, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 2048, 7, 7]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1417, Name: add_282, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1419, Name: where_6, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1038, Name: torch.ops.aten.sum.dim_IntList(where_6, [0, 2, 3])
Input Tensors:
tensor1419, Name: where_6, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1420, Name: sum_14, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1039, Name: torch.ops.aten.sub.Tensor(convolution_46, unsqueeze_286)
Input Tensors:
tensor1162, Name: convolution_46, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1165, Name: unsqueeze_286, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1421, Name: sub_77, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1040, Name: torch.ops.aten.mul.Tensor(where_6, sub_77)
Input Tensors:
tensor1419, Name: where_6, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1421, Name: sub_77, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1422, Name: mul_425, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1041, Name: torch.ops.aten.sum.dim_IntList(mul_425, [0, 2, 3])
Input Tensors:
tensor1422, Name: mul_425, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1423, Name: sum_15, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1042, Name: torch.ops.aten.mul.Tensor(sum_14, 0.00031887755102040814)
Input Tensors:
tensor1420, Name: sum_14, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1424, Name: mul_426, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1043, Name: torch.ops.aten.mul.Tensor(sum_15, 0.00031887755102040814)
Input Tensors:
tensor1423, Name: sum_15, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1425, Name: mul_427, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1044, Name: torch.ops.aten.mul.Tensor(squeeze_139, squeeze_139)
Input Tensors:
tensor1167, Name: squeeze_139, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1167, Name: squeeze_139, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1426, Name: mul_428, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1045, Name: torch.ops.aten.mul.Tensor(mul_427, mul_428)
Input Tensors:
tensor1425, Name: mul_427, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1426, Name: mul_428, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1427, Name: mul_429, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1046, Name: torch.ops.aten.mul.Tensor(squeeze_139, primals_140)
Input Tensors:
tensor1167, Name: squeeze_139, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor139, Name: primals_140, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1428, Name: mul_430, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1047, Name: torch.ops.aten.mul.Tensor(sub_77, unsqueeze_292)
Input Tensors:
tensor1421, Name: sub_77, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1427, Name: unsqueeze_292, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1429, Name: mul_431, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1048, Name: torch.ops.aten.sub.Tensor(where_6, mul_431)
Input Tensors:
tensor1419, Name: where_6, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1429, Name: mul_431, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1430, Name: sub_79, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1049, Name: torch.ops.aten.sub.Tensor(sub_79, unsqueeze_289)
Input Tensors:
tensor1430, Name: sub_79, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1424, Name: unsqueeze_289, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1431, Name: sub_80, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1050, Name: torch.ops.aten.mul.Tensor(sub_80, unsqueeze_295)
Input Tensors:
tensor1431, Name: sub_80, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1428, Name: unsqueeze_295, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1432, Name: mul_432, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1051, Name: torch.ops.aten.mul.Tensor(sum_15, squeeze_139)
Input Tensors:
tensor1423, Name: sum_15, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1167, Name: squeeze_139, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1433, Name: mul_433, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1052, Name: torch.ops.aten.convolution_backward.default(mul_432, relu_39, primals_139, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1432, Name: mul_432, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1108, Name: relu_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor138, Name: primals_139, Is global?: 1: Size in byte: 8388608, Dimensions: f32[2048, 1024, 1, 1]
Output Tensors:
tensor1434, Name: getitem_126, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1435, Name: getitem_127, Is global?: 0: Size in byte: 8388608, Dimensions: f32[2048, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 1053, Name: torch.ops.aten.sub.Tensor(convolution_45, unsqueeze_298)
Input Tensors:
tensor1145, Name: convolution_45, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1148, Name: unsqueeze_298, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1436, Name: sub_81, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1054, Name: torch.ops.aten.mul.Tensor(where_6, sub_81)
Input Tensors:
tensor1419, Name: where_6, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1436, Name: sub_81, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1437, Name: mul_434, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1055, Name: torch.ops.aten.sum.dim_IntList(mul_434, [0, 2, 3])
Input Tensors:
tensor1437, Name: mul_434, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1438, Name: sum_17, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1056, Name: torch.ops.aten.mul.Tensor(sum_17, 0.00031887755102040814)
Input Tensors:
tensor1438, Name: sum_17, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1439, Name: mul_436, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1057, Name: torch.ops.aten.mul.Tensor(squeeze_136, squeeze_136)
Input Tensors:
tensor1150, Name: squeeze_136, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1150, Name: squeeze_136, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1440, Name: mul_437, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1058, Name: torch.ops.aten.mul.Tensor(mul_436, mul_437)
Input Tensors:
tensor1439, Name: mul_436, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1440, Name: mul_437, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1441, Name: mul_438, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1059, Name: torch.ops.aten.mul.Tensor(squeeze_136, primals_137)
Input Tensors:
tensor1150, Name: squeeze_136, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor136, Name: primals_137, Is global?: 1: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1442, Name: mul_439, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1060, Name: torch.ops.aten.mul.Tensor(sub_81, unsqueeze_304)
Input Tensors:
tensor1436, Name: sub_81, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1441, Name: unsqueeze_304, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1443, Name: mul_440, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1061, Name: torch.ops.aten.sub.Tensor(where_6, mul_440)
Input Tensors:
tensor1419, Name: where_6, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1443, Name: mul_440, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
Output Tensors:
tensor1444, Name: sub_83, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1062, Name: torch.ops.aten.sub.Tensor(sub_83, unsqueeze_289)
Input Tensors:
tensor1444, Name: sub_83, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1424, Name: unsqueeze_289, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1445, Name: sub_84, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1063, Name: torch.ops.aten.mul.Tensor(sub_84, unsqueeze_307)
Input Tensors:
tensor1445, Name: sub_84, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1442, Name: unsqueeze_307, Is global?: 0: Size in byte: 8192, Dimensions: f32[1, 2048, 1, 1]
Output Tensors:
tensor1446, Name: mul_441, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
____________________________________________________________________
Kernel ID: 1064, Name: torch.ops.aten.mul.Tensor(sum_17, squeeze_136)
Input Tensors:
tensor1438, Name: sum_17, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
tensor1150, Name: squeeze_136, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
Output Tensors:
tensor1447, Name: mul_442, Is global?: 0: Size in byte: 8192, Dimensions: f32[2048]
____________________________________________________________________
Kernel ID: 1065, Name: torch.ops.aten.convolution_backward.default(mul_441, relu_41, primals_136, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1446, Name: mul_441, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 2048, 7, 7]
tensor1144, Name: relu_41, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor135, Name: primals_136, Is global?: 1: Size in byte: 4194304, Dimensions: f32[2048, 512, 1, 1]
Output Tensors:
tensor1448, Name: getitem_129, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1449, Name: getitem_130, Is global?: 0: Size in byte: 4194304, Dimensions: f32[2048, 512, 1, 1]
____________________________________________________________________
Kernel ID: 1066, Name: torch.ops.aten.le.Scalar(relu_41, 0)
Input Tensors:
tensor1144, Name: relu_41, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1450, Name: le_7, Is global?: 0: Size in byte: 1605632, Dimensions: b8[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1067, Name: torch.ops.aten.where.self(le_7, full_default, getitem_129)
Input Tensors:
tensor1450, Name: le_7, Is global?: 0: Size in byte: 1605632, Dimensions: b8[64, 512, 7, 7]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1448, Name: getitem_129, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1451, Name: where_7, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1068, Name: torch.ops.aten.sum.dim_IntList(where_7, [0, 2, 3])
Input Tensors:
tensor1451, Name: where_7, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1452, Name: sum_18, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1069, Name: torch.ops.aten.sub.Tensor(convolution_44, unsqueeze_310)
Input Tensors:
tensor1127, Name: convolution_44, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1130, Name: unsqueeze_310, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1453, Name: sub_85, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1070, Name: torch.ops.aten.mul.Tensor(where_7, sub_85)
Input Tensors:
tensor1451, Name: where_7, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1453, Name: sub_85, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1454, Name: mul_443, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1071, Name: torch.ops.aten.sum.dim_IntList(mul_443, [0, 2, 3])
Input Tensors:
tensor1454, Name: mul_443, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1455, Name: sum_19, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1072, Name: torch.ops.aten.mul.Tensor(sum_18, 0.00031887755102040814)
Input Tensors:
tensor1452, Name: sum_18, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1456, Name: mul_444, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1073, Name: torch.ops.aten.mul.Tensor(sum_19, 0.00031887755102040814)
Input Tensors:
tensor1455, Name: sum_19, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1457, Name: mul_445, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1074, Name: torch.ops.aten.mul.Tensor(squeeze_133, squeeze_133)
Input Tensors:
tensor1132, Name: squeeze_133, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1132, Name: squeeze_133, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1458, Name: mul_446, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1075, Name: torch.ops.aten.mul.Tensor(mul_445, mul_446)
Input Tensors:
tensor1457, Name: mul_445, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1458, Name: mul_446, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1459, Name: mul_447, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1076, Name: torch.ops.aten.mul.Tensor(squeeze_133, primals_134)
Input Tensors:
tensor1132, Name: squeeze_133, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor133, Name: primals_134, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1460, Name: mul_448, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1077, Name: torch.ops.aten.mul.Tensor(sub_85, unsqueeze_316)
Input Tensors:
tensor1453, Name: sub_85, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1459, Name: unsqueeze_316, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1461, Name: mul_449, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1078, Name: torch.ops.aten.sub.Tensor(where_7, mul_449)
Input Tensors:
tensor1451, Name: where_7, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1461, Name: mul_449, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
Output Tensors:
tensor1462, Name: sub_87, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1079, Name: torch.ops.aten.sub.Tensor(sub_87, unsqueeze_313)
Input Tensors:
tensor1462, Name: sub_87, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1456, Name: unsqueeze_313, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1463, Name: sub_88, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1080, Name: torch.ops.aten.mul.Tensor(sub_88, unsqueeze_319)
Input Tensors:
tensor1463, Name: sub_88, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1460, Name: unsqueeze_319, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1464, Name: mul_450, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
____________________________________________________________________
Kernel ID: 1081, Name: torch.ops.aten.mul.Tensor(sum_19, squeeze_133)
Input Tensors:
tensor1455, Name: sum_19, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1132, Name: squeeze_133, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1465, Name: mul_451, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1082, Name: torch.ops.aten.convolution_backward.default(mul_450, relu_40, primals_133, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1464, Name: mul_450, Is global?: 0: Size in byte: 6422528, Dimensions: f32[64, 512, 7, 7]
tensor1126, Name: relu_40, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor132, Name: primals_133, Is global?: 1: Size in byte: 9437184, Dimensions: f32[512, 512, 3, 3]
Output Tensors:
tensor1466, Name: getitem_132, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor1467, Name: getitem_133, Is global?: 0: Size in byte: 9437184, Dimensions: f32[512, 512, 3, 3]
____________________________________________________________________
Kernel ID: 1083, Name: torch.ops.aten.le.Scalar(relu_40, 0)
Input Tensors:
tensor1126, Name: relu_40, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
Output Tensors:
tensor1468, Name: le_8, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 1084, Name: torch.ops.aten.where.self(le_8, full_default, getitem_132)
Input Tensors:
tensor1468, Name: le_8, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 512, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1466, Name: getitem_132, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
Output Tensors:
tensor1469, Name: where_8, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 1085, Name: torch.ops.aten.sum.dim_IntList(where_8, [0, 2, 3])
Input Tensors:
tensor1469, Name: where_8, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
Output Tensors:
tensor1470, Name: sum_20, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1086, Name: torch.ops.aten.sub.Tensor(convolution_43, unsqueeze_322)
Input Tensors:
tensor1109, Name: convolution_43, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor1112, Name: unsqueeze_322, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1471, Name: sub_89, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 1087, Name: torch.ops.aten.mul.Tensor(where_8, sub_89)
Input Tensors:
tensor1469, Name: where_8, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor1471, Name: sub_89, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
Output Tensors:
tensor1472, Name: mul_452, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 1088, Name: torch.ops.aten.sum.dim_IntList(mul_452, [0, 2, 3])
Input Tensors:
tensor1472, Name: mul_452, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
Output Tensors:
tensor1473, Name: sum_21, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1089, Name: torch.ops.aten.mul.Tensor(sum_20, 7.971938775510203e-05)
Input Tensors:
tensor1470, Name: sum_20, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1474, Name: mul_453, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1090, Name: torch.ops.aten.mul.Tensor(sum_21, 7.971938775510203e-05)
Input Tensors:
tensor1473, Name: sum_21, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1475, Name: mul_454, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1091, Name: torch.ops.aten.mul.Tensor(squeeze_130, squeeze_130)
Input Tensors:
tensor1114, Name: squeeze_130, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1114, Name: squeeze_130, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1476, Name: mul_455, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1092, Name: torch.ops.aten.mul.Tensor(mul_454, mul_455)
Input Tensors:
tensor1475, Name: mul_454, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1476, Name: mul_455, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1477, Name: mul_456, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1093, Name: torch.ops.aten.mul.Tensor(squeeze_130, primals_131)
Input Tensors:
tensor1114, Name: squeeze_130, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor130, Name: primals_131, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1478, Name: mul_457, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1094, Name: torch.ops.aten.mul.Tensor(sub_89, unsqueeze_328)
Input Tensors:
tensor1471, Name: sub_89, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor1477, Name: unsqueeze_328, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1479, Name: mul_458, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 1095, Name: torch.ops.aten.sub.Tensor(where_8, mul_458)
Input Tensors:
tensor1469, Name: where_8, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor1479, Name: mul_458, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
Output Tensors:
tensor1480, Name: sub_91, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 1096, Name: torch.ops.aten.sub.Tensor(sub_91, unsqueeze_325)
Input Tensors:
tensor1480, Name: sub_91, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor1474, Name: unsqueeze_325, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1481, Name: sub_92, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 1097, Name: torch.ops.aten.mul.Tensor(sub_92, unsqueeze_331)
Input Tensors:
tensor1481, Name: sub_92, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor1478, Name: unsqueeze_331, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1482, Name: mul_459, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
____________________________________________________________________
Kernel ID: 1098, Name: torch.ops.aten.mul.Tensor(sum_21, squeeze_130)
Input Tensors:
tensor1473, Name: sum_21, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1114, Name: squeeze_130, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1483, Name: mul_460, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1099, Name: torch.ops.aten.convolution_backward.default(mul_459, relu_39, primals_130, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1482, Name: mul_459, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 512, 14, 14]
tensor1108, Name: relu_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor129, Name: primals_130, Is global?: 1: Size in byte: 2097152, Dimensions: f32[512, 1024, 1, 1]
Output Tensors:
tensor1484, Name: getitem_135, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1485, Name: getitem_136, Is global?: 0: Size in byte: 2097152, Dimensions: f32[512, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 1100, Name: torch.ops.aten.add.Tensor(getitem_126, getitem_135)
Input Tensors:
tensor1434, Name: getitem_126, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1484, Name: getitem_135, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1486, Name: add_283, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1101, Name: torch.ops.aten.le.Scalar(relu_39, 0)
Input Tensors:
tensor1108, Name: relu_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1487, Name: le_9, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1102, Name: torch.ops.aten.where.self(le_9, full_default, add_283)
Input Tensors:
tensor1487, Name: le_9, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1486, Name: add_283, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1488, Name: where_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1103, Name: torch.ops.aten.sum.dim_IntList(where_9, [0, 2, 3])
Input Tensors:
tensor1488, Name: where_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1489, Name: sum_22, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1104, Name: torch.ops.aten.sub.Tensor(convolution_42, unsqueeze_334)
Input Tensors:
tensor1090, Name: convolution_42, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1093, Name: unsqueeze_334, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1490, Name: sub_93, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1105, Name: torch.ops.aten.mul.Tensor(where_9, sub_93)
Input Tensors:
tensor1488, Name: where_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1490, Name: sub_93, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1491, Name: mul_461, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1106, Name: torch.ops.aten.sum.dim_IntList(mul_461, [0, 2, 3])
Input Tensors:
tensor1491, Name: mul_461, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1492, Name: sum_23, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1107, Name: torch.ops.aten.mul.Tensor(sum_22, 7.971938775510203e-05)
Input Tensors:
tensor1489, Name: sum_22, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1493, Name: mul_462, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1108, Name: torch.ops.aten.mul.Tensor(sum_23, 7.971938775510203e-05)
Input Tensors:
tensor1492, Name: sum_23, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1494, Name: mul_463, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1109, Name: torch.ops.aten.mul.Tensor(squeeze_127, squeeze_127)
Input Tensors:
tensor1095, Name: squeeze_127, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1095, Name: squeeze_127, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1495, Name: mul_464, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1110, Name: torch.ops.aten.mul.Tensor(mul_463, mul_464)
Input Tensors:
tensor1494, Name: mul_463, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1495, Name: mul_464, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1496, Name: mul_465, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1111, Name: torch.ops.aten.mul.Tensor(squeeze_127, primals_128)
Input Tensors:
tensor1095, Name: squeeze_127, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor127, Name: primals_128, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1497, Name: mul_466, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1112, Name: torch.ops.aten.mul.Tensor(sub_93, unsqueeze_340)
Input Tensors:
tensor1490, Name: sub_93, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1496, Name: unsqueeze_340, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1498, Name: mul_467, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1113, Name: torch.ops.aten.sub.Tensor(where_9, mul_467)
Input Tensors:
tensor1488, Name: where_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1498, Name: mul_467, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1499, Name: sub_95, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1114, Name: torch.ops.aten.sub.Tensor(sub_95, unsqueeze_337)
Input Tensors:
tensor1499, Name: sub_95, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1493, Name: unsqueeze_337, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1500, Name: sub_96, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1115, Name: torch.ops.aten.mul.Tensor(sub_96, unsqueeze_343)
Input Tensors:
tensor1500, Name: sub_96, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1497, Name: unsqueeze_343, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1501, Name: mul_468, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1116, Name: torch.ops.aten.mul.Tensor(sum_23, squeeze_127)
Input Tensors:
tensor1492, Name: sum_23, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1095, Name: squeeze_127, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1502, Name: mul_469, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1117, Name: torch.ops.aten.convolution_backward.default(mul_468, relu_38, primals_127, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1501, Name: mul_468, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1089, Name: relu_38, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor126, Name: primals_127, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor1503, Name: getitem_138, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1504, Name: getitem_139, Is global?: 0: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
____________________________________________________________________
Kernel ID: 1118, Name: torch.ops.aten.le.Scalar(relu_38, 0)
Input Tensors:
tensor1089, Name: relu_38, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1505, Name: le_10, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1119, Name: torch.ops.aten.where.self(le_10, full_default, getitem_138)
Input Tensors:
tensor1505, Name: le_10, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1503, Name: getitem_138, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1506, Name: where_10, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1120, Name: torch.ops.aten.sum.dim_IntList(where_10, [0, 2, 3])
Input Tensors:
tensor1506, Name: where_10, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1507, Name: sum_24, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1121, Name: torch.ops.aten.sub.Tensor(convolution_41, unsqueeze_346)
Input Tensors:
tensor1072, Name: convolution_41, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1075, Name: unsqueeze_346, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1508, Name: sub_97, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1122, Name: torch.ops.aten.mul.Tensor(where_10, sub_97)
Input Tensors:
tensor1506, Name: where_10, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1508, Name: sub_97, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1509, Name: mul_470, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1123, Name: torch.ops.aten.sum.dim_IntList(mul_470, [0, 2, 3])
Input Tensors:
tensor1509, Name: mul_470, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1510, Name: sum_25, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1124, Name: torch.ops.aten.mul.Tensor(sum_24, 7.971938775510203e-05)
Input Tensors:
tensor1507, Name: sum_24, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1511, Name: mul_471, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1125, Name: torch.ops.aten.mul.Tensor(sum_25, 7.971938775510203e-05)
Input Tensors:
tensor1510, Name: sum_25, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1512, Name: mul_472, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1126, Name: torch.ops.aten.mul.Tensor(squeeze_124, squeeze_124)
Input Tensors:
tensor1077, Name: squeeze_124, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1077, Name: squeeze_124, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1513, Name: mul_473, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1127, Name: torch.ops.aten.mul.Tensor(mul_472, mul_473)
Input Tensors:
tensor1512, Name: mul_472, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1513, Name: mul_473, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1514, Name: mul_474, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1128, Name: torch.ops.aten.mul.Tensor(squeeze_124, primals_125)
Input Tensors:
tensor1077, Name: squeeze_124, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor124, Name: primals_125, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1515, Name: mul_475, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1129, Name: torch.ops.aten.mul.Tensor(sub_97, unsqueeze_352)
Input Tensors:
tensor1508, Name: sub_97, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1514, Name: unsqueeze_352, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1516, Name: mul_476, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1130, Name: torch.ops.aten.sub.Tensor(where_10, mul_476)
Input Tensors:
tensor1506, Name: where_10, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1516, Name: mul_476, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1517, Name: sub_99, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1131, Name: torch.ops.aten.sub.Tensor(sub_99, unsqueeze_349)
Input Tensors:
tensor1517, Name: sub_99, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1511, Name: unsqueeze_349, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1518, Name: sub_100, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1132, Name: torch.ops.aten.mul.Tensor(sub_100, unsqueeze_355)
Input Tensors:
tensor1518, Name: sub_100, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1515, Name: unsqueeze_355, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1519, Name: mul_477, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1133, Name: torch.ops.aten.mul.Tensor(sum_25, squeeze_124)
Input Tensors:
tensor1510, Name: sum_25, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1077, Name: squeeze_124, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1520, Name: mul_478, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1134, Name: torch.ops.aten.convolution_backward.default(mul_477, relu_37, primals_124, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1519, Name: mul_477, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1071, Name: relu_37, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor123, Name: primals_124, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor1521, Name: getitem_141, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1522, Name: getitem_142, Is global?: 0: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
____________________________________________________________________
Kernel ID: 1135, Name: torch.ops.aten.le.Scalar(relu_37, 0)
Input Tensors:
tensor1071, Name: relu_37, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1523, Name: le_11, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1136, Name: torch.ops.aten.where.self(le_11, full_default, getitem_141)
Input Tensors:
tensor1523, Name: le_11, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1521, Name: getitem_141, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1524, Name: where_11, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1137, Name: torch.ops.aten.sum.dim_IntList(where_11, [0, 2, 3])
Input Tensors:
tensor1524, Name: where_11, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1525, Name: sum_26, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1138, Name: torch.ops.aten.sub.Tensor(convolution_40, unsqueeze_358)
Input Tensors:
tensor1054, Name: convolution_40, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1057, Name: unsqueeze_358, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1526, Name: sub_101, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1139, Name: torch.ops.aten.mul.Tensor(where_11, sub_101)
Input Tensors:
tensor1524, Name: where_11, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1526, Name: sub_101, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1527, Name: mul_479, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1140, Name: torch.ops.aten.sum.dim_IntList(mul_479, [0, 2, 3])
Input Tensors:
tensor1527, Name: mul_479, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1528, Name: sum_27, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1141, Name: torch.ops.aten.mul.Tensor(sum_26, 7.971938775510203e-05)
Input Tensors:
tensor1525, Name: sum_26, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1529, Name: mul_480, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1142, Name: torch.ops.aten.mul.Tensor(sum_27, 7.971938775510203e-05)
Input Tensors:
tensor1528, Name: sum_27, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1530, Name: mul_481, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1143, Name: torch.ops.aten.mul.Tensor(squeeze_121, squeeze_121)
Input Tensors:
tensor1059, Name: squeeze_121, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1059, Name: squeeze_121, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1531, Name: mul_482, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1144, Name: torch.ops.aten.mul.Tensor(mul_481, mul_482)
Input Tensors:
tensor1530, Name: mul_481, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1531, Name: mul_482, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1532, Name: mul_483, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1145, Name: torch.ops.aten.mul.Tensor(squeeze_121, primals_122)
Input Tensors:
tensor1059, Name: squeeze_121, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor121, Name: primals_122, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1533, Name: mul_484, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1146, Name: torch.ops.aten.mul.Tensor(sub_101, unsqueeze_364)
Input Tensors:
tensor1526, Name: sub_101, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1532, Name: unsqueeze_364, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1534, Name: mul_485, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1147, Name: torch.ops.aten.sub.Tensor(where_11, mul_485)
Input Tensors:
tensor1524, Name: where_11, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1534, Name: mul_485, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1535, Name: sub_103, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1148, Name: torch.ops.aten.sub.Tensor(sub_103, unsqueeze_361)
Input Tensors:
tensor1535, Name: sub_103, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1529, Name: unsqueeze_361, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1536, Name: sub_104, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1149, Name: torch.ops.aten.mul.Tensor(sub_104, unsqueeze_367)
Input Tensors:
tensor1536, Name: sub_104, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1533, Name: unsqueeze_367, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1537, Name: mul_486, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1150, Name: torch.ops.aten.mul.Tensor(sum_27, squeeze_121)
Input Tensors:
tensor1528, Name: sum_27, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1059, Name: squeeze_121, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1538, Name: mul_487, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1151, Name: torch.ops.aten.convolution_backward.default(mul_486, relu_36, primals_121, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1537, Name: mul_486, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1053, Name: relu_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor120, Name: primals_121, Is global?: 1: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
Output Tensors:
tensor1539, Name: getitem_144, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1540, Name: getitem_145, Is global?: 0: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 1152, Name: torch.ops.aten.add.Tensor(where_9, getitem_144)
Input Tensors:
tensor1488, Name: where_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1539, Name: getitem_144, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1541, Name: add_284, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1153, Name: torch.ops.aten.le.Scalar(relu_36, 0)
Input Tensors:
tensor1053, Name: relu_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1542, Name: le_12, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1154, Name: torch.ops.aten.where.self(le_12, full_default, add_284)
Input Tensors:
tensor1542, Name: le_12, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1541, Name: add_284, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1543, Name: where_12, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1155, Name: torch.ops.aten.sum.dim_IntList(where_12, [0, 2, 3])
Input Tensors:
tensor1543, Name: where_12, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1544, Name: sum_28, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1156, Name: torch.ops.aten.sub.Tensor(convolution_39, unsqueeze_370)
Input Tensors:
tensor1035, Name: convolution_39, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1038, Name: unsqueeze_370, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1545, Name: sub_105, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1157, Name: torch.ops.aten.mul.Tensor(where_12, sub_105)
Input Tensors:
tensor1543, Name: where_12, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1545, Name: sub_105, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1546, Name: mul_488, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1158, Name: torch.ops.aten.sum.dim_IntList(mul_488, [0, 2, 3])
Input Tensors:
tensor1546, Name: mul_488, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1547, Name: sum_29, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1159, Name: torch.ops.aten.mul.Tensor(sum_28, 7.971938775510203e-05)
Input Tensors:
tensor1544, Name: sum_28, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1548, Name: mul_489, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1160, Name: torch.ops.aten.mul.Tensor(sum_29, 7.971938775510203e-05)
Input Tensors:
tensor1547, Name: sum_29, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1549, Name: mul_490, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1161, Name: torch.ops.aten.mul.Tensor(squeeze_118, squeeze_118)
Input Tensors:
tensor1040, Name: squeeze_118, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1040, Name: squeeze_118, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1550, Name: mul_491, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1162, Name: torch.ops.aten.mul.Tensor(mul_490, mul_491)
Input Tensors:
tensor1549, Name: mul_490, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1550, Name: mul_491, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1551, Name: mul_492, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1163, Name: torch.ops.aten.mul.Tensor(squeeze_118, primals_119)
Input Tensors:
tensor1040, Name: squeeze_118, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor118, Name: primals_119, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1552, Name: mul_493, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1164, Name: torch.ops.aten.mul.Tensor(sub_105, unsqueeze_376)
Input Tensors:
tensor1545, Name: sub_105, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1551, Name: unsqueeze_376, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1553, Name: mul_494, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1165, Name: torch.ops.aten.sub.Tensor(where_12, mul_494)
Input Tensors:
tensor1543, Name: where_12, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1553, Name: mul_494, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1554, Name: sub_107, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1166, Name: torch.ops.aten.sub.Tensor(sub_107, unsqueeze_373)
Input Tensors:
tensor1554, Name: sub_107, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1548, Name: unsqueeze_373, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1555, Name: sub_108, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1167, Name: torch.ops.aten.mul.Tensor(sub_108, unsqueeze_379)
Input Tensors:
tensor1555, Name: sub_108, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1552, Name: unsqueeze_379, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1556, Name: mul_495, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1168, Name: torch.ops.aten.mul.Tensor(sum_29, squeeze_118)
Input Tensors:
tensor1547, Name: sum_29, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1040, Name: squeeze_118, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1557, Name: mul_496, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1169, Name: torch.ops.aten.convolution_backward.default(mul_495, relu_35, primals_118, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1556, Name: mul_495, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1034, Name: relu_35, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor117, Name: primals_118, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor1558, Name: getitem_147, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1559, Name: getitem_148, Is global?: 0: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
____________________________________________________________________
Kernel ID: 1170, Name: torch.ops.aten.le.Scalar(relu_35, 0)
Input Tensors:
tensor1034, Name: relu_35, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1560, Name: le_13, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1171, Name: torch.ops.aten.where.self(le_13, full_default, getitem_147)
Input Tensors:
tensor1560, Name: le_13, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1558, Name: getitem_147, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1561, Name: where_13, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1172, Name: torch.ops.aten.sum.dim_IntList(where_13, [0, 2, 3])
Input Tensors:
tensor1561, Name: where_13, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1562, Name: sum_30, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1173, Name: torch.ops.aten.sub.Tensor(convolution_38, unsqueeze_382)
Input Tensors:
tensor1017, Name: convolution_38, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1020, Name: unsqueeze_382, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1563, Name: sub_109, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1174, Name: torch.ops.aten.mul.Tensor(where_13, sub_109)
Input Tensors:
tensor1561, Name: where_13, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1563, Name: sub_109, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1564, Name: mul_497, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1175, Name: torch.ops.aten.sum.dim_IntList(mul_497, [0, 2, 3])
Input Tensors:
tensor1564, Name: mul_497, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1565, Name: sum_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1176, Name: torch.ops.aten.mul.Tensor(sum_30, 7.971938775510203e-05)
Input Tensors:
tensor1562, Name: sum_30, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1566, Name: mul_498, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1177, Name: torch.ops.aten.mul.Tensor(sum_31, 7.971938775510203e-05)
Input Tensors:
tensor1565, Name: sum_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1567, Name: mul_499, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1178, Name: torch.ops.aten.mul.Tensor(squeeze_115, squeeze_115)
Input Tensors:
tensor1022, Name: squeeze_115, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1022, Name: squeeze_115, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1568, Name: mul_500, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1179, Name: torch.ops.aten.mul.Tensor(mul_499, mul_500)
Input Tensors:
tensor1567, Name: mul_499, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1568, Name: mul_500, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1569, Name: mul_501, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1180, Name: torch.ops.aten.mul.Tensor(squeeze_115, primals_116)
Input Tensors:
tensor1022, Name: squeeze_115, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor115, Name: primals_116, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1570, Name: mul_502, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1181, Name: torch.ops.aten.mul.Tensor(sub_109, unsqueeze_388)
Input Tensors:
tensor1563, Name: sub_109, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1569, Name: unsqueeze_388, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1571, Name: mul_503, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1182, Name: torch.ops.aten.sub.Tensor(where_13, mul_503)
Input Tensors:
tensor1561, Name: where_13, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1571, Name: mul_503, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1572, Name: sub_111, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1183, Name: torch.ops.aten.sub.Tensor(sub_111, unsqueeze_385)
Input Tensors:
tensor1572, Name: sub_111, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1566, Name: unsqueeze_385, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1573, Name: sub_112, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1184, Name: torch.ops.aten.mul.Tensor(sub_112, unsqueeze_391)
Input Tensors:
tensor1573, Name: sub_112, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1570, Name: unsqueeze_391, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1574, Name: mul_504, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1185, Name: torch.ops.aten.mul.Tensor(sum_31, squeeze_115)
Input Tensors:
tensor1565, Name: sum_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1022, Name: squeeze_115, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1575, Name: mul_505, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1186, Name: torch.ops.aten.convolution_backward.default(mul_504, relu_34, primals_115, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1574, Name: mul_504, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1016, Name: relu_34, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor114, Name: primals_115, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor1576, Name: getitem_150, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1577, Name: getitem_151, Is global?: 0: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
____________________________________________________________________
Kernel ID: 1187, Name: torch.ops.aten.le.Scalar(relu_34, 0)
Input Tensors:
tensor1016, Name: relu_34, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1578, Name: le_14, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1188, Name: torch.ops.aten.where.self(le_14, full_default, getitem_150)
Input Tensors:
tensor1578, Name: le_14, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1576, Name: getitem_150, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1579, Name: where_14, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1189, Name: torch.ops.aten.sum.dim_IntList(where_14, [0, 2, 3])
Input Tensors:
tensor1579, Name: where_14, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1580, Name: sum_32, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1190, Name: torch.ops.aten.sub.Tensor(convolution_37, unsqueeze_394)
Input Tensors:
tensor999, Name: convolution_37, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1002, Name: unsqueeze_394, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1581, Name: sub_113, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1191, Name: torch.ops.aten.mul.Tensor(where_14, sub_113)
Input Tensors:
tensor1579, Name: where_14, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1581, Name: sub_113, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1582, Name: mul_506, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1192, Name: torch.ops.aten.sum.dim_IntList(mul_506, [0, 2, 3])
Input Tensors:
tensor1582, Name: mul_506, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1583, Name: sum_33, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1193, Name: torch.ops.aten.mul.Tensor(sum_32, 7.971938775510203e-05)
Input Tensors:
tensor1580, Name: sum_32, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1584, Name: mul_507, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1194, Name: torch.ops.aten.mul.Tensor(sum_33, 7.971938775510203e-05)
Input Tensors:
tensor1583, Name: sum_33, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1585, Name: mul_508, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1195, Name: torch.ops.aten.mul.Tensor(squeeze_112, squeeze_112)
Input Tensors:
tensor1004, Name: squeeze_112, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1004, Name: squeeze_112, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1586, Name: mul_509, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1196, Name: torch.ops.aten.mul.Tensor(mul_508, mul_509)
Input Tensors:
tensor1585, Name: mul_508, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1586, Name: mul_509, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1587, Name: mul_510, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1197, Name: torch.ops.aten.mul.Tensor(squeeze_112, primals_113)
Input Tensors:
tensor1004, Name: squeeze_112, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor112, Name: primals_113, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1588, Name: mul_511, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1198, Name: torch.ops.aten.mul.Tensor(sub_113, unsqueeze_400)
Input Tensors:
tensor1581, Name: sub_113, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1587, Name: unsqueeze_400, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1589, Name: mul_512, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1199, Name: torch.ops.aten.sub.Tensor(where_14, mul_512)
Input Tensors:
tensor1579, Name: where_14, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1589, Name: mul_512, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1590, Name: sub_115, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1200, Name: torch.ops.aten.sub.Tensor(sub_115, unsqueeze_397)
Input Tensors:
tensor1590, Name: sub_115, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1584, Name: unsqueeze_397, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1591, Name: sub_116, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1201, Name: torch.ops.aten.mul.Tensor(sub_116, unsqueeze_403)
Input Tensors:
tensor1591, Name: sub_116, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1588, Name: unsqueeze_403, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1592, Name: mul_513, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1202, Name: torch.ops.aten.mul.Tensor(sum_33, squeeze_112)
Input Tensors:
tensor1583, Name: sum_33, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1004, Name: squeeze_112, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1593, Name: mul_514, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1203, Name: torch.ops.aten.convolution_backward.default(mul_513, relu_33, primals_112, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1592, Name: mul_513, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor998, Name: relu_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor111, Name: primals_112, Is global?: 1: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
Output Tensors:
tensor1594, Name: getitem_153, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1595, Name: getitem_154, Is global?: 0: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 1204, Name: torch.ops.aten.add.Tensor(where_12, getitem_153)
Input Tensors:
tensor1543, Name: where_12, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1594, Name: getitem_153, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1596, Name: add_285, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1205, Name: torch.ops.aten.le.Scalar(relu_33, 0)
Input Tensors:
tensor998, Name: relu_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1597, Name: le_15, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1206, Name: torch.ops.aten.where.self(le_15, full_default, add_285)
Input Tensors:
tensor1597, Name: le_15, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1596, Name: add_285, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1598, Name: where_15, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1207, Name: torch.ops.aten.sum.dim_IntList(where_15, [0, 2, 3])
Input Tensors:
tensor1598, Name: where_15, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1599, Name: sum_34, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1208, Name: torch.ops.aten.sub.Tensor(convolution_36, unsqueeze_406)
Input Tensors:
tensor980, Name: convolution_36, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor983, Name: unsqueeze_406, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1600, Name: sub_117, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1209, Name: torch.ops.aten.mul.Tensor(where_15, sub_117)
Input Tensors:
tensor1598, Name: where_15, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1600, Name: sub_117, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1601, Name: mul_515, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1210, Name: torch.ops.aten.sum.dim_IntList(mul_515, [0, 2, 3])
Input Tensors:
tensor1601, Name: mul_515, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1602, Name: sum_35, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1211, Name: torch.ops.aten.mul.Tensor(sum_34, 7.971938775510203e-05)
Input Tensors:
tensor1599, Name: sum_34, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1603, Name: mul_516, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1212, Name: torch.ops.aten.mul.Tensor(sum_35, 7.971938775510203e-05)
Input Tensors:
tensor1602, Name: sum_35, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1604, Name: mul_517, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1213, Name: torch.ops.aten.mul.Tensor(squeeze_109, squeeze_109)
Input Tensors:
tensor985, Name: squeeze_109, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor985, Name: squeeze_109, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1605, Name: mul_518, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1214, Name: torch.ops.aten.mul.Tensor(mul_517, mul_518)
Input Tensors:
tensor1604, Name: mul_517, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1605, Name: mul_518, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1606, Name: mul_519, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1215, Name: torch.ops.aten.mul.Tensor(squeeze_109, primals_110)
Input Tensors:
tensor985, Name: squeeze_109, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor109, Name: primals_110, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1607, Name: mul_520, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1216, Name: torch.ops.aten.mul.Tensor(sub_117, unsqueeze_412)
Input Tensors:
tensor1600, Name: sub_117, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1606, Name: unsqueeze_412, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1608, Name: mul_521, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1217, Name: torch.ops.aten.sub.Tensor(where_15, mul_521)
Input Tensors:
tensor1598, Name: where_15, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1608, Name: mul_521, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1609, Name: sub_119, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1218, Name: torch.ops.aten.sub.Tensor(sub_119, unsqueeze_409)
Input Tensors:
tensor1609, Name: sub_119, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1603, Name: unsqueeze_409, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1610, Name: sub_120, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1219, Name: torch.ops.aten.mul.Tensor(sub_120, unsqueeze_415)
Input Tensors:
tensor1610, Name: sub_120, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1607, Name: unsqueeze_415, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1611, Name: mul_522, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1220, Name: torch.ops.aten.mul.Tensor(sum_35, squeeze_109)
Input Tensors:
tensor1602, Name: sum_35, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor985, Name: squeeze_109, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1612, Name: mul_523, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1221, Name: torch.ops.aten.convolution_backward.default(mul_522, relu_32, primals_109, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1611, Name: mul_522, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor979, Name: relu_32, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor108, Name: primals_109, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor1613, Name: getitem_156, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1614, Name: getitem_157, Is global?: 0: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
____________________________________________________________________
Kernel ID: 1222, Name: torch.ops.aten.le.Scalar(relu_32, 0)
Input Tensors:
tensor979, Name: relu_32, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1615, Name: le_16, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1223, Name: torch.ops.aten.where.self(le_16, full_default, getitem_156)
Input Tensors:
tensor1615, Name: le_16, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1613, Name: getitem_156, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1616, Name: where_16, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1224, Name: torch.ops.aten.sum.dim_IntList(where_16, [0, 2, 3])
Input Tensors:
tensor1616, Name: where_16, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1617, Name: sum_36, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1225, Name: torch.ops.aten.sub.Tensor(convolution_35, unsqueeze_418)
Input Tensors:
tensor962, Name: convolution_35, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor965, Name: unsqueeze_418, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1618, Name: sub_121, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1226, Name: torch.ops.aten.mul.Tensor(where_16, sub_121)
Input Tensors:
tensor1616, Name: where_16, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1618, Name: sub_121, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1619, Name: mul_524, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1227, Name: torch.ops.aten.sum.dim_IntList(mul_524, [0, 2, 3])
Input Tensors:
tensor1619, Name: mul_524, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1620, Name: sum_37, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1228, Name: torch.ops.aten.mul.Tensor(sum_36, 7.971938775510203e-05)
Input Tensors:
tensor1617, Name: sum_36, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1621, Name: mul_525, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1229, Name: torch.ops.aten.mul.Tensor(sum_37, 7.971938775510203e-05)
Input Tensors:
tensor1620, Name: sum_37, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1622, Name: mul_526, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1230, Name: torch.ops.aten.mul.Tensor(squeeze_106, squeeze_106)
Input Tensors:
tensor967, Name: squeeze_106, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor967, Name: squeeze_106, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1623, Name: mul_527, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1231, Name: torch.ops.aten.mul.Tensor(mul_526, mul_527)
Input Tensors:
tensor1622, Name: mul_526, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1623, Name: mul_527, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1624, Name: mul_528, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1232, Name: torch.ops.aten.mul.Tensor(squeeze_106, primals_107)
Input Tensors:
tensor967, Name: squeeze_106, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor106, Name: primals_107, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1625, Name: mul_529, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1233, Name: torch.ops.aten.mul.Tensor(sub_121, unsqueeze_424)
Input Tensors:
tensor1618, Name: sub_121, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1624, Name: unsqueeze_424, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1626, Name: mul_530, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1234, Name: torch.ops.aten.sub.Tensor(where_16, mul_530)
Input Tensors:
tensor1616, Name: where_16, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1626, Name: mul_530, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1627, Name: sub_123, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1235, Name: torch.ops.aten.sub.Tensor(sub_123, unsqueeze_421)
Input Tensors:
tensor1627, Name: sub_123, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1621, Name: unsqueeze_421, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1628, Name: sub_124, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1236, Name: torch.ops.aten.mul.Tensor(sub_124, unsqueeze_427)
Input Tensors:
tensor1628, Name: sub_124, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1625, Name: unsqueeze_427, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1629, Name: mul_531, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1237, Name: torch.ops.aten.mul.Tensor(sum_37, squeeze_106)
Input Tensors:
tensor1620, Name: sum_37, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor967, Name: squeeze_106, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1630, Name: mul_532, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1238, Name: torch.ops.aten.convolution_backward.default(mul_531, relu_31, primals_106, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1629, Name: mul_531, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor961, Name: relu_31, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor105, Name: primals_106, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor1631, Name: getitem_159, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1632, Name: getitem_160, Is global?: 0: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
____________________________________________________________________
Kernel ID: 1239, Name: torch.ops.aten.le.Scalar(relu_31, 0)
Input Tensors:
tensor961, Name: relu_31, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1633, Name: le_17, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1240, Name: torch.ops.aten.where.self(le_17, full_default, getitem_159)
Input Tensors:
tensor1633, Name: le_17, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1631, Name: getitem_159, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1634, Name: where_17, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1241, Name: torch.ops.aten.sum.dim_IntList(where_17, [0, 2, 3])
Input Tensors:
tensor1634, Name: where_17, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1635, Name: sum_38, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1242, Name: torch.ops.aten.sub.Tensor(convolution_34, unsqueeze_430)
Input Tensors:
tensor944, Name: convolution_34, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor947, Name: unsqueeze_430, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1636, Name: sub_125, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1243, Name: torch.ops.aten.mul.Tensor(where_17, sub_125)
Input Tensors:
tensor1634, Name: where_17, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1636, Name: sub_125, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1637, Name: mul_533, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1244, Name: torch.ops.aten.sum.dim_IntList(mul_533, [0, 2, 3])
Input Tensors:
tensor1637, Name: mul_533, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1638, Name: sum_39, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1245, Name: torch.ops.aten.mul.Tensor(sum_38, 7.971938775510203e-05)
Input Tensors:
tensor1635, Name: sum_38, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1639, Name: mul_534, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1246, Name: torch.ops.aten.mul.Tensor(sum_39, 7.971938775510203e-05)
Input Tensors:
tensor1638, Name: sum_39, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1640, Name: mul_535, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1247, Name: torch.ops.aten.mul.Tensor(squeeze_103, squeeze_103)
Input Tensors:
tensor949, Name: squeeze_103, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor949, Name: squeeze_103, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1641, Name: mul_536, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1248, Name: torch.ops.aten.mul.Tensor(mul_535, mul_536)
Input Tensors:
tensor1640, Name: mul_535, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1641, Name: mul_536, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1642, Name: mul_537, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1249, Name: torch.ops.aten.mul.Tensor(squeeze_103, primals_104)
Input Tensors:
tensor949, Name: squeeze_103, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor103, Name: primals_104, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1643, Name: mul_538, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1250, Name: torch.ops.aten.mul.Tensor(sub_125, unsqueeze_436)
Input Tensors:
tensor1636, Name: sub_125, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1642, Name: unsqueeze_436, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1644, Name: mul_539, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1251, Name: torch.ops.aten.sub.Tensor(where_17, mul_539)
Input Tensors:
tensor1634, Name: where_17, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1644, Name: mul_539, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1645, Name: sub_127, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1252, Name: torch.ops.aten.sub.Tensor(sub_127, unsqueeze_433)
Input Tensors:
tensor1645, Name: sub_127, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1639, Name: unsqueeze_433, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1646, Name: sub_128, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1253, Name: torch.ops.aten.mul.Tensor(sub_128, unsqueeze_439)
Input Tensors:
tensor1646, Name: sub_128, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1643, Name: unsqueeze_439, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1647, Name: mul_540, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1254, Name: torch.ops.aten.mul.Tensor(sum_39, squeeze_103)
Input Tensors:
tensor1638, Name: sum_39, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor949, Name: squeeze_103, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1648, Name: mul_541, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1255, Name: torch.ops.aten.convolution_backward.default(mul_540, relu_30, primals_103, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1647, Name: mul_540, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor943, Name: relu_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor102, Name: primals_103, Is global?: 1: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
Output Tensors:
tensor1649, Name: getitem_162, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1650, Name: getitem_163, Is global?: 0: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 1256, Name: torch.ops.aten.add.Tensor(where_15, getitem_162)
Input Tensors:
tensor1598, Name: where_15, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1649, Name: getitem_162, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1651, Name: add_286, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1257, Name: torch.ops.aten.le.Scalar(relu_30, 0)
Input Tensors:
tensor943, Name: relu_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1652, Name: le_18, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1258, Name: torch.ops.aten.where.self(le_18, full_default, add_286)
Input Tensors:
tensor1652, Name: le_18, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1651, Name: add_286, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1653, Name: where_18, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1259, Name: torch.ops.aten.sum.dim_IntList(where_18, [0, 2, 3])
Input Tensors:
tensor1653, Name: where_18, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1654, Name: sum_40, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1260, Name: torch.ops.aten.sub.Tensor(convolution_33, unsqueeze_442)
Input Tensors:
tensor925, Name: convolution_33, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor928, Name: unsqueeze_442, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1655, Name: sub_129, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1261, Name: torch.ops.aten.mul.Tensor(where_18, sub_129)
Input Tensors:
tensor1653, Name: where_18, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1655, Name: sub_129, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1656, Name: mul_542, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1262, Name: torch.ops.aten.sum.dim_IntList(mul_542, [0, 2, 3])
Input Tensors:
tensor1656, Name: mul_542, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1657, Name: sum_41, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1263, Name: torch.ops.aten.mul.Tensor(sum_40, 7.971938775510203e-05)
Input Tensors:
tensor1654, Name: sum_40, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1658, Name: mul_543, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1264, Name: torch.ops.aten.mul.Tensor(sum_41, 7.971938775510203e-05)
Input Tensors:
tensor1657, Name: sum_41, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1659, Name: mul_544, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1265, Name: torch.ops.aten.mul.Tensor(squeeze_100, squeeze_100)
Input Tensors:
tensor930, Name: squeeze_100, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor930, Name: squeeze_100, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1660, Name: mul_545, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1266, Name: torch.ops.aten.mul.Tensor(mul_544, mul_545)
Input Tensors:
tensor1659, Name: mul_544, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1660, Name: mul_545, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1661, Name: mul_546, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1267, Name: torch.ops.aten.mul.Tensor(squeeze_100, primals_101)
Input Tensors:
tensor930, Name: squeeze_100, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor100, Name: primals_101, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1662, Name: mul_547, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1268, Name: torch.ops.aten.mul.Tensor(sub_129, unsqueeze_448)
Input Tensors:
tensor1655, Name: sub_129, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1661, Name: unsqueeze_448, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1663, Name: mul_548, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1269, Name: torch.ops.aten.sub.Tensor(where_18, mul_548)
Input Tensors:
tensor1653, Name: where_18, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1663, Name: mul_548, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1664, Name: sub_131, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1270, Name: torch.ops.aten.sub.Tensor(sub_131, unsqueeze_445)
Input Tensors:
tensor1664, Name: sub_131, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1658, Name: unsqueeze_445, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1665, Name: sub_132, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1271, Name: torch.ops.aten.mul.Tensor(sub_132, unsqueeze_451)
Input Tensors:
tensor1665, Name: sub_132, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1662, Name: unsqueeze_451, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1666, Name: mul_549, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1272, Name: torch.ops.aten.mul.Tensor(sum_41, squeeze_100)
Input Tensors:
tensor1657, Name: sum_41, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor930, Name: squeeze_100, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1667, Name: mul_550, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1273, Name: torch.ops.aten.convolution_backward.default(mul_549, relu_29, primals_100, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1666, Name: mul_549, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor924, Name: relu_29, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor99, Name: primals_100, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor1668, Name: getitem_165, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1669, Name: getitem_166, Is global?: 0: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
____________________________________________________________________
Kernel ID: 1274, Name: torch.ops.aten.le.Scalar(relu_29, 0)
Input Tensors:
tensor924, Name: relu_29, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1670, Name: le_19, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1275, Name: torch.ops.aten.where.self(le_19, full_default, getitem_165)
Input Tensors:
tensor1670, Name: le_19, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1668, Name: getitem_165, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1671, Name: where_19, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1276, Name: torch.ops.aten.sum.dim_IntList(where_19, [0, 2, 3])
Input Tensors:
tensor1671, Name: where_19, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1672, Name: sum_42, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1277, Name: torch.ops.aten.sub.Tensor(convolution_32, unsqueeze_454)
Input Tensors:
tensor907, Name: convolution_32, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor910, Name: unsqueeze_454, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1673, Name: sub_133, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1278, Name: torch.ops.aten.mul.Tensor(where_19, sub_133)
Input Tensors:
tensor1671, Name: where_19, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1673, Name: sub_133, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1674, Name: mul_551, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1279, Name: torch.ops.aten.sum.dim_IntList(mul_551, [0, 2, 3])
Input Tensors:
tensor1674, Name: mul_551, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1675, Name: sum_43, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1280, Name: torch.ops.aten.mul.Tensor(sum_42, 7.971938775510203e-05)
Input Tensors:
tensor1672, Name: sum_42, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1676, Name: mul_552, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1281, Name: torch.ops.aten.mul.Tensor(sum_43, 7.971938775510203e-05)
Input Tensors:
tensor1675, Name: sum_43, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1677, Name: mul_553, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1282, Name: torch.ops.aten.mul.Tensor(squeeze_97, squeeze_97)
Input Tensors:
tensor912, Name: squeeze_97, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor912, Name: squeeze_97, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1678, Name: mul_554, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1283, Name: torch.ops.aten.mul.Tensor(mul_553, mul_554)
Input Tensors:
tensor1677, Name: mul_553, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1678, Name: mul_554, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1679, Name: mul_555, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1284, Name: torch.ops.aten.mul.Tensor(squeeze_97, primals_98)
Input Tensors:
tensor912, Name: squeeze_97, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor97, Name: primals_98, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1680, Name: mul_556, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1285, Name: torch.ops.aten.mul.Tensor(sub_133, unsqueeze_460)
Input Tensors:
tensor1673, Name: sub_133, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1679, Name: unsqueeze_460, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1681, Name: mul_557, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1286, Name: torch.ops.aten.sub.Tensor(where_19, mul_557)
Input Tensors:
tensor1671, Name: where_19, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1681, Name: mul_557, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1682, Name: sub_135, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1287, Name: torch.ops.aten.sub.Tensor(sub_135, unsqueeze_457)
Input Tensors:
tensor1682, Name: sub_135, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1676, Name: unsqueeze_457, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1683, Name: sub_136, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1288, Name: torch.ops.aten.mul.Tensor(sub_136, unsqueeze_463)
Input Tensors:
tensor1683, Name: sub_136, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1680, Name: unsqueeze_463, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1684, Name: mul_558, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1289, Name: torch.ops.aten.mul.Tensor(sum_43, squeeze_97)
Input Tensors:
tensor1675, Name: sum_43, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor912, Name: squeeze_97, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1685, Name: mul_559, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1290, Name: torch.ops.aten.convolution_backward.default(mul_558, relu_28, primals_97, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1684, Name: mul_558, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor906, Name: relu_28, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor96, Name: primals_97, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor1686, Name: getitem_168, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1687, Name: getitem_169, Is global?: 0: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
____________________________________________________________________
Kernel ID: 1291, Name: torch.ops.aten.le.Scalar(relu_28, 0)
Input Tensors:
tensor906, Name: relu_28, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1688, Name: le_20, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1292, Name: torch.ops.aten.where.self(le_20, full_default, getitem_168)
Input Tensors:
tensor1688, Name: le_20, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1686, Name: getitem_168, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1689, Name: where_20, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1293, Name: torch.ops.aten.sum.dim_IntList(where_20, [0, 2, 3])
Input Tensors:
tensor1689, Name: where_20, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1690, Name: sum_44, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1294, Name: torch.ops.aten.sub.Tensor(convolution_31, unsqueeze_466)
Input Tensors:
tensor889, Name: convolution_31, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor892, Name: unsqueeze_466, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1691, Name: sub_137, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1295, Name: torch.ops.aten.mul.Tensor(where_20, sub_137)
Input Tensors:
tensor1689, Name: where_20, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1691, Name: sub_137, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1692, Name: mul_560, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1296, Name: torch.ops.aten.sum.dim_IntList(mul_560, [0, 2, 3])
Input Tensors:
tensor1692, Name: mul_560, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1693, Name: sum_45, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1297, Name: torch.ops.aten.mul.Tensor(sum_44, 7.971938775510203e-05)
Input Tensors:
tensor1690, Name: sum_44, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1694, Name: mul_561, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1298, Name: torch.ops.aten.mul.Tensor(sum_45, 7.971938775510203e-05)
Input Tensors:
tensor1693, Name: sum_45, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1695, Name: mul_562, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1299, Name: torch.ops.aten.mul.Tensor(squeeze_94, squeeze_94)
Input Tensors:
tensor894, Name: squeeze_94, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor894, Name: squeeze_94, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1696, Name: mul_563, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1300, Name: torch.ops.aten.mul.Tensor(mul_562, mul_563)
Input Tensors:
tensor1695, Name: mul_562, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1696, Name: mul_563, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1697, Name: mul_564, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1301, Name: torch.ops.aten.mul.Tensor(squeeze_94, primals_95)
Input Tensors:
tensor894, Name: squeeze_94, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor94, Name: primals_95, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1698, Name: mul_565, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1302, Name: torch.ops.aten.mul.Tensor(sub_137, unsqueeze_472)
Input Tensors:
tensor1691, Name: sub_137, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1697, Name: unsqueeze_472, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1699, Name: mul_566, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1303, Name: torch.ops.aten.sub.Tensor(where_20, mul_566)
Input Tensors:
tensor1689, Name: where_20, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1699, Name: mul_566, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1700, Name: sub_139, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1304, Name: torch.ops.aten.sub.Tensor(sub_139, unsqueeze_469)
Input Tensors:
tensor1700, Name: sub_139, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1694, Name: unsqueeze_469, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1701, Name: sub_140, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1305, Name: torch.ops.aten.mul.Tensor(sub_140, unsqueeze_475)
Input Tensors:
tensor1701, Name: sub_140, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1698, Name: unsqueeze_475, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1702, Name: mul_567, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1306, Name: torch.ops.aten.mul.Tensor(sum_45, squeeze_94)
Input Tensors:
tensor1693, Name: sum_45, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor894, Name: squeeze_94, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1703, Name: mul_568, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1307, Name: torch.ops.aten.convolution_backward.default(mul_567, relu_27, primals_94, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1702, Name: mul_567, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor888, Name: relu_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor93, Name: primals_94, Is global?: 1: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
Output Tensors:
tensor1704, Name: getitem_171, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1705, Name: getitem_172, Is global?: 0: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 1308, Name: torch.ops.aten.add.Tensor(where_18, getitem_171)
Input Tensors:
tensor1653, Name: where_18, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1704, Name: getitem_171, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1706, Name: add_287, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1309, Name: torch.ops.aten.le.Scalar(relu_27, 0)
Input Tensors:
tensor888, Name: relu_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1707, Name: le_21, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1310, Name: torch.ops.aten.where.self(le_21, full_default, add_287)
Input Tensors:
tensor1707, Name: le_21, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1706, Name: add_287, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1708, Name: where_21, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1311, Name: torch.ops.aten.sum.dim_IntList(where_21, [0, 2, 3])
Input Tensors:
tensor1708, Name: where_21, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1709, Name: sum_46, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1312, Name: torch.ops.aten.sub.Tensor(convolution_30, unsqueeze_478)
Input Tensors:
tensor870, Name: convolution_30, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor873, Name: unsqueeze_478, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1710, Name: sub_141, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1313, Name: torch.ops.aten.mul.Tensor(where_21, sub_141)
Input Tensors:
tensor1708, Name: where_21, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1710, Name: sub_141, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1711, Name: mul_569, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1314, Name: torch.ops.aten.sum.dim_IntList(mul_569, [0, 2, 3])
Input Tensors:
tensor1711, Name: mul_569, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1712, Name: sum_47, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1315, Name: torch.ops.aten.mul.Tensor(sum_46, 7.971938775510203e-05)
Input Tensors:
tensor1709, Name: sum_46, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1713, Name: mul_570, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1316, Name: torch.ops.aten.mul.Tensor(sum_47, 7.971938775510203e-05)
Input Tensors:
tensor1712, Name: sum_47, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1714, Name: mul_571, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1317, Name: torch.ops.aten.mul.Tensor(squeeze_91, squeeze_91)
Input Tensors:
tensor875, Name: squeeze_91, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor875, Name: squeeze_91, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1715, Name: mul_572, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1318, Name: torch.ops.aten.mul.Tensor(mul_571, mul_572)
Input Tensors:
tensor1714, Name: mul_571, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1715, Name: mul_572, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1716, Name: mul_573, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1319, Name: torch.ops.aten.mul.Tensor(squeeze_91, primals_92)
Input Tensors:
tensor875, Name: squeeze_91, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor91, Name: primals_92, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1717, Name: mul_574, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1320, Name: torch.ops.aten.mul.Tensor(sub_141, unsqueeze_484)
Input Tensors:
tensor1710, Name: sub_141, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1716, Name: unsqueeze_484, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1718, Name: mul_575, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1321, Name: torch.ops.aten.sub.Tensor(where_21, mul_575)
Input Tensors:
tensor1708, Name: where_21, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1718, Name: mul_575, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1719, Name: sub_143, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1322, Name: torch.ops.aten.sub.Tensor(sub_143, unsqueeze_481)
Input Tensors:
tensor1719, Name: sub_143, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1713, Name: unsqueeze_481, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1720, Name: sub_144, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1323, Name: torch.ops.aten.mul.Tensor(sub_144, unsqueeze_487)
Input Tensors:
tensor1720, Name: sub_144, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1717, Name: unsqueeze_487, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1721, Name: mul_576, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1324, Name: torch.ops.aten.mul.Tensor(sum_47, squeeze_91)
Input Tensors:
tensor1712, Name: sum_47, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor875, Name: squeeze_91, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1722, Name: mul_577, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1325, Name: torch.ops.aten.convolution_backward.default(mul_576, relu_26, primals_91, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1721, Name: mul_576, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor869, Name: relu_26, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor90, Name: primals_91, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor1723, Name: getitem_174, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1724, Name: getitem_175, Is global?: 0: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
____________________________________________________________________
Kernel ID: 1326, Name: torch.ops.aten.le.Scalar(relu_26, 0)
Input Tensors:
tensor869, Name: relu_26, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1725, Name: le_22, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1327, Name: torch.ops.aten.where.self(le_22, full_default, getitem_174)
Input Tensors:
tensor1725, Name: le_22, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1723, Name: getitem_174, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1726, Name: where_22, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1328, Name: torch.ops.aten.sum.dim_IntList(where_22, [0, 2, 3])
Input Tensors:
tensor1726, Name: where_22, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1727, Name: sum_48, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1329, Name: torch.ops.aten.sub.Tensor(convolution_29, unsqueeze_490)
Input Tensors:
tensor852, Name: convolution_29, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor855, Name: unsqueeze_490, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1728, Name: sub_145, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1330, Name: torch.ops.aten.mul.Tensor(where_22, sub_145)
Input Tensors:
tensor1726, Name: where_22, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1728, Name: sub_145, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1729, Name: mul_578, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1331, Name: torch.ops.aten.sum.dim_IntList(mul_578, [0, 2, 3])
Input Tensors:
tensor1729, Name: mul_578, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1730, Name: sum_49, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1332, Name: torch.ops.aten.mul.Tensor(sum_48, 7.971938775510203e-05)
Input Tensors:
tensor1727, Name: sum_48, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1731, Name: mul_579, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1333, Name: torch.ops.aten.mul.Tensor(sum_49, 7.971938775510203e-05)
Input Tensors:
tensor1730, Name: sum_49, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1732, Name: mul_580, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1334, Name: torch.ops.aten.mul.Tensor(squeeze_88, squeeze_88)
Input Tensors:
tensor857, Name: squeeze_88, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor857, Name: squeeze_88, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1733, Name: mul_581, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1335, Name: torch.ops.aten.mul.Tensor(mul_580, mul_581)
Input Tensors:
tensor1732, Name: mul_580, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1733, Name: mul_581, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1734, Name: mul_582, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1336, Name: torch.ops.aten.mul.Tensor(squeeze_88, primals_89)
Input Tensors:
tensor857, Name: squeeze_88, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor88, Name: primals_89, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1735, Name: mul_583, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1337, Name: torch.ops.aten.mul.Tensor(sub_145, unsqueeze_496)
Input Tensors:
tensor1728, Name: sub_145, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1734, Name: unsqueeze_496, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1736, Name: mul_584, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1338, Name: torch.ops.aten.sub.Tensor(where_22, mul_584)
Input Tensors:
tensor1726, Name: where_22, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1736, Name: mul_584, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1737, Name: sub_147, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1339, Name: torch.ops.aten.sub.Tensor(sub_147, unsqueeze_493)
Input Tensors:
tensor1737, Name: sub_147, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1731, Name: unsqueeze_493, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1738, Name: sub_148, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1340, Name: torch.ops.aten.mul.Tensor(sub_148, unsqueeze_499)
Input Tensors:
tensor1738, Name: sub_148, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1735, Name: unsqueeze_499, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1739, Name: mul_585, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1341, Name: torch.ops.aten.mul.Tensor(sum_49, squeeze_88)
Input Tensors:
tensor1730, Name: sum_49, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor857, Name: squeeze_88, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1740, Name: mul_586, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1342, Name: torch.ops.aten.convolution_backward.default(mul_585, relu_25, primals_88, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1739, Name: mul_585, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor851, Name: relu_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor87, Name: primals_88, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor1741, Name: getitem_177, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1742, Name: getitem_178, Is global?: 0: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
____________________________________________________________________
Kernel ID: 1343, Name: torch.ops.aten.le.Scalar(relu_25, 0)
Input Tensors:
tensor851, Name: relu_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1743, Name: le_23, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1344, Name: torch.ops.aten.where.self(le_23, full_default, getitem_177)
Input Tensors:
tensor1743, Name: le_23, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1741, Name: getitem_177, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1744, Name: where_23, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1345, Name: torch.ops.aten.sum.dim_IntList(where_23, [0, 2, 3])
Input Tensors:
tensor1744, Name: where_23, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1745, Name: sum_50, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1346, Name: torch.ops.aten.sub.Tensor(convolution_28, unsqueeze_502)
Input Tensors:
tensor834, Name: convolution_28, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor837, Name: unsqueeze_502, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1746, Name: sub_149, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1347, Name: torch.ops.aten.mul.Tensor(where_23, sub_149)
Input Tensors:
tensor1744, Name: where_23, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1746, Name: sub_149, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1747, Name: mul_587, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1348, Name: torch.ops.aten.sum.dim_IntList(mul_587, [0, 2, 3])
Input Tensors:
tensor1747, Name: mul_587, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1748, Name: sum_51, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1349, Name: torch.ops.aten.mul.Tensor(sum_50, 7.971938775510203e-05)
Input Tensors:
tensor1745, Name: sum_50, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1749, Name: mul_588, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1350, Name: torch.ops.aten.mul.Tensor(sum_51, 7.971938775510203e-05)
Input Tensors:
tensor1748, Name: sum_51, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1750, Name: mul_589, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1351, Name: torch.ops.aten.mul.Tensor(squeeze_85, squeeze_85)
Input Tensors:
tensor839, Name: squeeze_85, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor839, Name: squeeze_85, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1751, Name: mul_590, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1352, Name: torch.ops.aten.mul.Tensor(mul_589, mul_590)
Input Tensors:
tensor1750, Name: mul_589, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1751, Name: mul_590, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1752, Name: mul_591, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1353, Name: torch.ops.aten.mul.Tensor(squeeze_85, primals_86)
Input Tensors:
tensor839, Name: squeeze_85, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor85, Name: primals_86, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1753, Name: mul_592, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1354, Name: torch.ops.aten.mul.Tensor(sub_149, unsqueeze_508)
Input Tensors:
tensor1746, Name: sub_149, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1752, Name: unsqueeze_508, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1754, Name: mul_593, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1355, Name: torch.ops.aten.sub.Tensor(where_23, mul_593)
Input Tensors:
tensor1744, Name: where_23, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1754, Name: mul_593, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1755, Name: sub_151, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1356, Name: torch.ops.aten.sub.Tensor(sub_151, unsqueeze_505)
Input Tensors:
tensor1755, Name: sub_151, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1749, Name: unsqueeze_505, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1756, Name: sub_152, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1357, Name: torch.ops.aten.mul.Tensor(sub_152, unsqueeze_511)
Input Tensors:
tensor1756, Name: sub_152, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1753, Name: unsqueeze_511, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1757, Name: mul_594, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1358, Name: torch.ops.aten.mul.Tensor(sum_51, squeeze_85)
Input Tensors:
tensor1748, Name: sum_51, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor839, Name: squeeze_85, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1758, Name: mul_595, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1359, Name: torch.ops.aten.convolution_backward.default(mul_594, relu_24, primals_85, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1757, Name: mul_594, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor833, Name: relu_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor84, Name: primals_85, Is global?: 1: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
Output Tensors:
tensor1759, Name: getitem_180, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1760, Name: getitem_181, Is global?: 0: Size in byte: 1048576, Dimensions: f32[256, 1024, 1, 1]
____________________________________________________________________
Kernel ID: 1360, Name: torch.ops.aten.add.Tensor(where_21, getitem_180)
Input Tensors:
tensor1708, Name: where_21, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1759, Name: getitem_180, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1761, Name: add_288, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1361, Name: torch.ops.aten.le.Scalar(relu_24, 0)
Input Tensors:
tensor833, Name: relu_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1762, Name: le_24, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1362, Name: torch.ops.aten.where.self(le_24, full_default, add_288)
Input Tensors:
tensor1762, Name: le_24, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 1024, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1761, Name: add_288, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1763, Name: where_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1363, Name: torch.ops.aten.sum.dim_IntList(where_24, [0, 2, 3])
Input Tensors:
tensor1763, Name: where_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1764, Name: sum_52, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1364, Name: torch.ops.aten.sub.Tensor(convolution_27, unsqueeze_514)
Input Tensors:
tensor815, Name: convolution_27, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor818, Name: unsqueeze_514, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1765, Name: sub_153, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1365, Name: torch.ops.aten.mul.Tensor(where_24, sub_153)
Input Tensors:
tensor1763, Name: where_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1765, Name: sub_153, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1766, Name: mul_596, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1366, Name: torch.ops.aten.sum.dim_IntList(mul_596, [0, 2, 3])
Input Tensors:
tensor1766, Name: mul_596, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1767, Name: sum_53, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1367, Name: torch.ops.aten.mul.Tensor(sum_52, 7.971938775510203e-05)
Input Tensors:
tensor1764, Name: sum_52, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1768, Name: mul_597, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1368, Name: torch.ops.aten.mul.Tensor(sum_53, 7.971938775510203e-05)
Input Tensors:
tensor1767, Name: sum_53, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1769, Name: mul_598, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1369, Name: torch.ops.aten.mul.Tensor(squeeze_82, squeeze_82)
Input Tensors:
tensor820, Name: squeeze_82, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor820, Name: squeeze_82, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1770, Name: mul_599, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1370, Name: torch.ops.aten.mul.Tensor(mul_598, mul_599)
Input Tensors:
tensor1769, Name: mul_598, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1770, Name: mul_599, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1771, Name: mul_600, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1371, Name: torch.ops.aten.mul.Tensor(squeeze_82, primals_83)
Input Tensors:
tensor820, Name: squeeze_82, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor82, Name: primals_83, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1772, Name: mul_601, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1372, Name: torch.ops.aten.mul.Tensor(sub_153, unsqueeze_520)
Input Tensors:
tensor1765, Name: sub_153, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1771, Name: unsqueeze_520, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1773, Name: mul_602, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1373, Name: torch.ops.aten.sub.Tensor(where_24, mul_602)
Input Tensors:
tensor1763, Name: where_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1773, Name: mul_602, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1774, Name: sub_155, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1374, Name: torch.ops.aten.sub.Tensor(sub_155, unsqueeze_517)
Input Tensors:
tensor1774, Name: sub_155, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1768, Name: unsqueeze_517, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1775, Name: sub_156, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1375, Name: torch.ops.aten.mul.Tensor(sub_156, unsqueeze_523)
Input Tensors:
tensor1775, Name: sub_156, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1772, Name: unsqueeze_523, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1776, Name: mul_603, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1376, Name: torch.ops.aten.mul.Tensor(sum_53, squeeze_82)
Input Tensors:
tensor1767, Name: sum_53, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor820, Name: squeeze_82, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1777, Name: mul_604, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1377, Name: torch.ops.aten.convolution_backward.default(mul_603, relu_21, primals_82, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1776, Name: mul_603, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor761, Name: relu_21, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor81, Name: primals_82, Is global?: 1: Size in byte: 2097152, Dimensions: f32[1024, 512, 1, 1]
Output Tensors:
tensor1778, Name: getitem_183, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1779, Name: getitem_184, Is global?: 0: Size in byte: 2097152, Dimensions: f32[1024, 512, 1, 1]
____________________________________________________________________
Kernel ID: 1378, Name: torch.ops.aten.sub.Tensor(convolution_26, unsqueeze_526)
Input Tensors:
tensor798, Name: convolution_26, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor801, Name: unsqueeze_526, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1780, Name: sub_157, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1379, Name: torch.ops.aten.mul.Tensor(where_24, sub_157)
Input Tensors:
tensor1763, Name: where_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1780, Name: sub_157, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1781, Name: mul_605, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1380, Name: torch.ops.aten.sum.dim_IntList(mul_605, [0, 2, 3])
Input Tensors:
tensor1781, Name: mul_605, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1782, Name: sum_55, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1381, Name: torch.ops.aten.mul.Tensor(sum_55, 7.971938775510203e-05)
Input Tensors:
tensor1782, Name: sum_55, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1783, Name: mul_607, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1382, Name: torch.ops.aten.mul.Tensor(squeeze_79, squeeze_79)
Input Tensors:
tensor803, Name: squeeze_79, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor803, Name: squeeze_79, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1784, Name: mul_608, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1383, Name: torch.ops.aten.mul.Tensor(mul_607, mul_608)
Input Tensors:
tensor1783, Name: mul_607, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor1784, Name: mul_608, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1785, Name: mul_609, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1384, Name: torch.ops.aten.mul.Tensor(squeeze_79, primals_80)
Input Tensors:
tensor803, Name: squeeze_79, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor79, Name: primals_80, Is global?: 1: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1786, Name: mul_610, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1385, Name: torch.ops.aten.mul.Tensor(sub_157, unsqueeze_532)
Input Tensors:
tensor1780, Name: sub_157, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1785, Name: unsqueeze_532, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1787, Name: mul_611, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1386, Name: torch.ops.aten.sub.Tensor(where_24, mul_611)
Input Tensors:
tensor1763, Name: where_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1787, Name: mul_611, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
Output Tensors:
tensor1788, Name: sub_159, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1387, Name: torch.ops.aten.sub.Tensor(sub_159, unsqueeze_517)
Input Tensors:
tensor1788, Name: sub_159, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1768, Name: unsqueeze_517, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1789, Name: sub_160, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1388, Name: torch.ops.aten.mul.Tensor(sub_160, unsqueeze_535)
Input Tensors:
tensor1789, Name: sub_160, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor1786, Name: unsqueeze_535, Is global?: 0: Size in byte: 4096, Dimensions: f32[1, 1024, 1, 1]
Output Tensors:
tensor1790, Name: mul_612, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
____________________________________________________________________
Kernel ID: 1389, Name: torch.ops.aten.mul.Tensor(sum_55, squeeze_79)
Input Tensors:
tensor1782, Name: sum_55, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
tensor803, Name: squeeze_79, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
Output Tensors:
tensor1791, Name: mul_613, Is global?: 0: Size in byte: 4096, Dimensions: f32[1024]
____________________________________________________________________
Kernel ID: 1390, Name: torch.ops.aten.convolution_backward.default(mul_612, relu_23, primals_79, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1790, Name: mul_612, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 1024, 14, 14]
tensor797, Name: relu_23, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor78, Name: primals_79, Is global?: 1: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
Output Tensors:
tensor1792, Name: getitem_186, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1793, Name: getitem_187, Is global?: 0: Size in byte: 1048576, Dimensions: f32[1024, 256, 1, 1]
____________________________________________________________________
Kernel ID: 1391, Name: torch.ops.aten.le.Scalar(relu_23, 0)
Input Tensors:
tensor797, Name: relu_23, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1794, Name: le_25, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1392, Name: torch.ops.aten.where.self(le_25, full_default, getitem_186)
Input Tensors:
tensor1794, Name: le_25, Is global?: 0: Size in byte: 3211264, Dimensions: b8[64, 256, 14, 14]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1792, Name: getitem_186, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1795, Name: where_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1393, Name: torch.ops.aten.sum.dim_IntList(where_25, [0, 2, 3])
Input Tensors:
tensor1795, Name: where_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1796, Name: sum_56, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1394, Name: torch.ops.aten.sub.Tensor(convolution_25, unsqueeze_538)
Input Tensors:
tensor780, Name: convolution_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor783, Name: unsqueeze_538, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1797, Name: sub_161, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1395, Name: torch.ops.aten.mul.Tensor(where_25, sub_161)
Input Tensors:
tensor1795, Name: where_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1797, Name: sub_161, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1798, Name: mul_614, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1396, Name: torch.ops.aten.sum.dim_IntList(mul_614, [0, 2, 3])
Input Tensors:
tensor1798, Name: mul_614, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1799, Name: sum_57, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1397, Name: torch.ops.aten.mul.Tensor(sum_56, 7.971938775510203e-05)
Input Tensors:
tensor1796, Name: sum_56, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1800, Name: mul_615, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1398, Name: torch.ops.aten.mul.Tensor(sum_57, 7.971938775510203e-05)
Input Tensors:
tensor1799, Name: sum_57, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1801, Name: mul_616, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1399, Name: torch.ops.aten.mul.Tensor(squeeze_76, squeeze_76)
Input Tensors:
tensor785, Name: squeeze_76, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor785, Name: squeeze_76, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1802, Name: mul_617, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1400, Name: torch.ops.aten.mul.Tensor(mul_616, mul_617)
Input Tensors:
tensor1801, Name: mul_616, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1802, Name: mul_617, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1803, Name: mul_618, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1401, Name: torch.ops.aten.mul.Tensor(squeeze_76, primals_77)
Input Tensors:
tensor785, Name: squeeze_76, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor76, Name: primals_77, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1804, Name: mul_619, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1402, Name: torch.ops.aten.mul.Tensor(sub_161, unsqueeze_544)
Input Tensors:
tensor1797, Name: sub_161, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1803, Name: unsqueeze_544, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1805, Name: mul_620, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1403, Name: torch.ops.aten.sub.Tensor(where_25, mul_620)
Input Tensors:
tensor1795, Name: where_25, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1805, Name: mul_620, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
Output Tensors:
tensor1806, Name: sub_163, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1404, Name: torch.ops.aten.sub.Tensor(sub_163, unsqueeze_541)
Input Tensors:
tensor1806, Name: sub_163, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1800, Name: unsqueeze_541, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1807, Name: sub_164, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1405, Name: torch.ops.aten.mul.Tensor(sub_164, unsqueeze_547)
Input Tensors:
tensor1807, Name: sub_164, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor1804, Name: unsqueeze_547, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1808, Name: mul_621, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
____________________________________________________________________
Kernel ID: 1406, Name: torch.ops.aten.mul.Tensor(sum_57, squeeze_76)
Input Tensors:
tensor1799, Name: sum_57, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor785, Name: squeeze_76, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1809, Name: mul_622, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1407, Name: torch.ops.aten.convolution_backward.default(mul_621, relu_22, primals_76, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1808, Name: mul_621, Is global?: 0: Size in byte: 12845056, Dimensions: f32[64, 256, 14, 14]
tensor779, Name: relu_22, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor75, Name: primals_76, Is global?: 1: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
Output Tensors:
tensor1810, Name: getitem_189, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor1811, Name: getitem_190, Is global?: 0: Size in byte: 2359296, Dimensions: f32[256, 256, 3, 3]
____________________________________________________________________
Kernel ID: 1408, Name: torch.ops.aten.le.Scalar(relu_22, 0)
Input Tensors:
tensor779, Name: relu_22, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
Output Tensors:
tensor1812, Name: le_26, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 1409, Name: torch.ops.aten.where.self(le_26, full_default, getitem_189)
Input Tensors:
tensor1812, Name: le_26, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 256, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1810, Name: getitem_189, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
Output Tensors:
tensor1813, Name: where_26, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 1410, Name: torch.ops.aten.sum.dim_IntList(where_26, [0, 2, 3])
Input Tensors:
tensor1813, Name: where_26, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
Output Tensors:
tensor1814, Name: sum_58, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1411, Name: torch.ops.aten.sub.Tensor(convolution_24, unsqueeze_550)
Input Tensors:
tensor762, Name: convolution_24, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor765, Name: unsqueeze_550, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1815, Name: sub_165, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 1412, Name: torch.ops.aten.mul.Tensor(where_26, sub_165)
Input Tensors:
tensor1813, Name: where_26, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor1815, Name: sub_165, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
Output Tensors:
tensor1816, Name: mul_623, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 1413, Name: torch.ops.aten.sum.dim_IntList(mul_623, [0, 2, 3])
Input Tensors:
tensor1816, Name: mul_623, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
Output Tensors:
tensor1817, Name: sum_59, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1414, Name: torch.ops.aten.mul.Tensor(sum_58, 1.992984693877551e-05)
Input Tensors:
tensor1814, Name: sum_58, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1818, Name: mul_624, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1415, Name: torch.ops.aten.mul.Tensor(sum_59, 1.992984693877551e-05)
Input Tensors:
tensor1817, Name: sum_59, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1819, Name: mul_625, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1416, Name: torch.ops.aten.mul.Tensor(squeeze_73, squeeze_73)
Input Tensors:
tensor767, Name: squeeze_73, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor767, Name: squeeze_73, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1820, Name: mul_626, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1417, Name: torch.ops.aten.mul.Tensor(mul_625, mul_626)
Input Tensors:
tensor1819, Name: mul_625, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor1820, Name: mul_626, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1821, Name: mul_627, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1418, Name: torch.ops.aten.mul.Tensor(squeeze_73, primals_74)
Input Tensors:
tensor767, Name: squeeze_73, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor73, Name: primals_74, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1822, Name: mul_628, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1419, Name: torch.ops.aten.mul.Tensor(sub_165, unsqueeze_556)
Input Tensors:
tensor1815, Name: sub_165, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor1821, Name: unsqueeze_556, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1823, Name: mul_629, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 1420, Name: torch.ops.aten.sub.Tensor(where_26, mul_629)
Input Tensors:
tensor1813, Name: where_26, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor1823, Name: mul_629, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
Output Tensors:
tensor1824, Name: sub_167, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 1421, Name: torch.ops.aten.sub.Tensor(sub_167, unsqueeze_553)
Input Tensors:
tensor1824, Name: sub_167, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor1818, Name: unsqueeze_553, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1825, Name: sub_168, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 1422, Name: torch.ops.aten.mul.Tensor(sub_168, unsqueeze_559)
Input Tensors:
tensor1825, Name: sub_168, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor1822, Name: unsqueeze_559, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor1826, Name: mul_630, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
____________________________________________________________________
Kernel ID: 1423, Name: torch.ops.aten.mul.Tensor(sum_59, squeeze_73)
Input Tensors:
tensor1817, Name: sum_59, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor767, Name: squeeze_73, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor1827, Name: mul_631, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1424, Name: torch.ops.aten.convolution_backward.default(mul_630, relu_21, primals_73, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1826, Name: mul_630, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 256, 28, 28]
tensor761, Name: relu_21, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor72, Name: primals_73, Is global?: 1: Size in byte: 524288, Dimensions: f32[256, 512, 1, 1]
Output Tensors:
tensor1828, Name: getitem_192, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1829, Name: getitem_193, Is global?: 0: Size in byte: 524288, Dimensions: f32[256, 512, 1, 1]
____________________________________________________________________
Kernel ID: 1425, Name: torch.ops.aten.add.Tensor(getitem_183, getitem_192)
Input Tensors:
tensor1778, Name: getitem_183, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1828, Name: getitem_192, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1830, Name: add_289, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1426, Name: torch.ops.aten.le.Scalar(relu_21, 0)
Input Tensors:
tensor761, Name: relu_21, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1831, Name: le_27, Is global?: 0: Size in byte: 25690112, Dimensions: b8[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1427, Name: torch.ops.aten.where.self(le_27, full_default, add_289)
Input Tensors:
tensor1831, Name: le_27, Is global?: 0: Size in byte: 25690112, Dimensions: b8[64, 512, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1830, Name: add_289, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1832, Name: where_27, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1428, Name: torch.ops.aten.sum.dim_IntList(where_27, [0, 2, 3])
Input Tensors:
tensor1832, Name: where_27, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1833, Name: sum_60, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1429, Name: torch.ops.aten.sub.Tensor(convolution_23, unsqueeze_562)
Input Tensors:
tensor743, Name: convolution_23, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor746, Name: unsqueeze_562, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1834, Name: sub_169, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1430, Name: torch.ops.aten.mul.Tensor(where_27, sub_169)
Input Tensors:
tensor1832, Name: where_27, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1834, Name: sub_169, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1835, Name: mul_632, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1431, Name: torch.ops.aten.sum.dim_IntList(mul_632, [0, 2, 3])
Input Tensors:
tensor1835, Name: mul_632, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1836, Name: sum_61, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1432, Name: torch.ops.aten.mul.Tensor(sum_60, 1.992984693877551e-05)
Input Tensors:
tensor1833, Name: sum_60, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1837, Name: mul_633, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1433, Name: torch.ops.aten.mul.Tensor(sum_61, 1.992984693877551e-05)
Input Tensors:
tensor1836, Name: sum_61, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1838, Name: mul_634, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1434, Name: torch.ops.aten.mul.Tensor(squeeze_70, squeeze_70)
Input Tensors:
tensor748, Name: squeeze_70, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor748, Name: squeeze_70, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1839, Name: mul_635, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1435, Name: torch.ops.aten.mul.Tensor(mul_634, mul_635)
Input Tensors:
tensor1838, Name: mul_634, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1839, Name: mul_635, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1840, Name: mul_636, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1436, Name: torch.ops.aten.mul.Tensor(squeeze_70, primals_71)
Input Tensors:
tensor748, Name: squeeze_70, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor70, Name: primals_71, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1841, Name: mul_637, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1437, Name: torch.ops.aten.mul.Tensor(sub_169, unsqueeze_568)
Input Tensors:
tensor1834, Name: sub_169, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1840, Name: unsqueeze_568, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1842, Name: mul_638, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1438, Name: torch.ops.aten.sub.Tensor(where_27, mul_638)
Input Tensors:
tensor1832, Name: where_27, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1842, Name: mul_638, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1843, Name: sub_171, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1439, Name: torch.ops.aten.sub.Tensor(sub_171, unsqueeze_565)
Input Tensors:
tensor1843, Name: sub_171, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1837, Name: unsqueeze_565, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1844, Name: sub_172, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1440, Name: torch.ops.aten.mul.Tensor(sub_172, unsqueeze_571)
Input Tensors:
tensor1844, Name: sub_172, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1841, Name: unsqueeze_571, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1845, Name: mul_639, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1441, Name: torch.ops.aten.mul.Tensor(sum_61, squeeze_70)
Input Tensors:
tensor1836, Name: sum_61, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor748, Name: squeeze_70, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1846, Name: mul_640, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1442, Name: torch.ops.aten.convolution_backward.default(mul_639, relu_20, primals_70, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1845, Name: mul_639, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor742, Name: relu_20, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor69, Name: primals_70, Is global?: 1: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
Output Tensors:
tensor1847, Name: getitem_195, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1848, Name: getitem_196, Is global?: 0: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
____________________________________________________________________
Kernel ID: 1443, Name: torch.ops.aten.le.Scalar(relu_20, 0)
Input Tensors:
tensor742, Name: relu_20, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1849, Name: le_28, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1444, Name: torch.ops.aten.where.self(le_28, full_default, getitem_195)
Input Tensors:
tensor1849, Name: le_28, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1847, Name: getitem_195, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1850, Name: where_28, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1445, Name: torch.ops.aten.sum.dim_IntList(where_28, [0, 2, 3])
Input Tensors:
tensor1850, Name: where_28, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1851, Name: sum_62, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1446, Name: torch.ops.aten.sub.Tensor(convolution_22, unsqueeze_574)
Input Tensors:
tensor725, Name: convolution_22, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor728, Name: unsqueeze_574, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1852, Name: sub_173, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1447, Name: torch.ops.aten.mul.Tensor(where_28, sub_173)
Input Tensors:
tensor1850, Name: where_28, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1852, Name: sub_173, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1853, Name: mul_641, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1448, Name: torch.ops.aten.sum.dim_IntList(mul_641, [0, 2, 3])
Input Tensors:
tensor1853, Name: mul_641, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1854, Name: sum_63, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1449, Name: torch.ops.aten.mul.Tensor(sum_62, 1.992984693877551e-05)
Input Tensors:
tensor1851, Name: sum_62, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1855, Name: mul_642, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1450, Name: torch.ops.aten.mul.Tensor(sum_63, 1.992984693877551e-05)
Input Tensors:
tensor1854, Name: sum_63, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1856, Name: mul_643, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1451, Name: torch.ops.aten.mul.Tensor(squeeze_67, squeeze_67)
Input Tensors:
tensor730, Name: squeeze_67, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor730, Name: squeeze_67, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1857, Name: mul_644, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1452, Name: torch.ops.aten.mul.Tensor(mul_643, mul_644)
Input Tensors:
tensor1856, Name: mul_643, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor1857, Name: mul_644, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1858, Name: mul_645, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1453, Name: torch.ops.aten.mul.Tensor(squeeze_67, primals_68)
Input Tensors:
tensor730, Name: squeeze_67, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor67, Name: primals_68, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1859, Name: mul_646, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1454, Name: torch.ops.aten.mul.Tensor(sub_173, unsqueeze_580)
Input Tensors:
tensor1852, Name: sub_173, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1858, Name: unsqueeze_580, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1860, Name: mul_647, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1455, Name: torch.ops.aten.sub.Tensor(where_28, mul_647)
Input Tensors:
tensor1850, Name: where_28, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1860, Name: mul_647, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1861, Name: sub_175, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1456, Name: torch.ops.aten.sub.Tensor(sub_175, unsqueeze_577)
Input Tensors:
tensor1861, Name: sub_175, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1855, Name: unsqueeze_577, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1862, Name: sub_176, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1457, Name: torch.ops.aten.mul.Tensor(sub_176, unsqueeze_583)
Input Tensors:
tensor1862, Name: sub_176, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1859, Name: unsqueeze_583, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1863, Name: mul_648, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1458, Name: torch.ops.aten.mul.Tensor(sum_63, squeeze_67)
Input Tensors:
tensor1854, Name: sum_63, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor730, Name: squeeze_67, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1864, Name: mul_649, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1459, Name: torch.ops.aten.convolution_backward.default(mul_648, relu_19, primals_67, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1863, Name: mul_648, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor724, Name: relu_19, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor66, Name: primals_67, Is global?: 1: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
Output Tensors:
tensor1865, Name: getitem_198, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1866, Name: getitem_199, Is global?: 0: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
____________________________________________________________________
Kernel ID: 1460, Name: torch.ops.aten.le.Scalar(relu_19, 0)
Input Tensors:
tensor724, Name: relu_19, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1867, Name: le_29, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1461, Name: torch.ops.aten.where.self(le_29, full_default, getitem_198)
Input Tensors:
tensor1867, Name: le_29, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1865, Name: getitem_198, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1868, Name: where_29, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1462, Name: torch.ops.aten.sum.dim_IntList(where_29, [0, 2, 3])
Input Tensors:
tensor1868, Name: where_29, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1869, Name: sum_64, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1463, Name: torch.ops.aten.sub.Tensor(convolution_21, unsqueeze_586)
Input Tensors:
tensor707, Name: convolution_21, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor710, Name: unsqueeze_586, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1870, Name: sub_177, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1464, Name: torch.ops.aten.mul.Tensor(where_29, sub_177)
Input Tensors:
tensor1868, Name: where_29, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1870, Name: sub_177, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1871, Name: mul_650, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1465, Name: torch.ops.aten.sum.dim_IntList(mul_650, [0, 2, 3])
Input Tensors:
tensor1871, Name: mul_650, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1872, Name: sum_65, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1466, Name: torch.ops.aten.mul.Tensor(sum_64, 1.992984693877551e-05)
Input Tensors:
tensor1869, Name: sum_64, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1873, Name: mul_651, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1467, Name: torch.ops.aten.mul.Tensor(sum_65, 1.992984693877551e-05)
Input Tensors:
tensor1872, Name: sum_65, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1874, Name: mul_652, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1468, Name: torch.ops.aten.mul.Tensor(squeeze_64, squeeze_64)
Input Tensors:
tensor712, Name: squeeze_64, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor712, Name: squeeze_64, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1875, Name: mul_653, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1469, Name: torch.ops.aten.mul.Tensor(mul_652, mul_653)
Input Tensors:
tensor1874, Name: mul_652, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor1875, Name: mul_653, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1876, Name: mul_654, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1470, Name: torch.ops.aten.mul.Tensor(squeeze_64, primals_65)
Input Tensors:
tensor712, Name: squeeze_64, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor64, Name: primals_65, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1877, Name: mul_655, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1471, Name: torch.ops.aten.mul.Tensor(sub_177, unsqueeze_592)
Input Tensors:
tensor1870, Name: sub_177, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1876, Name: unsqueeze_592, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1878, Name: mul_656, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1472, Name: torch.ops.aten.sub.Tensor(where_29, mul_656)
Input Tensors:
tensor1868, Name: where_29, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1878, Name: mul_656, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1879, Name: sub_179, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1473, Name: torch.ops.aten.sub.Tensor(sub_179, unsqueeze_589)
Input Tensors:
tensor1879, Name: sub_179, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1873, Name: unsqueeze_589, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1880, Name: sub_180, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1474, Name: torch.ops.aten.mul.Tensor(sub_180, unsqueeze_595)
Input Tensors:
tensor1880, Name: sub_180, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1877, Name: unsqueeze_595, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1881, Name: mul_657, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1475, Name: torch.ops.aten.mul.Tensor(sum_65, squeeze_64)
Input Tensors:
tensor1872, Name: sum_65, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor712, Name: squeeze_64, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1882, Name: mul_658, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1476, Name: torch.ops.aten.convolution_backward.default(mul_657, relu_18, primals_64, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1881, Name: mul_657, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor706, Name: relu_18, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor63, Name: primals_64, Is global?: 1: Size in byte: 262144, Dimensions: f32[128, 512, 1, 1]
Output Tensors:
tensor1883, Name: getitem_201, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1884, Name: getitem_202, Is global?: 0: Size in byte: 262144, Dimensions: f32[128, 512, 1, 1]
____________________________________________________________________
Kernel ID: 1477, Name: torch.ops.aten.add.Tensor(where_27, getitem_201)
Input Tensors:
tensor1832, Name: where_27, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1883, Name: getitem_201, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1885, Name: add_290, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1478, Name: torch.ops.aten.le.Scalar(relu_18, 0)
Input Tensors:
tensor706, Name: relu_18, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1886, Name: le_30, Is global?: 0: Size in byte: 25690112, Dimensions: b8[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1479, Name: torch.ops.aten.where.self(le_30, full_default, add_290)
Input Tensors:
tensor1886, Name: le_30, Is global?: 0: Size in byte: 25690112, Dimensions: b8[64, 512, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1885, Name: add_290, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1887, Name: where_30, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1480, Name: torch.ops.aten.sum.dim_IntList(where_30, [0, 2, 3])
Input Tensors:
tensor1887, Name: where_30, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1888, Name: sum_66, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1481, Name: torch.ops.aten.sub.Tensor(convolution_20, unsqueeze_598)
Input Tensors:
tensor688, Name: convolution_20, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor691, Name: unsqueeze_598, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1889, Name: sub_181, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1482, Name: torch.ops.aten.mul.Tensor(where_30, sub_181)
Input Tensors:
tensor1887, Name: where_30, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1889, Name: sub_181, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1890, Name: mul_659, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1483, Name: torch.ops.aten.sum.dim_IntList(mul_659, [0, 2, 3])
Input Tensors:
tensor1890, Name: mul_659, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1891, Name: sum_67, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1484, Name: torch.ops.aten.mul.Tensor(sum_66, 1.992984693877551e-05)
Input Tensors:
tensor1888, Name: sum_66, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1892, Name: mul_660, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1485, Name: torch.ops.aten.mul.Tensor(sum_67, 1.992984693877551e-05)
Input Tensors:
tensor1891, Name: sum_67, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1893, Name: mul_661, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1486, Name: torch.ops.aten.mul.Tensor(squeeze_61, squeeze_61)
Input Tensors:
tensor693, Name: squeeze_61, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor693, Name: squeeze_61, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1894, Name: mul_662, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1487, Name: torch.ops.aten.mul.Tensor(mul_661, mul_662)
Input Tensors:
tensor1893, Name: mul_661, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1894, Name: mul_662, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1895, Name: mul_663, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1488, Name: torch.ops.aten.mul.Tensor(squeeze_61, primals_62)
Input Tensors:
tensor693, Name: squeeze_61, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor61, Name: primals_62, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1896, Name: mul_664, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1489, Name: torch.ops.aten.mul.Tensor(sub_181, unsqueeze_604)
Input Tensors:
tensor1889, Name: sub_181, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1895, Name: unsqueeze_604, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1897, Name: mul_665, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1490, Name: torch.ops.aten.sub.Tensor(where_30, mul_665)
Input Tensors:
tensor1887, Name: where_30, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1897, Name: mul_665, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1898, Name: sub_183, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1491, Name: torch.ops.aten.sub.Tensor(sub_183, unsqueeze_601)
Input Tensors:
tensor1898, Name: sub_183, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1892, Name: unsqueeze_601, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1899, Name: sub_184, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1492, Name: torch.ops.aten.mul.Tensor(sub_184, unsqueeze_607)
Input Tensors:
tensor1899, Name: sub_184, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1896, Name: unsqueeze_607, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1900, Name: mul_666, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1493, Name: torch.ops.aten.mul.Tensor(sum_67, squeeze_61)
Input Tensors:
tensor1891, Name: sum_67, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor693, Name: squeeze_61, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1901, Name: mul_667, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1494, Name: torch.ops.aten.convolution_backward.default(mul_666, relu_17, primals_61, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1900, Name: mul_666, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor687, Name: relu_17, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor60, Name: primals_61, Is global?: 1: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
Output Tensors:
tensor1902, Name: getitem_204, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1903, Name: getitem_205, Is global?: 0: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
____________________________________________________________________
Kernel ID: 1495, Name: torch.ops.aten.le.Scalar(relu_17, 0)
Input Tensors:
tensor687, Name: relu_17, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1904, Name: le_31, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1496, Name: torch.ops.aten.where.self(le_31, full_default, getitem_204)
Input Tensors:
tensor1904, Name: le_31, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1902, Name: getitem_204, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1905, Name: where_31, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1497, Name: torch.ops.aten.sum.dim_IntList(where_31, [0, 2, 3])
Input Tensors:
tensor1905, Name: where_31, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1906, Name: sum_68, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1498, Name: torch.ops.aten.sub.Tensor(convolution_19, unsqueeze_610)
Input Tensors:
tensor670, Name: convolution_19, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor673, Name: unsqueeze_610, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1907, Name: sub_185, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1499, Name: torch.ops.aten.mul.Tensor(where_31, sub_185)
Input Tensors:
tensor1905, Name: where_31, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1907, Name: sub_185, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1908, Name: mul_668, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1500, Name: torch.ops.aten.sum.dim_IntList(mul_668, [0, 2, 3])
Input Tensors:
tensor1908, Name: mul_668, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1909, Name: sum_69, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1501, Name: torch.ops.aten.mul.Tensor(sum_68, 1.992984693877551e-05)
Input Tensors:
tensor1906, Name: sum_68, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1910, Name: mul_669, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1502, Name: torch.ops.aten.mul.Tensor(sum_69, 1.992984693877551e-05)
Input Tensors:
tensor1909, Name: sum_69, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1911, Name: mul_670, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1503, Name: torch.ops.aten.mul.Tensor(squeeze_58, squeeze_58)
Input Tensors:
tensor675, Name: squeeze_58, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor675, Name: squeeze_58, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1912, Name: mul_671, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1504, Name: torch.ops.aten.mul.Tensor(mul_670, mul_671)
Input Tensors:
tensor1911, Name: mul_670, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor1912, Name: mul_671, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1913, Name: mul_672, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1505, Name: torch.ops.aten.mul.Tensor(squeeze_58, primals_59)
Input Tensors:
tensor675, Name: squeeze_58, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor58, Name: primals_59, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1914, Name: mul_673, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1506, Name: torch.ops.aten.mul.Tensor(sub_185, unsqueeze_616)
Input Tensors:
tensor1907, Name: sub_185, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1913, Name: unsqueeze_616, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1915, Name: mul_674, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1507, Name: torch.ops.aten.sub.Tensor(where_31, mul_674)
Input Tensors:
tensor1905, Name: where_31, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1915, Name: mul_674, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1916, Name: sub_187, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1508, Name: torch.ops.aten.sub.Tensor(sub_187, unsqueeze_613)
Input Tensors:
tensor1916, Name: sub_187, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1910, Name: unsqueeze_613, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1917, Name: sub_188, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1509, Name: torch.ops.aten.mul.Tensor(sub_188, unsqueeze_619)
Input Tensors:
tensor1917, Name: sub_188, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1914, Name: unsqueeze_619, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1918, Name: mul_675, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1510, Name: torch.ops.aten.mul.Tensor(sum_69, squeeze_58)
Input Tensors:
tensor1909, Name: sum_69, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor675, Name: squeeze_58, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1919, Name: mul_676, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1511, Name: torch.ops.aten.convolution_backward.default(mul_675, relu_16, primals_58, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1918, Name: mul_675, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor669, Name: relu_16, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor57, Name: primals_58, Is global?: 1: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
Output Tensors:
tensor1920, Name: getitem_207, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1921, Name: getitem_208, Is global?: 0: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
____________________________________________________________________
Kernel ID: 1512, Name: torch.ops.aten.le.Scalar(relu_16, 0)
Input Tensors:
tensor669, Name: relu_16, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1922, Name: le_32, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1513, Name: torch.ops.aten.where.self(le_32, full_default, getitem_207)
Input Tensors:
tensor1922, Name: le_32, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1920, Name: getitem_207, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1923, Name: where_32, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1514, Name: torch.ops.aten.sum.dim_IntList(where_32, [0, 2, 3])
Input Tensors:
tensor1923, Name: where_32, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1924, Name: sum_70, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1515, Name: torch.ops.aten.sub.Tensor(convolution_18, unsqueeze_622)
Input Tensors:
tensor652, Name: convolution_18, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor655, Name: unsqueeze_622, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1925, Name: sub_189, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1516, Name: torch.ops.aten.mul.Tensor(where_32, sub_189)
Input Tensors:
tensor1923, Name: where_32, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1925, Name: sub_189, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1926, Name: mul_677, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1517, Name: torch.ops.aten.sum.dim_IntList(mul_677, [0, 2, 3])
Input Tensors:
tensor1926, Name: mul_677, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1927, Name: sum_71, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1518, Name: torch.ops.aten.mul.Tensor(sum_70, 1.992984693877551e-05)
Input Tensors:
tensor1924, Name: sum_70, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1928, Name: mul_678, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1519, Name: torch.ops.aten.mul.Tensor(sum_71, 1.992984693877551e-05)
Input Tensors:
tensor1927, Name: sum_71, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1929, Name: mul_679, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1520, Name: torch.ops.aten.mul.Tensor(squeeze_55, squeeze_55)
Input Tensors:
tensor657, Name: squeeze_55, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor657, Name: squeeze_55, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1930, Name: mul_680, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1521, Name: torch.ops.aten.mul.Tensor(mul_679, mul_680)
Input Tensors:
tensor1929, Name: mul_679, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor1930, Name: mul_680, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1931, Name: mul_681, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1522, Name: torch.ops.aten.mul.Tensor(squeeze_55, primals_56)
Input Tensors:
tensor657, Name: squeeze_55, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor55, Name: primals_56, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1932, Name: mul_682, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1523, Name: torch.ops.aten.mul.Tensor(sub_189, unsqueeze_628)
Input Tensors:
tensor1925, Name: sub_189, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1931, Name: unsqueeze_628, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1933, Name: mul_683, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1524, Name: torch.ops.aten.sub.Tensor(where_32, mul_683)
Input Tensors:
tensor1923, Name: where_32, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1933, Name: mul_683, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1934, Name: sub_191, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1525, Name: torch.ops.aten.sub.Tensor(sub_191, unsqueeze_625)
Input Tensors:
tensor1934, Name: sub_191, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1928, Name: unsqueeze_625, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1935, Name: sub_192, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1526, Name: torch.ops.aten.mul.Tensor(sub_192, unsqueeze_631)
Input Tensors:
tensor1935, Name: sub_192, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1932, Name: unsqueeze_631, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1936, Name: mul_684, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1527, Name: torch.ops.aten.mul.Tensor(sum_71, squeeze_55)
Input Tensors:
tensor1927, Name: sum_71, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor657, Name: squeeze_55, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1937, Name: mul_685, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1528, Name: torch.ops.aten.convolution_backward.default(mul_684, relu_15, primals_55, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1936, Name: mul_684, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor651, Name: relu_15, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor54, Name: primals_55, Is global?: 1: Size in byte: 262144, Dimensions: f32[128, 512, 1, 1]
Output Tensors:
tensor1938, Name: getitem_210, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1939, Name: getitem_211, Is global?: 0: Size in byte: 262144, Dimensions: f32[128, 512, 1, 1]
____________________________________________________________________
Kernel ID: 1529, Name: torch.ops.aten.add.Tensor(where_30, getitem_210)
Input Tensors:
tensor1887, Name: where_30, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1938, Name: getitem_210, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1940, Name: add_291, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1530, Name: torch.ops.aten.le.Scalar(relu_15, 0)
Input Tensors:
tensor651, Name: relu_15, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1941, Name: le_33, Is global?: 0: Size in byte: 25690112, Dimensions: b8[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1531, Name: torch.ops.aten.where.self(le_33, full_default, add_291)
Input Tensors:
tensor1941, Name: le_33, Is global?: 0: Size in byte: 25690112, Dimensions: b8[64, 512, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1940, Name: add_291, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1942, Name: where_33, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1532, Name: torch.ops.aten.sum.dim_IntList(where_33, [0, 2, 3])
Input Tensors:
tensor1942, Name: where_33, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1943, Name: sum_72, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1533, Name: torch.ops.aten.sub.Tensor(convolution_17, unsqueeze_634)
Input Tensors:
tensor633, Name: convolution_17, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor636, Name: unsqueeze_634, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1944, Name: sub_193, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1534, Name: torch.ops.aten.mul.Tensor(where_33, sub_193)
Input Tensors:
tensor1942, Name: where_33, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1944, Name: sub_193, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1945, Name: mul_686, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1535, Name: torch.ops.aten.sum.dim_IntList(mul_686, [0, 2, 3])
Input Tensors:
tensor1945, Name: mul_686, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1946, Name: sum_73, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1536, Name: torch.ops.aten.mul.Tensor(sum_72, 1.992984693877551e-05)
Input Tensors:
tensor1943, Name: sum_72, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1947, Name: mul_687, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1537, Name: torch.ops.aten.mul.Tensor(sum_73, 1.992984693877551e-05)
Input Tensors:
tensor1946, Name: sum_73, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1948, Name: mul_688, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1538, Name: torch.ops.aten.mul.Tensor(squeeze_52, squeeze_52)
Input Tensors:
tensor638, Name: squeeze_52, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor638, Name: squeeze_52, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1949, Name: mul_689, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1539, Name: torch.ops.aten.mul.Tensor(mul_688, mul_689)
Input Tensors:
tensor1948, Name: mul_688, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor1949, Name: mul_689, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1950, Name: mul_690, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1540, Name: torch.ops.aten.mul.Tensor(squeeze_52, primals_53)
Input Tensors:
tensor638, Name: squeeze_52, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor52, Name: primals_53, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1951, Name: mul_691, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1541, Name: torch.ops.aten.mul.Tensor(sub_193, unsqueeze_640)
Input Tensors:
tensor1944, Name: sub_193, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1950, Name: unsqueeze_640, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1952, Name: mul_692, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1542, Name: torch.ops.aten.sub.Tensor(where_33, mul_692)
Input Tensors:
tensor1942, Name: where_33, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1952, Name: mul_692, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1953, Name: sub_195, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1543, Name: torch.ops.aten.sub.Tensor(sub_195, unsqueeze_637)
Input Tensors:
tensor1953, Name: sub_195, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1947, Name: unsqueeze_637, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1954, Name: sub_196, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1544, Name: torch.ops.aten.mul.Tensor(sub_196, unsqueeze_643)
Input Tensors:
tensor1954, Name: sub_196, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1951, Name: unsqueeze_643, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1955, Name: mul_693, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1545, Name: torch.ops.aten.mul.Tensor(sum_73, squeeze_52)
Input Tensors:
tensor1946, Name: sum_73, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor638, Name: squeeze_52, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor1956, Name: mul_694, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1546, Name: torch.ops.aten.convolution_backward.default(mul_693, relu_14, primals_52, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1955, Name: mul_693, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor632, Name: relu_14, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor51, Name: primals_52, Is global?: 1: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
Output Tensors:
tensor1957, Name: getitem_213, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1958, Name: getitem_214, Is global?: 0: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
____________________________________________________________________
Kernel ID: 1547, Name: torch.ops.aten.le.Scalar(relu_14, 0)
Input Tensors:
tensor632, Name: relu_14, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1959, Name: le_34, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1548, Name: torch.ops.aten.where.self(le_34, full_default, getitem_213)
Input Tensors:
tensor1959, Name: le_34, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1957, Name: getitem_213, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1960, Name: where_34, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1549, Name: torch.ops.aten.sum.dim_IntList(where_34, [0, 2, 3])
Input Tensors:
tensor1960, Name: where_34, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1961, Name: sum_74, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1550, Name: torch.ops.aten.sub.Tensor(convolution_16, unsqueeze_646)
Input Tensors:
tensor615, Name: convolution_16, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor618, Name: unsqueeze_646, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1962, Name: sub_197, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1551, Name: torch.ops.aten.mul.Tensor(where_34, sub_197)
Input Tensors:
tensor1960, Name: where_34, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1962, Name: sub_197, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1963, Name: mul_695, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1552, Name: torch.ops.aten.sum.dim_IntList(mul_695, [0, 2, 3])
Input Tensors:
tensor1963, Name: mul_695, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1964, Name: sum_75, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1553, Name: torch.ops.aten.mul.Tensor(sum_74, 1.992984693877551e-05)
Input Tensors:
tensor1961, Name: sum_74, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1965, Name: mul_696, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1554, Name: torch.ops.aten.mul.Tensor(sum_75, 1.992984693877551e-05)
Input Tensors:
tensor1964, Name: sum_75, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1966, Name: mul_697, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1555, Name: torch.ops.aten.mul.Tensor(squeeze_49, squeeze_49)
Input Tensors:
tensor620, Name: squeeze_49, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor620, Name: squeeze_49, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1967, Name: mul_698, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1556, Name: torch.ops.aten.mul.Tensor(mul_697, mul_698)
Input Tensors:
tensor1966, Name: mul_697, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor1967, Name: mul_698, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1968, Name: mul_699, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1557, Name: torch.ops.aten.mul.Tensor(squeeze_49, primals_50)
Input Tensors:
tensor620, Name: squeeze_49, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor49, Name: primals_50, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1969, Name: mul_700, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1558, Name: torch.ops.aten.mul.Tensor(sub_197, unsqueeze_652)
Input Tensors:
tensor1962, Name: sub_197, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1968, Name: unsqueeze_652, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1970, Name: mul_701, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1559, Name: torch.ops.aten.sub.Tensor(where_34, mul_701)
Input Tensors:
tensor1960, Name: where_34, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1970, Name: mul_701, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1971, Name: sub_199, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1560, Name: torch.ops.aten.sub.Tensor(sub_199, unsqueeze_649)
Input Tensors:
tensor1971, Name: sub_199, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1965, Name: unsqueeze_649, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1972, Name: sub_200, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1561, Name: torch.ops.aten.mul.Tensor(sub_200, unsqueeze_655)
Input Tensors:
tensor1972, Name: sub_200, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1969, Name: unsqueeze_655, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1973, Name: mul_702, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1562, Name: torch.ops.aten.mul.Tensor(sum_75, squeeze_49)
Input Tensors:
tensor1964, Name: sum_75, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor620, Name: squeeze_49, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1974, Name: mul_703, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1563, Name: torch.ops.aten.convolution_backward.default(mul_702, relu_13, primals_49, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1973, Name: mul_702, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor614, Name: relu_13, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor48, Name: primals_49, Is global?: 1: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
Output Tensors:
tensor1975, Name: getitem_216, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1976, Name: getitem_217, Is global?: 0: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
____________________________________________________________________
Kernel ID: 1564, Name: torch.ops.aten.le.Scalar(relu_13, 0)
Input Tensors:
tensor614, Name: relu_13, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1977, Name: le_35, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1565, Name: torch.ops.aten.where.self(le_35, full_default, getitem_216)
Input Tensors:
tensor1977, Name: le_35, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1975, Name: getitem_216, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1978, Name: where_35, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1566, Name: torch.ops.aten.sum.dim_IntList(where_35, [0, 2, 3])
Input Tensors:
tensor1978, Name: where_35, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1979, Name: sum_76, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1567, Name: torch.ops.aten.sub.Tensor(convolution_15, unsqueeze_658)
Input Tensors:
tensor597, Name: convolution_15, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor600, Name: unsqueeze_658, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1980, Name: sub_201, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1568, Name: torch.ops.aten.mul.Tensor(where_35, sub_201)
Input Tensors:
tensor1978, Name: where_35, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1980, Name: sub_201, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1981, Name: mul_704, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1569, Name: torch.ops.aten.sum.dim_IntList(mul_704, [0, 2, 3])
Input Tensors:
tensor1981, Name: mul_704, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1982, Name: sum_77, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1570, Name: torch.ops.aten.mul.Tensor(sum_76, 1.992984693877551e-05)
Input Tensors:
tensor1979, Name: sum_76, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1983, Name: mul_705, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1571, Name: torch.ops.aten.mul.Tensor(sum_77, 1.992984693877551e-05)
Input Tensors:
tensor1982, Name: sum_77, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1984, Name: mul_706, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1572, Name: torch.ops.aten.mul.Tensor(squeeze_46, squeeze_46)
Input Tensors:
tensor602, Name: squeeze_46, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor602, Name: squeeze_46, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1985, Name: mul_707, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1573, Name: torch.ops.aten.mul.Tensor(mul_706, mul_707)
Input Tensors:
tensor1984, Name: mul_706, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor1985, Name: mul_707, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1986, Name: mul_708, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1574, Name: torch.ops.aten.mul.Tensor(squeeze_46, primals_47)
Input Tensors:
tensor602, Name: squeeze_46, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor46, Name: primals_47, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1987, Name: mul_709, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1575, Name: torch.ops.aten.mul.Tensor(sub_201, unsqueeze_664)
Input Tensors:
tensor1980, Name: sub_201, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1986, Name: unsqueeze_664, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1988, Name: mul_710, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1576, Name: torch.ops.aten.sub.Tensor(where_35, mul_710)
Input Tensors:
tensor1978, Name: where_35, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1988, Name: mul_710, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor1989, Name: sub_203, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1577, Name: torch.ops.aten.sub.Tensor(sub_203, unsqueeze_661)
Input Tensors:
tensor1989, Name: sub_203, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1983, Name: unsqueeze_661, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1990, Name: sub_204, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1578, Name: torch.ops.aten.mul.Tensor(sub_204, unsqueeze_667)
Input Tensors:
tensor1990, Name: sub_204, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor1987, Name: unsqueeze_667, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor1991, Name: mul_711, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1579, Name: torch.ops.aten.mul.Tensor(sum_77, squeeze_46)
Input Tensors:
tensor1982, Name: sum_77, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor602, Name: squeeze_46, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor1992, Name: mul_712, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1580, Name: torch.ops.aten.convolution_backward.default(mul_711, relu_12, primals_46, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor1991, Name: mul_711, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor596, Name: relu_12, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor45, Name: primals_46, Is global?: 1: Size in byte: 262144, Dimensions: f32[128, 512, 1, 1]
Output Tensors:
tensor1993, Name: getitem_219, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1994, Name: getitem_220, Is global?: 0: Size in byte: 262144, Dimensions: f32[128, 512, 1, 1]
____________________________________________________________________
Kernel ID: 1581, Name: torch.ops.aten.add.Tensor(where_33, getitem_219)
Input Tensors:
tensor1942, Name: where_33, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1993, Name: getitem_219, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1995, Name: add_292, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1582, Name: torch.ops.aten.le.Scalar(relu_12, 0)
Input Tensors:
tensor596, Name: relu_12, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1996, Name: le_36, Is global?: 0: Size in byte: 25690112, Dimensions: b8[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1583, Name: torch.ops.aten.where.self(le_36, full_default, add_292)
Input Tensors:
tensor1996, Name: le_36, Is global?: 0: Size in byte: 25690112, Dimensions: b8[64, 512, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor1995, Name: add_292, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1997, Name: where_36, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1584, Name: torch.ops.aten.sum.dim_IntList(where_36, [0, 2, 3])
Input Tensors:
tensor1997, Name: where_36, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor1998, Name: sum_78, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1585, Name: torch.ops.aten.sub.Tensor(convolution_14, unsqueeze_670)
Input Tensors:
tensor578, Name: convolution_14, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor581, Name: unsqueeze_670, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor1999, Name: sub_205, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1586, Name: torch.ops.aten.mul.Tensor(where_36, sub_205)
Input Tensors:
tensor1997, Name: where_36, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor1999, Name: sub_205, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor2000, Name: mul_713, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1587, Name: torch.ops.aten.sum.dim_IntList(mul_713, [0, 2, 3])
Input Tensors:
tensor2000, Name: mul_713, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor2001, Name: sum_79, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1588, Name: torch.ops.aten.mul.Tensor(sum_78, 1.992984693877551e-05)
Input Tensors:
tensor1998, Name: sum_78, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2002, Name: mul_714, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1589, Name: torch.ops.aten.mul.Tensor(sum_79, 1.992984693877551e-05)
Input Tensors:
tensor2001, Name: sum_79, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2003, Name: mul_715, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1590, Name: torch.ops.aten.mul.Tensor(squeeze_43, squeeze_43)
Input Tensors:
tensor583, Name: squeeze_43, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor583, Name: squeeze_43, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2004, Name: mul_716, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1591, Name: torch.ops.aten.mul.Tensor(mul_715, mul_716)
Input Tensors:
tensor2003, Name: mul_715, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor2004, Name: mul_716, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2005, Name: mul_717, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1592, Name: torch.ops.aten.mul.Tensor(squeeze_43, primals_44)
Input Tensors:
tensor583, Name: squeeze_43, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor43, Name: primals_44, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2006, Name: mul_718, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1593, Name: torch.ops.aten.mul.Tensor(sub_205, unsqueeze_676)
Input Tensors:
tensor1999, Name: sub_205, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor2005, Name: unsqueeze_676, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor2007, Name: mul_719, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1594, Name: torch.ops.aten.sub.Tensor(where_36, mul_719)
Input Tensors:
tensor1997, Name: where_36, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor2007, Name: mul_719, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor2008, Name: sub_207, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1595, Name: torch.ops.aten.sub.Tensor(sub_207, unsqueeze_673)
Input Tensors:
tensor2008, Name: sub_207, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor2002, Name: unsqueeze_673, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor2009, Name: sub_208, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1596, Name: torch.ops.aten.mul.Tensor(sub_208, unsqueeze_679)
Input Tensors:
tensor2009, Name: sub_208, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor2006, Name: unsqueeze_679, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor2010, Name: mul_720, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1597, Name: torch.ops.aten.mul.Tensor(sum_79, squeeze_43)
Input Tensors:
tensor2001, Name: sum_79, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor583, Name: squeeze_43, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2011, Name: mul_721, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1598, Name: torch.ops.aten.convolution_backward.default(mul_720, relu_9, primals_43, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2010, Name: mul_720, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor524, Name: relu_9, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor42, Name: primals_43, Is global?: 1: Size in byte: 524288, Dimensions: f32[512, 256, 1, 1]
Output Tensors:
tensor2012, Name: getitem_222, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2013, Name: getitem_223, Is global?: 0: Size in byte: 524288, Dimensions: f32[512, 256, 1, 1]
____________________________________________________________________
Kernel ID: 1599, Name: torch.ops.aten.sub.Tensor(convolution_13, unsqueeze_682)
Input Tensors:
tensor561, Name: convolution_13, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor564, Name: unsqueeze_682, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor2014, Name: sub_209, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1600, Name: torch.ops.aten.mul.Tensor(where_36, sub_209)
Input Tensors:
tensor1997, Name: where_36, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor2014, Name: sub_209, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor2015, Name: mul_722, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1601, Name: torch.ops.aten.sum.dim_IntList(mul_722, [0, 2, 3])
Input Tensors:
tensor2015, Name: mul_722, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor2016, Name: sum_81, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1602, Name: torch.ops.aten.mul.Tensor(sum_81, 1.992984693877551e-05)
Input Tensors:
tensor2016, Name: sum_81, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2017, Name: mul_724, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1603, Name: torch.ops.aten.mul.Tensor(squeeze_40, squeeze_40)
Input Tensors:
tensor566, Name: squeeze_40, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor566, Name: squeeze_40, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2018, Name: mul_725, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1604, Name: torch.ops.aten.mul.Tensor(mul_724, mul_725)
Input Tensors:
tensor2017, Name: mul_724, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor2018, Name: mul_725, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2019, Name: mul_726, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1605, Name: torch.ops.aten.mul.Tensor(squeeze_40, primals_41)
Input Tensors:
tensor566, Name: squeeze_40, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor40, Name: primals_41, Is global?: 1: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2020, Name: mul_727, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1606, Name: torch.ops.aten.mul.Tensor(sub_209, unsqueeze_688)
Input Tensors:
tensor2014, Name: sub_209, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor2019, Name: unsqueeze_688, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor2021, Name: mul_728, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1607, Name: torch.ops.aten.sub.Tensor(where_36, mul_728)
Input Tensors:
tensor1997, Name: where_36, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor2021, Name: mul_728, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
Output Tensors:
tensor2022, Name: sub_211, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1608, Name: torch.ops.aten.sub.Tensor(sub_211, unsqueeze_673)
Input Tensors:
tensor2022, Name: sub_211, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor2002, Name: unsqueeze_673, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor2023, Name: sub_212, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1609, Name: torch.ops.aten.mul.Tensor(sub_212, unsqueeze_691)
Input Tensors:
tensor2023, Name: sub_212, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor2020, Name: unsqueeze_691, Is global?: 0: Size in byte: 2048, Dimensions: f32[1, 512, 1, 1]
Output Tensors:
tensor2024, Name: mul_729, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
____________________________________________________________________
Kernel ID: 1610, Name: torch.ops.aten.mul.Tensor(sum_81, squeeze_40)
Input Tensors:
tensor2016, Name: sum_81, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
tensor566, Name: squeeze_40, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
Output Tensors:
tensor2025, Name: mul_730, Is global?: 0: Size in byte: 2048, Dimensions: f32[512]
____________________________________________________________________
Kernel ID: 1611, Name: torch.ops.aten.convolution_backward.default(mul_729, relu_11, primals_40, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2024, Name: mul_729, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 512, 28, 28]
tensor560, Name: relu_11, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor39, Name: primals_40, Is global?: 1: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
Output Tensors:
tensor2026, Name: getitem_225, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor2027, Name: getitem_226, Is global?: 0: Size in byte: 262144, Dimensions: f32[512, 128, 1, 1]
____________________________________________________________________
Kernel ID: 1612, Name: torch.ops.aten.le.Scalar(relu_11, 0)
Input Tensors:
tensor560, Name: relu_11, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor2028, Name: le_37, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1613, Name: torch.ops.aten.where.self(le_37, full_default, getitem_225)
Input Tensors:
tensor2028, Name: le_37, Is global?: 0: Size in byte: 6422528, Dimensions: b8[64, 128, 28, 28]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2026, Name: getitem_225, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor2029, Name: where_37, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1614, Name: torch.ops.aten.sum.dim_IntList(where_37, [0, 2, 3])
Input Tensors:
tensor2029, Name: where_37, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor2030, Name: sum_82, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1615, Name: torch.ops.aten.sub.Tensor(convolution_12, unsqueeze_694)
Input Tensors:
tensor543, Name: convolution_12, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor546, Name: unsqueeze_694, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor2031, Name: sub_213, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1616, Name: torch.ops.aten.mul.Tensor(where_37, sub_213)
Input Tensors:
tensor2029, Name: where_37, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor2031, Name: sub_213, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor2032, Name: mul_731, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1617, Name: torch.ops.aten.sum.dim_IntList(mul_731, [0, 2, 3])
Input Tensors:
tensor2032, Name: mul_731, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor2033, Name: sum_83, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1618, Name: torch.ops.aten.mul.Tensor(sum_82, 1.992984693877551e-05)
Input Tensors:
tensor2030, Name: sum_82, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2034, Name: mul_732, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1619, Name: torch.ops.aten.mul.Tensor(sum_83, 1.992984693877551e-05)
Input Tensors:
tensor2033, Name: sum_83, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2035, Name: mul_733, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1620, Name: torch.ops.aten.mul.Tensor(squeeze_37, squeeze_37)
Input Tensors:
tensor548, Name: squeeze_37, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor548, Name: squeeze_37, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2036, Name: mul_734, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1621, Name: torch.ops.aten.mul.Tensor(mul_733, mul_734)
Input Tensors:
tensor2035, Name: mul_733, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor2036, Name: mul_734, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2037, Name: mul_735, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1622, Name: torch.ops.aten.mul.Tensor(squeeze_37, primals_38)
Input Tensors:
tensor548, Name: squeeze_37, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor37, Name: primals_38, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2038, Name: mul_736, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1623, Name: torch.ops.aten.mul.Tensor(sub_213, unsqueeze_700)
Input Tensors:
tensor2031, Name: sub_213, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor2037, Name: unsqueeze_700, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor2039, Name: mul_737, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1624, Name: torch.ops.aten.sub.Tensor(where_37, mul_737)
Input Tensors:
tensor2029, Name: where_37, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor2039, Name: mul_737, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
Output Tensors:
tensor2040, Name: sub_215, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1625, Name: torch.ops.aten.sub.Tensor(sub_215, unsqueeze_697)
Input Tensors:
tensor2040, Name: sub_215, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor2034, Name: unsqueeze_697, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor2041, Name: sub_216, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1626, Name: torch.ops.aten.mul.Tensor(sub_216, unsqueeze_703)
Input Tensors:
tensor2041, Name: sub_216, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor2038, Name: unsqueeze_703, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor2042, Name: mul_738, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
____________________________________________________________________
Kernel ID: 1627, Name: torch.ops.aten.mul.Tensor(sum_83, squeeze_37)
Input Tensors:
tensor2033, Name: sum_83, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor548, Name: squeeze_37, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2043, Name: mul_739, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1628, Name: torch.ops.aten.convolution_backward.default(mul_738, relu_10, primals_37, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2042, Name: mul_738, Is global?: 0: Size in byte: 25690112, Dimensions: f32[64, 128, 28, 28]
tensor542, Name: relu_10, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor36, Name: primals_37, Is global?: 1: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
Output Tensors:
tensor2044, Name: getitem_228, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor2045, Name: getitem_229, Is global?: 0: Size in byte: 589824, Dimensions: f32[128, 128, 3, 3]
____________________________________________________________________
Kernel ID: 1629, Name: torch.ops.aten.le.Scalar(relu_10, 0)
Input Tensors:
tensor542, Name: relu_10, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
Output Tensors:
tensor2046, Name: le_38, Is global?: 0: Size in byte: 25690112, Dimensions: b8[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 1630, Name: torch.ops.aten.where.self(le_38, full_default, getitem_228)
Input Tensors:
tensor2046, Name: le_38, Is global?: 0: Size in byte: 25690112, Dimensions: b8[64, 128, 56, 56]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2044, Name: getitem_228, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
Output Tensors:
tensor2047, Name: where_38, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 1631, Name: torch.ops.aten.sum.dim_IntList(where_38, [0, 2, 3])
Input Tensors:
tensor2047, Name: where_38, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
Output Tensors:
tensor2048, Name: sum_84, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1632, Name: torch.ops.aten.sub.Tensor(convolution_11, unsqueeze_706)
Input Tensors:
tensor525, Name: convolution_11, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor528, Name: unsqueeze_706, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor2049, Name: sub_217, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 1633, Name: torch.ops.aten.mul.Tensor(where_38, sub_217)
Input Tensors:
tensor2047, Name: where_38, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor2049, Name: sub_217, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
Output Tensors:
tensor2050, Name: mul_740, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 1634, Name: torch.ops.aten.sum.dim_IntList(mul_740, [0, 2, 3])
Input Tensors:
tensor2050, Name: mul_740, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
Output Tensors:
tensor2051, Name: sum_85, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1635, Name: torch.ops.aten.mul.Tensor(sum_84, 4.982461734693877e-06)
Input Tensors:
tensor2048, Name: sum_84, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2052, Name: mul_741, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1636, Name: torch.ops.aten.mul.Tensor(sum_85, 4.982461734693877e-06)
Input Tensors:
tensor2051, Name: sum_85, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2053, Name: mul_742, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1637, Name: torch.ops.aten.mul.Tensor(squeeze_34, squeeze_34)
Input Tensors:
tensor530, Name: squeeze_34, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor530, Name: squeeze_34, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2054, Name: mul_743, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1638, Name: torch.ops.aten.mul.Tensor(mul_742, mul_743)
Input Tensors:
tensor2053, Name: mul_742, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor2054, Name: mul_743, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2055, Name: mul_744, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1639, Name: torch.ops.aten.mul.Tensor(squeeze_34, primals_35)
Input Tensors:
tensor530, Name: squeeze_34, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor34, Name: primals_35, Is global?: 1: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2056, Name: mul_745, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1640, Name: torch.ops.aten.mul.Tensor(sub_217, unsqueeze_712)
Input Tensors:
tensor2049, Name: sub_217, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor2055, Name: unsqueeze_712, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor2057, Name: mul_746, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 1641, Name: torch.ops.aten.sub.Tensor(where_38, mul_746)
Input Tensors:
tensor2047, Name: where_38, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor2057, Name: mul_746, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
Output Tensors:
tensor2058, Name: sub_219, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 1642, Name: torch.ops.aten.sub.Tensor(sub_219, unsqueeze_709)
Input Tensors:
tensor2058, Name: sub_219, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor2052, Name: unsqueeze_709, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor2059, Name: sub_220, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 1643, Name: torch.ops.aten.mul.Tensor(sub_220, unsqueeze_715)
Input Tensors:
tensor2059, Name: sub_220, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor2056, Name: unsqueeze_715, Is global?: 0: Size in byte: 512, Dimensions: f32[1, 128, 1, 1]
Output Tensors:
tensor2060, Name: mul_747, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
____________________________________________________________________
Kernel ID: 1644, Name: torch.ops.aten.mul.Tensor(sum_85, squeeze_34)
Input Tensors:
tensor2051, Name: sum_85, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
tensor530, Name: squeeze_34, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
Output Tensors:
tensor2061, Name: mul_748, Is global?: 0: Size in byte: 512, Dimensions: f32[128]
____________________________________________________________________
Kernel ID: 1645, Name: torch.ops.aten.convolution_backward.default(mul_747, relu_9, primals_34, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2060, Name: mul_747, Is global?: 0: Size in byte: 102760448, Dimensions: f32[64, 128, 56, 56]
tensor524, Name: relu_9, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor33, Name: primals_34, Is global?: 1: Size in byte: 131072, Dimensions: f32[128, 256, 1, 1]
Output Tensors:
tensor2062, Name: getitem_231, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2063, Name: getitem_232, Is global?: 0: Size in byte: 131072, Dimensions: f32[128, 256, 1, 1]
____________________________________________________________________
Kernel ID: 1646, Name: torch.ops.aten.add.Tensor(getitem_222, getitem_231)
Input Tensors:
tensor2012, Name: getitem_222, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2062, Name: getitem_231, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2064, Name: add_293, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1647, Name: torch.ops.aten.le.Scalar(relu_9, 0)
Input Tensors:
tensor524, Name: relu_9, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2065, Name: le_39, Is global?: 0: Size in byte: 51380224, Dimensions: b8[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1648, Name: torch.ops.aten.where.self(le_39, full_default, add_293)
Input Tensors:
tensor2065, Name: le_39, Is global?: 0: Size in byte: 51380224, Dimensions: b8[64, 256, 56, 56]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2064, Name: add_293, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2066, Name: where_39, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1649, Name: torch.ops.aten.sum.dim_IntList(where_39, [0, 2, 3])
Input Tensors:
tensor2066, Name: where_39, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2067, Name: sum_86, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1650, Name: torch.ops.aten.sub.Tensor(convolution_10, unsqueeze_718)
Input Tensors:
tensor506, Name: convolution_10, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor509, Name: unsqueeze_718, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2068, Name: sub_221, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1651, Name: torch.ops.aten.mul.Tensor(where_39, sub_221)
Input Tensors:
tensor2066, Name: where_39, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2068, Name: sub_221, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2069, Name: mul_749, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1652, Name: torch.ops.aten.sum.dim_IntList(mul_749, [0, 2, 3])
Input Tensors:
tensor2069, Name: mul_749, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2070, Name: sum_87, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1653, Name: torch.ops.aten.mul.Tensor(sum_86, 4.982461734693877e-06)
Input Tensors:
tensor2067, Name: sum_86, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2071, Name: mul_750, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1654, Name: torch.ops.aten.mul.Tensor(sum_87, 4.982461734693877e-06)
Input Tensors:
tensor2070, Name: sum_87, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2072, Name: mul_751, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1655, Name: torch.ops.aten.mul.Tensor(squeeze_31, squeeze_31)
Input Tensors:
tensor511, Name: squeeze_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor511, Name: squeeze_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2073, Name: mul_752, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1656, Name: torch.ops.aten.mul.Tensor(mul_751, mul_752)
Input Tensors:
tensor2072, Name: mul_751, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor2073, Name: mul_752, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2074, Name: mul_753, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1657, Name: torch.ops.aten.mul.Tensor(squeeze_31, primals_32)
Input Tensors:
tensor511, Name: squeeze_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor31, Name: primals_32, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2075, Name: mul_754, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1658, Name: torch.ops.aten.mul.Tensor(sub_221, unsqueeze_724)
Input Tensors:
tensor2068, Name: sub_221, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2074, Name: unsqueeze_724, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2076, Name: mul_755, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1659, Name: torch.ops.aten.sub.Tensor(where_39, mul_755)
Input Tensors:
tensor2066, Name: where_39, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2076, Name: mul_755, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2077, Name: sub_223, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1660, Name: torch.ops.aten.sub.Tensor(sub_223, unsqueeze_721)
Input Tensors:
tensor2077, Name: sub_223, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2071, Name: unsqueeze_721, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2078, Name: sub_224, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1661, Name: torch.ops.aten.mul.Tensor(sub_224, unsqueeze_727)
Input Tensors:
tensor2078, Name: sub_224, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2075, Name: unsqueeze_727, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2079, Name: mul_756, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1662, Name: torch.ops.aten.mul.Tensor(sum_87, squeeze_31)
Input Tensors:
tensor2070, Name: sum_87, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor511, Name: squeeze_31, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2080, Name: mul_757, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1663, Name: torch.ops.aten.convolution_backward.default(mul_756, relu_8, primals_31, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2079, Name: mul_756, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor505, Name: relu_8, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor30, Name: primals_31, Is global?: 1: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
Output Tensors:
tensor2081, Name: getitem_234, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2082, Name: getitem_235, Is global?: 0: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
____________________________________________________________________
Kernel ID: 1664, Name: torch.ops.aten.le.Scalar(relu_8, 0)
Input Tensors:
tensor505, Name: relu_8, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2083, Name: le_40, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1665, Name: torch.ops.aten.where.self(le_40, full_default, getitem_234)
Input Tensors:
tensor2083, Name: le_40, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2081, Name: getitem_234, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2084, Name: where_40, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1666, Name: torch.ops.aten.sum.dim_IntList(where_40, [0, 2, 3])
Input Tensors:
tensor2084, Name: where_40, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2085, Name: sum_88, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1667, Name: torch.ops.aten.sub.Tensor(convolution_9, unsqueeze_730)
Input Tensors:
tensor488, Name: convolution_9, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor491, Name: unsqueeze_730, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2086, Name: sub_225, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1668, Name: torch.ops.aten.mul.Tensor(where_40, sub_225)
Input Tensors:
tensor2084, Name: where_40, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2086, Name: sub_225, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2087, Name: mul_758, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1669, Name: torch.ops.aten.sum.dim_IntList(mul_758, [0, 2, 3])
Input Tensors:
tensor2087, Name: mul_758, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2088, Name: sum_89, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1670, Name: torch.ops.aten.mul.Tensor(sum_88, 4.982461734693877e-06)
Input Tensors:
tensor2085, Name: sum_88, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2089, Name: mul_759, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1671, Name: torch.ops.aten.mul.Tensor(sum_89, 4.982461734693877e-06)
Input Tensors:
tensor2088, Name: sum_89, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2090, Name: mul_760, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1672, Name: torch.ops.aten.mul.Tensor(squeeze_28, squeeze_28)
Input Tensors:
tensor493, Name: squeeze_28, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor493, Name: squeeze_28, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2091, Name: mul_761, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1673, Name: torch.ops.aten.mul.Tensor(mul_760, mul_761)
Input Tensors:
tensor2090, Name: mul_760, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor2091, Name: mul_761, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2092, Name: mul_762, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1674, Name: torch.ops.aten.mul.Tensor(squeeze_28, primals_29)
Input Tensors:
tensor493, Name: squeeze_28, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor28, Name: primals_29, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2093, Name: mul_763, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1675, Name: torch.ops.aten.mul.Tensor(sub_225, unsqueeze_736)
Input Tensors:
tensor2086, Name: sub_225, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2092, Name: unsqueeze_736, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2094, Name: mul_764, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1676, Name: torch.ops.aten.sub.Tensor(where_40, mul_764)
Input Tensors:
tensor2084, Name: where_40, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2094, Name: mul_764, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2095, Name: sub_227, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1677, Name: torch.ops.aten.sub.Tensor(sub_227, unsqueeze_733)
Input Tensors:
tensor2095, Name: sub_227, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2089, Name: unsqueeze_733, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2096, Name: sub_228, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1678, Name: torch.ops.aten.mul.Tensor(sub_228, unsqueeze_739)
Input Tensors:
tensor2096, Name: sub_228, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2093, Name: unsqueeze_739, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2097, Name: mul_765, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1679, Name: torch.ops.aten.mul.Tensor(sum_89, squeeze_28)
Input Tensors:
tensor2088, Name: sum_89, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor493, Name: squeeze_28, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2098, Name: mul_766, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1680, Name: torch.ops.aten.convolution_backward.default(mul_765, relu_7, primals_28, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2097, Name: mul_765, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor487, Name: relu_7, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor27, Name: primals_28, Is global?: 1: Size in byte: 147456, Dimensions: f32[64, 64, 3, 3]
Output Tensors:
tensor2099, Name: getitem_237, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2100, Name: getitem_238, Is global?: 0: Size in byte: 147456, Dimensions: f32[64, 64, 3, 3]
____________________________________________________________________
Kernel ID: 1681, Name: torch.ops.aten.le.Scalar(relu_7, 0)
Input Tensors:
tensor487, Name: relu_7, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2101, Name: le_41, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1682, Name: torch.ops.aten.where.self(le_41, full_default, getitem_237)
Input Tensors:
tensor2101, Name: le_41, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2099, Name: getitem_237, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2102, Name: where_41, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1683, Name: torch.ops.aten.sum.dim_IntList(where_41, [0, 2, 3])
Input Tensors:
tensor2102, Name: where_41, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2103, Name: sum_90, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1684, Name: torch.ops.aten.sub.Tensor(convolution_8, unsqueeze_742)
Input Tensors:
tensor470, Name: convolution_8, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor473, Name: unsqueeze_742, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2104, Name: sub_229, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1685, Name: torch.ops.aten.mul.Tensor(where_41, sub_229)
Input Tensors:
tensor2102, Name: where_41, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2104, Name: sub_229, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2105, Name: mul_767, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1686, Name: torch.ops.aten.sum.dim_IntList(mul_767, [0, 2, 3])
Input Tensors:
tensor2105, Name: mul_767, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2106, Name: sum_91, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1687, Name: torch.ops.aten.mul.Tensor(sum_90, 4.982461734693877e-06)
Input Tensors:
tensor2103, Name: sum_90, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2107, Name: mul_768, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1688, Name: torch.ops.aten.mul.Tensor(sum_91, 4.982461734693877e-06)
Input Tensors:
tensor2106, Name: sum_91, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2108, Name: mul_769, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1689, Name: torch.ops.aten.mul.Tensor(squeeze_25, squeeze_25)
Input Tensors:
tensor475, Name: squeeze_25, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor475, Name: squeeze_25, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2109, Name: mul_770, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1690, Name: torch.ops.aten.mul.Tensor(mul_769, mul_770)
Input Tensors:
tensor2108, Name: mul_769, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor2109, Name: mul_770, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2110, Name: mul_771, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1691, Name: torch.ops.aten.mul.Tensor(squeeze_25, primals_26)
Input Tensors:
tensor475, Name: squeeze_25, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor25, Name: primals_26, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2111, Name: mul_772, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1692, Name: torch.ops.aten.mul.Tensor(sub_229, unsqueeze_748)
Input Tensors:
tensor2104, Name: sub_229, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2110, Name: unsqueeze_748, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2112, Name: mul_773, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1693, Name: torch.ops.aten.sub.Tensor(where_41, mul_773)
Input Tensors:
tensor2102, Name: where_41, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2112, Name: mul_773, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2113, Name: sub_231, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1694, Name: torch.ops.aten.sub.Tensor(sub_231, unsqueeze_745)
Input Tensors:
tensor2113, Name: sub_231, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2107, Name: unsqueeze_745, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2114, Name: sub_232, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1695, Name: torch.ops.aten.mul.Tensor(sub_232, unsqueeze_751)
Input Tensors:
tensor2114, Name: sub_232, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2111, Name: unsqueeze_751, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2115, Name: mul_774, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1696, Name: torch.ops.aten.mul.Tensor(sum_91, squeeze_25)
Input Tensors:
tensor2106, Name: sum_91, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor475, Name: squeeze_25, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2116, Name: mul_775, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1697, Name: torch.ops.aten.convolution_backward.default(mul_774, relu_6, primals_25, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2115, Name: mul_774, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor469, Name: relu_6, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor24, Name: primals_25, Is global?: 1: Size in byte: 65536, Dimensions: f32[64, 256, 1, 1]
Output Tensors:
tensor2117, Name: getitem_240, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2118, Name: getitem_241, Is global?: 0: Size in byte: 65536, Dimensions: f32[64, 256, 1, 1]
____________________________________________________________________
Kernel ID: 1698, Name: torch.ops.aten.add.Tensor(where_39, getitem_240)
Input Tensors:
tensor2066, Name: where_39, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2117, Name: getitem_240, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2119, Name: add_294, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1699, Name: torch.ops.aten.le.Scalar(relu_6, 0)
Input Tensors:
tensor469, Name: relu_6, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2120, Name: le_42, Is global?: 0: Size in byte: 51380224, Dimensions: b8[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1700, Name: torch.ops.aten.where.self(le_42, full_default, add_294)
Input Tensors:
tensor2120, Name: le_42, Is global?: 0: Size in byte: 51380224, Dimensions: b8[64, 256, 56, 56]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2119, Name: add_294, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2121, Name: where_42, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1701, Name: torch.ops.aten.sum.dim_IntList(where_42, [0, 2, 3])
Input Tensors:
tensor2121, Name: where_42, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2122, Name: sum_92, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1702, Name: torch.ops.aten.sub.Tensor(convolution_7, unsqueeze_754)
Input Tensors:
tensor451, Name: convolution_7, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor454, Name: unsqueeze_754, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2123, Name: sub_233, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1703, Name: torch.ops.aten.mul.Tensor(where_42, sub_233)
Input Tensors:
tensor2121, Name: where_42, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2123, Name: sub_233, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2124, Name: mul_776, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1704, Name: torch.ops.aten.sum.dim_IntList(mul_776, [0, 2, 3])
Input Tensors:
tensor2124, Name: mul_776, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2125, Name: sum_93, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1705, Name: torch.ops.aten.mul.Tensor(sum_92, 4.982461734693877e-06)
Input Tensors:
tensor2122, Name: sum_92, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2126, Name: mul_777, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1706, Name: torch.ops.aten.mul.Tensor(sum_93, 4.982461734693877e-06)
Input Tensors:
tensor2125, Name: sum_93, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2127, Name: mul_778, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1707, Name: torch.ops.aten.mul.Tensor(squeeze_22, squeeze_22)
Input Tensors:
tensor456, Name: squeeze_22, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor456, Name: squeeze_22, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2128, Name: mul_779, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1708, Name: torch.ops.aten.mul.Tensor(mul_778, mul_779)
Input Tensors:
tensor2127, Name: mul_778, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor2128, Name: mul_779, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2129, Name: mul_780, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1709, Name: torch.ops.aten.mul.Tensor(squeeze_22, primals_23)
Input Tensors:
tensor456, Name: squeeze_22, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor22, Name: primals_23, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2130, Name: mul_781, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1710, Name: torch.ops.aten.mul.Tensor(sub_233, unsqueeze_760)
Input Tensors:
tensor2123, Name: sub_233, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2129, Name: unsqueeze_760, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2131, Name: mul_782, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1711, Name: torch.ops.aten.sub.Tensor(where_42, mul_782)
Input Tensors:
tensor2121, Name: where_42, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2131, Name: mul_782, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2132, Name: sub_235, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1712, Name: torch.ops.aten.sub.Tensor(sub_235, unsqueeze_757)
Input Tensors:
tensor2132, Name: sub_235, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2126, Name: unsqueeze_757, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2133, Name: sub_236, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1713, Name: torch.ops.aten.mul.Tensor(sub_236, unsqueeze_763)
Input Tensors:
tensor2133, Name: sub_236, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2130, Name: unsqueeze_763, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2134, Name: mul_783, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1714, Name: torch.ops.aten.mul.Tensor(sum_93, squeeze_22)
Input Tensors:
tensor2125, Name: sum_93, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor456, Name: squeeze_22, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2135, Name: mul_784, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1715, Name: torch.ops.aten.convolution_backward.default(mul_783, relu_5, primals_22, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2134, Name: mul_783, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor450, Name: relu_5, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor21, Name: primals_22, Is global?: 1: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
Output Tensors:
tensor2136, Name: getitem_243, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2137, Name: getitem_244, Is global?: 0: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
____________________________________________________________________
Kernel ID: 1716, Name: torch.ops.aten.le.Scalar(relu_5, 0)
Input Tensors:
tensor450, Name: relu_5, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2138, Name: le_43, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1717, Name: torch.ops.aten.where.self(le_43, full_default, getitem_243)
Input Tensors:
tensor2138, Name: le_43, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2136, Name: getitem_243, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2139, Name: where_43, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1718, Name: torch.ops.aten.sum.dim_IntList(where_43, [0, 2, 3])
Input Tensors:
tensor2139, Name: where_43, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2140, Name: sum_94, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1719, Name: torch.ops.aten.sub.Tensor(convolution_6, unsqueeze_766)
Input Tensors:
tensor433, Name: convolution_6, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor436, Name: unsqueeze_766, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2141, Name: sub_237, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1720, Name: torch.ops.aten.mul.Tensor(where_43, sub_237)
Input Tensors:
tensor2139, Name: where_43, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2141, Name: sub_237, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2142, Name: mul_785, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1721, Name: torch.ops.aten.sum.dim_IntList(mul_785, [0, 2, 3])
Input Tensors:
tensor2142, Name: mul_785, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2143, Name: sum_95, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1722, Name: torch.ops.aten.mul.Tensor(sum_94, 4.982461734693877e-06)
Input Tensors:
tensor2140, Name: sum_94, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2144, Name: mul_786, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1723, Name: torch.ops.aten.mul.Tensor(sum_95, 4.982461734693877e-06)
Input Tensors:
tensor2143, Name: sum_95, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2145, Name: mul_787, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1724, Name: torch.ops.aten.mul.Tensor(squeeze_19, squeeze_19)
Input Tensors:
tensor438, Name: squeeze_19, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor438, Name: squeeze_19, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2146, Name: mul_788, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1725, Name: torch.ops.aten.mul.Tensor(mul_787, mul_788)
Input Tensors:
tensor2145, Name: mul_787, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor2146, Name: mul_788, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2147, Name: mul_789, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1726, Name: torch.ops.aten.mul.Tensor(squeeze_19, primals_20)
Input Tensors:
tensor438, Name: squeeze_19, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor19, Name: primals_20, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2148, Name: mul_790, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1727, Name: torch.ops.aten.mul.Tensor(sub_237, unsqueeze_772)
Input Tensors:
tensor2141, Name: sub_237, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2147, Name: unsqueeze_772, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2149, Name: mul_791, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1728, Name: torch.ops.aten.sub.Tensor(where_43, mul_791)
Input Tensors:
tensor2139, Name: where_43, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2149, Name: mul_791, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2150, Name: sub_239, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1729, Name: torch.ops.aten.sub.Tensor(sub_239, unsqueeze_769)
Input Tensors:
tensor2150, Name: sub_239, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2144, Name: unsqueeze_769, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2151, Name: sub_240, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1730, Name: torch.ops.aten.mul.Tensor(sub_240, unsqueeze_775)
Input Tensors:
tensor2151, Name: sub_240, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2148, Name: unsqueeze_775, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2152, Name: mul_792, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1731, Name: torch.ops.aten.mul.Tensor(sum_95, squeeze_19)
Input Tensors:
tensor2143, Name: sum_95, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor438, Name: squeeze_19, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2153, Name: mul_793, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1732, Name: torch.ops.aten.convolution_backward.default(mul_792, relu_4, primals_19, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2152, Name: mul_792, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor432, Name: relu_4, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor18, Name: primals_19, Is global?: 1: Size in byte: 147456, Dimensions: f32[64, 64, 3, 3]
Output Tensors:
tensor2154, Name: getitem_246, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2155, Name: getitem_247, Is global?: 0: Size in byte: 147456, Dimensions: f32[64, 64, 3, 3]
____________________________________________________________________
Kernel ID: 1733, Name: torch.ops.aten.le.Scalar(relu_4, 0)
Input Tensors:
tensor432, Name: relu_4, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2156, Name: le_44, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1734, Name: torch.ops.aten.where.self(le_44, full_default, getitem_246)
Input Tensors:
tensor2156, Name: le_44, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2154, Name: getitem_246, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2157, Name: where_44, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1735, Name: torch.ops.aten.sum.dim_IntList(where_44, [0, 2, 3])
Input Tensors:
tensor2157, Name: where_44, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2158, Name: sum_96, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1736, Name: torch.ops.aten.sub.Tensor(convolution_5, unsqueeze_778)
Input Tensors:
tensor415, Name: convolution_5, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor418, Name: unsqueeze_778, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2159, Name: sub_241, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1737, Name: torch.ops.aten.mul.Tensor(where_44, sub_241)
Input Tensors:
tensor2157, Name: where_44, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2159, Name: sub_241, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2160, Name: mul_794, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1738, Name: torch.ops.aten.sum.dim_IntList(mul_794, [0, 2, 3])
Input Tensors:
tensor2160, Name: mul_794, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2161, Name: sum_97, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1739, Name: torch.ops.aten.mul.Tensor(sum_96, 4.982461734693877e-06)
Input Tensors:
tensor2158, Name: sum_96, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2162, Name: mul_795, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1740, Name: torch.ops.aten.mul.Tensor(sum_97, 4.982461734693877e-06)
Input Tensors:
tensor2161, Name: sum_97, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2163, Name: mul_796, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1741, Name: torch.ops.aten.mul.Tensor(squeeze_16, squeeze_16)
Input Tensors:
tensor420, Name: squeeze_16, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor420, Name: squeeze_16, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2164, Name: mul_797, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1742, Name: torch.ops.aten.mul.Tensor(mul_796, mul_797)
Input Tensors:
tensor2163, Name: mul_796, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor2164, Name: mul_797, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2165, Name: mul_798, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1743, Name: torch.ops.aten.mul.Tensor(squeeze_16, primals_17)
Input Tensors:
tensor420, Name: squeeze_16, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor16, Name: primals_17, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2166, Name: mul_799, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1744, Name: torch.ops.aten.mul.Tensor(sub_241, unsqueeze_784)
Input Tensors:
tensor2159, Name: sub_241, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2165, Name: unsqueeze_784, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2167, Name: mul_800, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1745, Name: torch.ops.aten.sub.Tensor(where_44, mul_800)
Input Tensors:
tensor2157, Name: where_44, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2167, Name: mul_800, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2168, Name: sub_243, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1746, Name: torch.ops.aten.sub.Tensor(sub_243, unsqueeze_781)
Input Tensors:
tensor2168, Name: sub_243, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2162, Name: unsqueeze_781, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2169, Name: sub_244, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1747, Name: torch.ops.aten.mul.Tensor(sub_244, unsqueeze_787)
Input Tensors:
tensor2169, Name: sub_244, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2166, Name: unsqueeze_787, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2170, Name: mul_801, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1748, Name: torch.ops.aten.mul.Tensor(sum_97, squeeze_16)
Input Tensors:
tensor2161, Name: sum_97, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor420, Name: squeeze_16, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2171, Name: mul_802, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1749, Name: torch.ops.aten.convolution_backward.default(mul_801, relu_3, primals_16, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2170, Name: mul_801, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor414, Name: relu_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor15, Name: primals_16, Is global?: 1: Size in byte: 65536, Dimensions: f32[64, 256, 1, 1]
Output Tensors:
tensor2172, Name: getitem_249, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2173, Name: getitem_250, Is global?: 0: Size in byte: 65536, Dimensions: f32[64, 256, 1, 1]
____________________________________________________________________
Kernel ID: 1750, Name: torch.ops.aten.add.Tensor(where_42, getitem_249)
Input Tensors:
tensor2121, Name: where_42, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2172, Name: getitem_249, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2174, Name: add_295, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1751, Name: torch.ops.aten.le.Scalar(relu_3, 0)
Input Tensors:
tensor414, Name: relu_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2175, Name: le_45, Is global?: 0: Size in byte: 51380224, Dimensions: b8[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1752, Name: torch.ops.aten.where.self(le_45, full_default, add_295)
Input Tensors:
tensor2175, Name: le_45, Is global?: 0: Size in byte: 51380224, Dimensions: b8[64, 256, 56, 56]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2174, Name: add_295, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2176, Name: where_45, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1753, Name: torch.ops.aten.sum.dim_IntList(where_45, [0, 2, 3])
Input Tensors:
tensor2176, Name: where_45, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2177, Name: sum_98, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1754, Name: torch.ops.aten.sub.Tensor(convolution_4, unsqueeze_790)
Input Tensors:
tensor396, Name: convolution_4, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor399, Name: unsqueeze_790, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2178, Name: sub_245, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1755, Name: torch.ops.aten.mul.Tensor(where_45, sub_245)
Input Tensors:
tensor2176, Name: where_45, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2178, Name: sub_245, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2179, Name: mul_803, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1756, Name: torch.ops.aten.sum.dim_IntList(mul_803, [0, 2, 3])
Input Tensors:
tensor2179, Name: mul_803, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2180, Name: sum_99, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1757, Name: torch.ops.aten.mul.Tensor(sum_98, 4.982461734693877e-06)
Input Tensors:
tensor2177, Name: sum_98, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2181, Name: mul_804, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1758, Name: torch.ops.aten.mul.Tensor(sum_99, 4.982461734693877e-06)
Input Tensors:
tensor2180, Name: sum_99, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2182, Name: mul_805, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1759, Name: torch.ops.aten.mul.Tensor(squeeze_13, squeeze_13)
Input Tensors:
tensor401, Name: squeeze_13, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor401, Name: squeeze_13, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2183, Name: mul_806, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1760, Name: torch.ops.aten.mul.Tensor(mul_805, mul_806)
Input Tensors:
tensor2182, Name: mul_805, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor2183, Name: mul_806, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2184, Name: mul_807, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1761, Name: torch.ops.aten.mul.Tensor(squeeze_13, primals_14)
Input Tensors:
tensor401, Name: squeeze_13, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor13, Name: primals_14, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2185, Name: mul_808, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1762, Name: torch.ops.aten.mul.Tensor(sub_245, unsqueeze_796)
Input Tensors:
tensor2178, Name: sub_245, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2184, Name: unsqueeze_796, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2186, Name: mul_809, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1763, Name: torch.ops.aten.sub.Tensor(where_45, mul_809)
Input Tensors:
tensor2176, Name: where_45, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2186, Name: mul_809, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2187, Name: sub_247, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1764, Name: torch.ops.aten.sub.Tensor(sub_247, unsqueeze_793)
Input Tensors:
tensor2187, Name: sub_247, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2181, Name: unsqueeze_793, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2188, Name: sub_248, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1765, Name: torch.ops.aten.mul.Tensor(sub_248, unsqueeze_799)
Input Tensors:
tensor2188, Name: sub_248, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2185, Name: unsqueeze_799, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2189, Name: mul_810, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1766, Name: torch.ops.aten.mul.Tensor(sum_99, squeeze_13)
Input Tensors:
tensor2180, Name: sum_99, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor401, Name: squeeze_13, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2190, Name: mul_811, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1767, Name: torch.ops.aten.convolution_backward.default(mul_810, getitem_2, primals_13, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2189, Name: mul_810, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor341, Name: getitem_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor12, Name: primals_13, Is global?: 1: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
Output Tensors:
tensor2191, Name: getitem_252, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2192, Name: getitem_253, Is global?: 0: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
____________________________________________________________________
Kernel ID: 1768, Name: torch.ops.aten.sub.Tensor(convolution_3, unsqueeze_802)
Input Tensors:
tensor379, Name: convolution_3, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor382, Name: unsqueeze_802, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2193, Name: sub_249, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1769, Name: torch.ops.aten.mul.Tensor(where_45, sub_249)
Input Tensors:
tensor2176, Name: where_45, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2193, Name: sub_249, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2194, Name: mul_812, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1770, Name: torch.ops.aten.sum.dim_IntList(mul_812, [0, 2, 3])
Input Tensors:
tensor2194, Name: mul_812, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2195, Name: sum_101, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1771, Name: torch.ops.aten.mul.Tensor(sum_101, 4.982461734693877e-06)
Input Tensors:
tensor2195, Name: sum_101, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2196, Name: mul_814, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1772, Name: torch.ops.aten.mul.Tensor(squeeze_10, squeeze_10)
Input Tensors:
tensor384, Name: squeeze_10, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor384, Name: squeeze_10, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2197, Name: mul_815, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1773, Name: torch.ops.aten.mul.Tensor(mul_814, mul_815)
Input Tensors:
tensor2196, Name: mul_814, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor2197, Name: mul_815, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2198, Name: mul_816, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1774, Name: torch.ops.aten.mul.Tensor(squeeze_10, primals_11)
Input Tensors:
tensor384, Name: squeeze_10, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor10, Name: primals_11, Is global?: 1: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2199, Name: mul_817, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1775, Name: torch.ops.aten.mul.Tensor(sub_249, unsqueeze_808)
Input Tensors:
tensor2193, Name: sub_249, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2198, Name: unsqueeze_808, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2200, Name: mul_818, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1776, Name: torch.ops.aten.sub.Tensor(where_45, mul_818)
Input Tensors:
tensor2176, Name: where_45, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2200, Name: mul_818, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
Output Tensors:
tensor2201, Name: sub_251, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1777, Name: torch.ops.aten.sub.Tensor(sub_251, unsqueeze_793)
Input Tensors:
tensor2201, Name: sub_251, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2181, Name: unsqueeze_793, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2202, Name: sub_252, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1778, Name: torch.ops.aten.mul.Tensor(sub_252, unsqueeze_811)
Input Tensors:
tensor2202, Name: sub_252, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor2199, Name: unsqueeze_811, Is global?: 0: Size in byte: 1024, Dimensions: f32[1, 256, 1, 1]
Output Tensors:
tensor2203, Name: mul_819, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
____________________________________________________________________
Kernel ID: 1779, Name: torch.ops.aten.mul.Tensor(sum_101, squeeze_10)
Input Tensors:
tensor2195, Name: sum_101, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
tensor384, Name: squeeze_10, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
Output Tensors:
tensor2204, Name: mul_820, Is global?: 0: Size in byte: 1024, Dimensions: f32[256]
____________________________________________________________________
Kernel ID: 1780, Name: torch.ops.aten.convolution_backward.default(mul_819, relu_2, primals_10, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2203, Name: mul_819, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 256, 56, 56]
tensor378, Name: relu_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor9, Name: primals_10, Is global?: 1: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
Output Tensors:
tensor2205, Name: getitem_255, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2206, Name: getitem_256, Is global?: 0: Size in byte: 65536, Dimensions: f32[256, 64, 1, 1]
____________________________________________________________________
Kernel ID: 1781, Name: torch.ops.aten.le.Scalar(relu_2, 0)
Input Tensors:
tensor378, Name: relu_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2207, Name: le_46, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1782, Name: torch.ops.aten.where.self(le_46, full_default, getitem_255)
Input Tensors:
tensor2207, Name: le_46, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2205, Name: getitem_255, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2208, Name: where_46, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1783, Name: torch.ops.aten.sum.dim_IntList(where_46, [0, 2, 3])
Input Tensors:
tensor2208, Name: where_46, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2209, Name: sum_102, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1784, Name: torch.ops.aten.sub.Tensor(convolution_2, unsqueeze_814)
Input Tensors:
tensor361, Name: convolution_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor364, Name: unsqueeze_814, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2210, Name: sub_253, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1785, Name: torch.ops.aten.mul.Tensor(where_46, sub_253)
Input Tensors:
tensor2208, Name: where_46, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2210, Name: sub_253, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2211, Name: mul_821, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1786, Name: torch.ops.aten.sum.dim_IntList(mul_821, [0, 2, 3])
Input Tensors:
tensor2211, Name: mul_821, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2212, Name: sum_103, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1787, Name: torch.ops.aten.mul.Tensor(sum_102, 4.982461734693877e-06)
Input Tensors:
tensor2209, Name: sum_102, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2213, Name: mul_822, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1788, Name: torch.ops.aten.mul.Tensor(sum_103, 4.982461734693877e-06)
Input Tensors:
tensor2212, Name: sum_103, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2214, Name: mul_823, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1789, Name: torch.ops.aten.mul.Tensor(squeeze_7, squeeze_7)
Input Tensors:
tensor366, Name: squeeze_7, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor366, Name: squeeze_7, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2215, Name: mul_824, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1790, Name: torch.ops.aten.mul.Tensor(mul_823, mul_824)
Input Tensors:
tensor2214, Name: mul_823, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor2215, Name: mul_824, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2216, Name: mul_825, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1791, Name: torch.ops.aten.mul.Tensor(squeeze_7, primals_8)
Input Tensors:
tensor366, Name: squeeze_7, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor7, Name: primals_8, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2217, Name: mul_826, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1792, Name: torch.ops.aten.mul.Tensor(sub_253, unsqueeze_820)
Input Tensors:
tensor2210, Name: sub_253, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2216, Name: unsqueeze_820, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2218, Name: mul_827, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1793, Name: torch.ops.aten.sub.Tensor(where_46, mul_827)
Input Tensors:
tensor2208, Name: where_46, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2218, Name: mul_827, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2219, Name: sub_255, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1794, Name: torch.ops.aten.sub.Tensor(sub_255, unsqueeze_817)
Input Tensors:
tensor2219, Name: sub_255, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2213, Name: unsqueeze_817, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2220, Name: sub_256, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1795, Name: torch.ops.aten.mul.Tensor(sub_256, unsqueeze_823)
Input Tensors:
tensor2220, Name: sub_256, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2217, Name: unsqueeze_823, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2221, Name: mul_828, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1796, Name: torch.ops.aten.mul.Tensor(sum_103, squeeze_7)
Input Tensors:
tensor2212, Name: sum_103, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor366, Name: squeeze_7, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2222, Name: mul_829, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1797, Name: torch.ops.aten.convolution_backward.default(mul_828, relu_1, primals_7, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2221, Name: mul_828, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor360, Name: relu_1, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor6, Name: primals_7, Is global?: 1: Size in byte: 147456, Dimensions: f32[64, 64, 3, 3]
Output Tensors:
tensor2223, Name: getitem_258, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2224, Name: getitem_259, Is global?: 0: Size in byte: 147456, Dimensions: f32[64, 64, 3, 3]
____________________________________________________________________
Kernel ID: 1798, Name: torch.ops.aten.le.Scalar(relu_1, 0)
Input Tensors:
tensor360, Name: relu_1, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2225, Name: le_47, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1799, Name: torch.ops.aten.where.self(le_47, full_default, getitem_258)
Input Tensors:
tensor2225, Name: le_47, Is global?: 0: Size in byte: 12845056, Dimensions: b8[64, 64, 56, 56]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2223, Name: getitem_258, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2226, Name: where_47, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1800, Name: torch.ops.aten.sum.dim_IntList(where_47, [0, 2, 3])
Input Tensors:
tensor2226, Name: where_47, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2227, Name: sum_104, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1801, Name: torch.ops.aten.sub.Tensor(convolution_1, unsqueeze_826)
Input Tensors:
tensor343, Name: convolution_1, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor346, Name: unsqueeze_826, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2228, Name: sub_257, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1802, Name: torch.ops.aten.mul.Tensor(where_47, sub_257)
Input Tensors:
tensor2226, Name: where_47, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2228, Name: sub_257, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2229, Name: mul_830, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1803, Name: torch.ops.aten.sum.dim_IntList(mul_830, [0, 2, 3])
Input Tensors:
tensor2229, Name: mul_830, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2230, Name: sum_105, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1804, Name: torch.ops.aten.mul.Tensor(sum_104, 4.982461734693877e-06)
Input Tensors:
tensor2227, Name: sum_104, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2231, Name: mul_831, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1805, Name: torch.ops.aten.mul.Tensor(sum_105, 4.982461734693877e-06)
Input Tensors:
tensor2230, Name: sum_105, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2232, Name: mul_832, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1806, Name: torch.ops.aten.mul.Tensor(squeeze_4, squeeze_4)
Input Tensors:
tensor348, Name: squeeze_4, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor348, Name: squeeze_4, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2233, Name: mul_833, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1807, Name: torch.ops.aten.mul.Tensor(mul_832, mul_833)
Input Tensors:
tensor2232, Name: mul_832, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor2233, Name: mul_833, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2234, Name: mul_834, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1808, Name: torch.ops.aten.mul.Tensor(squeeze_4, primals_5)
Input Tensors:
tensor348, Name: squeeze_4, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor4, Name: primals_5, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2235, Name: mul_835, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1809, Name: torch.ops.aten.mul.Tensor(sub_257, unsqueeze_832)
Input Tensors:
tensor2228, Name: sub_257, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2234, Name: unsqueeze_832, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2236, Name: mul_836, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1810, Name: torch.ops.aten.sub.Tensor(where_47, mul_836)
Input Tensors:
tensor2226, Name: where_47, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2236, Name: mul_836, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2237, Name: sub_259, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1811, Name: torch.ops.aten.sub.Tensor(sub_259, unsqueeze_829)
Input Tensors:
tensor2237, Name: sub_259, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2231, Name: unsqueeze_829, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2238, Name: sub_260, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1812, Name: torch.ops.aten.mul.Tensor(sub_260, unsqueeze_835)
Input Tensors:
tensor2238, Name: sub_260, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2235, Name: unsqueeze_835, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2239, Name: mul_837, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1813, Name: torch.ops.aten.mul.Tensor(sum_105, squeeze_4)
Input Tensors:
tensor2230, Name: sum_105, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor348, Name: squeeze_4, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2240, Name: mul_838, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1814, Name: torch.ops.aten.convolution_backward.default(mul_837, getitem_2, primals_4, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
Input Tensors:
tensor2239, Name: mul_837, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor341, Name: getitem_2, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor3, Name: primals_4, Is global?: 1: Size in byte: 16384, Dimensions: f32[64, 64, 1, 1]
Output Tensors:
tensor2241, Name: getitem_261, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2242, Name: getitem_262, Is global?: 0: Size in byte: 16384, Dimensions: f32[64, 64, 1, 1]
____________________________________________________________________
Kernel ID: 1815, Name: torch.ops.aten.add.Tensor(getitem_252, getitem_261)
Input Tensors:
tensor2191, Name: getitem_252, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor2241, Name: getitem_261, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
Output Tensors:
tensor2243, Name: add_296, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
____________________________________________________________________
Kernel ID: 1816, Name: torch.ops.aten.max_pool2d_with_indices_backward.default(add_296, relu, [3, 3], [2, 2], [1, 1], [1, 1], False, getitem_3)
Input Tensors:
tensor2243, Name: add_296, Is global?: 0: Size in byte: 51380224, Dimensions: f32[64, 64, 56, 56]
tensor340, Name: relu, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor342, Name: getitem_3, Is global?: 0: Size in byte: 102760448, Dimensions: i64[64, 64, 56, 56]
Output Tensors:
tensor2244, Name: max_pool2d_with_indices_backward, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 1817, Name: torch.ops.aten.le.Scalar(relu, 0)
Input Tensors:
tensor340, Name: relu, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
Output Tensors:
tensor2245, Name: le_48, Is global?: 0: Size in byte: 51380224, Dimensions: b8[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 1818, Name: torch.ops.aten.where.self(le_48, full_default, max_pool2d_with_indices_backward)
Input Tensors:
tensor2245, Name: le_48, Is global?: 0: Size in byte: 51380224, Dimensions: b8[64, 64, 112, 112]
tensor1308, Name: full_default, Is global?: 0: Size in byte: 4, Dimensions: f32[]
tensor2244, Name: max_pool2d_with_indices_backward, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
Output Tensors:
tensor2246, Name: where_48, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 1819, Name: torch.ops.aten.sum.dim_IntList(where_48, [0, 2, 3])
Input Tensors:
tensor2246, Name: where_48, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
Output Tensors:
tensor2247, Name: sum_106, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1820, Name: torch.ops.aten.sub.Tensor(convolution, unsqueeze_838)
Input Tensors:
tensor321, Name: convolution, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor329, Name: unsqueeze_838, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2248, Name: sub_261, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 1821, Name: torch.ops.aten.mul.Tensor(where_48, sub_261)
Input Tensors:
tensor2246, Name: where_48, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor2248, Name: sub_261, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
Output Tensors:
tensor2249, Name: mul_839, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 1822, Name: torch.ops.aten.sum.dim_IntList(mul_839, [0, 2, 3])
Input Tensors:
tensor2249, Name: mul_839, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
Output Tensors:
tensor2250, Name: sum_107, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1823, Name: torch.ops.aten.mul.Tensor(sum_106, 1.2456154336734693e-06)
Input Tensors:
tensor2247, Name: sum_106, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2251, Name: mul_840, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1824, Name: torch.ops.aten.mul.Tensor(sum_107, 1.2456154336734693e-06)
Input Tensors:
tensor2250, Name: sum_107, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2252, Name: mul_841, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1825, Name: torch.ops.aten.mul.Tensor(squeeze_1, squeeze_1)
Input Tensors:
tensor326, Name: squeeze_1, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor326, Name: squeeze_1, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2253, Name: mul_842, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1826, Name: torch.ops.aten.mul.Tensor(mul_841, mul_842)
Input Tensors:
tensor2252, Name: mul_841, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor2253, Name: mul_842, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2254, Name: mul_843, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1827, Name: torch.ops.aten.mul.Tensor(squeeze_1, primals_2)
Input Tensors:
tensor326, Name: squeeze_1, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor1, Name: primals_2, Is global?: 1: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2255, Name: mul_844, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1828, Name: torch.ops.aten.mul.Tensor(sub_261, unsqueeze_844)
Input Tensors:
tensor2248, Name: sub_261, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor2254, Name: unsqueeze_844, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2256, Name: mul_845, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 1829, Name: torch.ops.aten.sub.Tensor(where_48, mul_845)
Input Tensors:
tensor2246, Name: where_48, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor2256, Name: mul_845, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
Output Tensors:
tensor2257, Name: sub_263, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 1830, Name: torch.ops.aten.sub.Tensor(sub_263, unsqueeze_841)
Input Tensors:
tensor2257, Name: sub_263, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor2251, Name: unsqueeze_841, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2258, Name: sub_264, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 1831, Name: torch.ops.aten.mul.Tensor(sub_264, unsqueeze_847)
Input Tensors:
tensor2258, Name: sub_264, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor2255, Name: unsqueeze_847, Is global?: 0: Size in byte: 256, Dimensions: f32[1, 64, 1, 1]
Output Tensors:
tensor2259, Name: mul_846, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
____________________________________________________________________
Kernel ID: 1832, Name: torch.ops.aten.mul.Tensor(sum_107, squeeze_1)
Input Tensors:
tensor2250, Name: sum_107, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
tensor326, Name: squeeze_1, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
Output Tensors:
tensor2260, Name: mul_847, Is global?: 0: Size in byte: 256, Dimensions: f32[64]
____________________________________________________________________
Kernel ID: 1833, Name: torch.ops.aten.convolution_backward.default(mul_846, primals_321, primals_1, [0], [2, 2], [3, 3], [1, 1], False, [0, 0], 1, [False, True, False])
Input Tensors:
tensor2259, Name: mul_846, Is global?: 0: Size in byte: 205520896, Dimensions: f32[64, 64, 112, 112]
tensor320, Name: primals_321, Is global?: 1: Size in byte: 38535168, Dimensions: f32[64, 3, 224, 224]
tensor0, Name: primals_1, Is global?: 1: Size in byte: 37632, Dimensions: f32[64, 3, 7, 7]
Output Tensors:
tensor2261, Name: getitem_265, Is global?: 0: Size in byte: 37632, Dimensions: f32[64, 3, 7, 7]
____________________________________________________________________
